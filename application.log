2023-06-23 18:18:41,279 - root - INFO - i am in the main method...
2023-06-23 18:18:41,280 - root - INFO - Calling  spark object
2023-06-23 18:18:41,280 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:18:41,280 - Create_pyspark - INFO - master is local
2023-06-23 18:18:55,020 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:18:55,020 - root - INFO - Validating spark object 
2023-06-23 18:19:02,856 - root - INFO - Aplication done
2023-06-23 18:20:56,612 - root - INFO - i am in the main method...
2023-06-23 18:20:56,613 - root - INFO - Calling  spark object
2023-06-23 18:20:56,613 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:20:56,613 - Create_pyspark - INFO - master is local
2023-06-23 18:21:19,575 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:21:19,575 - root - INFO - Validating spark object 
2023-06-23 18:21:27,799 - root - INFO - Aplication done
2023-06-23 18:25:24,809 - root - INFO - i am in the main method...
2023-06-23 18:25:24,809 - root - INFO - Calling  spark object
2023-06-23 18:25:24,810 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:25:24,810 - Create_pyspark - INFO - master is local
2023-06-23 18:25:35,344 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:25:35,345 - root - INFO - Validating spark object 
2023-06-23 18:25:54,942 - root - INFO - i am in the main method...
2023-06-23 18:25:54,942 - root - INFO - Calling  spark object
2023-06-23 18:25:54,942 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:25:54,942 - Create_pyspark - INFO - master is local
2023-06-23 18:26:05,309 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:26:05,309 - root - INFO - Validating spark object 
2023-06-23 18:26:11,941 - root - INFO - Aplication done
2023-06-23 18:26:57,293 - root - INFO - i am in the main method...
2023-06-23 18:26:57,293 - root - INFO - Calling  spark object
2023-06-23 18:26:57,294 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:26:57,294 - Create_pyspark - INFO - master is local
2023-06-23 18:27:09,864 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:27:09,864 - root - INFO - Validating spark object 
2023-06-23 18:27:17,052 - root - INFO - Aplication done
2023-06-23 18:30:10,928 - root - INFO - i am in the main method...
2023-06-23 18:30:10,928 - root - INFO - Calling  spark object
2023-06-23 18:30:10,928 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:30:10,929 - Create_pyspark - INFO - master is local
2023-06-23 18:30:22,080 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:30:22,080 - root - INFO - Validating spark object 
2023-06-23 18:30:28,584 - root - INFO - Aplication done
2023-06-23 18:32:16,951 - root - INFO - i am in the main method...
2023-06-23 18:32:16,951 - root - INFO - Calling  spark object
2023-06-23 18:32:16,952 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 18:32:16,952 - Create_pyspark - INFO - master is local
2023-06-23 18:32:27,725 - Create_pyspark - INFO - Spark object created...
2023-06-23 18:32:27,725 - root - INFO - Validating spark object 
2023-06-23 18:32:33,885 - root - INFO - Aplication done
2023-06-23 19:06:00,885 - root - INFO - i am in the main method...
2023-06-23 19:06:00,885 - root - INFO - Calling  spark object
2023-06-23 19:06:00,886 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:06:00,886 - Create_pyspark - INFO - master is local
2023-06-23 19:06:12,147 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:06:12,147 - root - INFO - Validating spark object 
2023-06-23 19:06:12,148 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:06:19,069 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:06:19,070 - Validate - WARNING - Validation  done ...
2023-06-23 19:06:19,070 - root - INFO - reading file which is of > parquet
2023-06-23 19:06:20,221 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:06:21,537 - root - INFO - Aplication done
2023-06-23 19:18:39,481 - root - INFO - i am in the main method...
2023-06-23 19:18:39,482 - root - INFO - Calling  spark object
2023-06-23 19:18:39,482 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:18:39,482 - Create_pyspark - INFO - master is local
2023-06-23 19:18:50,828 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:18:50,829 - root - INFO - Validating spark object 
2023-06-23 19:18:50,829 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:18:59,260 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:18:59,260 - Validate - WARNING - Validation  done ...
2023-06-23 19:18:59,260 - root - INFO - reading file which is of > parquet
2023-06-23 19:19:00,392 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:19:01,892 - root - INFO - validating the dataframe...
2023-06-23 19:19:03,090 - root - INFO - Aplication done
2023-06-23 19:25:11,595 - root - INFO - i am in the main method...
2023-06-23 19:25:11,595 - root - INFO - Calling  spark object
2023-06-23 19:25:11,596 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:25:11,596 - Create_pyspark - INFO - master is local
2023-06-23 19:25:23,583 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:25:23,583 - root - INFO - Validating spark object 
2023-06-23 19:25:23,583 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:25:32,150 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:25:32,150 - Validate - WARNING - Validation  done ...
2023-06-23 19:25:32,151 - root - INFO - reading file which is of > parquet
2023-06-23 19:25:33,195 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:25:34,760 - root - INFO - validating the dataframe...
2023-06-23 19:25:35,846 - root - INFO - Aplication done
2023-06-23 19:26:44,091 - root - INFO - i am in the main method...
2023-06-23 19:26:44,092 - root - INFO - Calling  spark object
2023-06-23 19:26:44,092 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:26:44,092 - Create_pyspark - INFO - master is local
2023-06-23 19:26:55,865 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:26:55,865 - root - INFO - Validating spark object 
2023-06-23 19:26:55,865 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:27:03,573 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:27:03,573 - Validate - WARNING - Validation  done ...
2023-06-23 19:27:03,574 - root - INFO - reading file which is of > parquet
2023-06-23 19:27:04,619 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:27:06,464 - root - INFO - validating the dataframe...
2023-06-23 19:27:07,721 - root - INFO - Aplication done
2023-06-23 19:32:33,039 - root - INFO - i am in the main method...
2023-06-23 19:32:33,039 - root - INFO - Calling  spark object
2023-06-23 19:32:33,039 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:32:33,040 - Create_pyspark - INFO - master is local
2023-06-23 19:32:46,031 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:32:46,031 - root - INFO - Validating spark object 
2023-06-23 19:32:46,031 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:32:54,259 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:32:54,259 - Validate - WARNING - Validation  done ...
2023-06-23 19:32:54,260 - root - INFO - reading file which is of > parquet
2023-06-23 19:32:55,452 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:32:57,149 - root - INFO - validating the dataframe...
2023-06-23 19:32:58,170 - root - INFO - Aplication done
2023-06-23 19:38:40,961 - root - INFO - i am in the main method...
2023-06-23 19:38:40,962 - root - INFO - Calling  spark object
2023-06-23 19:38:40,964 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:38:40,964 - Create_pyspark - INFO - master is local
2023-06-23 19:38:54,083 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:38:54,083 - root - INFO - Validating spark object 
2023-06-23 19:38:54,087 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:39:02,199 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:39:02,199 - Validate - WARNING - Validation  done ...
2023-06-23 19:39:02,200 - root - INFO - reading file which is of > parquet
2023-06-23 19:39:03,733 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:39:05,521 - root - INFO - validating the dataframe...
2023-06-23 19:39:06,596 - root - INFO - Aplication done
2023-06-23 19:49:55,534 - root - INFO - i am in the main method...
2023-06-23 19:49:55,534 - root - INFO - Calling  spark object
2023-06-23 19:49:55,534 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:49:55,535 - Create_pyspark - INFO - master is local
2023-06-23 19:50:09,206 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:50:09,206 - root - INFO - Validating spark object 
2023-06-23 19:50:09,207 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:50:16,733 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:50:16,733 - Validate - WARNING - Validation  done ...
2023-06-23 19:50:16,733 - root - INFO - reading file which is of > parquet
2023-06-23 19:50:16,734 - Ingest - WARNING - load_files method  started...   
2023-06-23 19:50:17,957 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 19:50:17,981 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:50:20,188 - root - INFO - validating the dataframe...
2023-06-23 19:50:20,189 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 19:50:21,185 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 19:50:21,185 - root - INFO - Aplication done
2023-06-23 19:51:56,583 - root - INFO - i am in the main method...
2023-06-23 19:51:56,584 - root - INFO - Calling  spark object
2023-06-23 19:51:56,584 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:51:56,584 - Create_pyspark - INFO - master is local
2023-06-23 19:52:09,294 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:52:09,294 - root - INFO - Validating spark object 
2023-06-23 19:52:09,295 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:52:18,668 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:52:18,668 - Validate - WARNING - Validation  done ...
2023-06-23 19:52:18,669 - root - INFO - reading file which is of > parquet
2023-06-23 19:52:18,669 - Ingest - WARNING - load_files method  started...   
2023-06-23 19:52:19,769 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 19:52:19,791 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:52:21,245 - root - INFO - validating the dataframe...
2023-06-23 19:52:21,245 - Ingest - WARNING - here to count the records in the df_fact
2023-06-23 19:52:22,639 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 19:52:22,640 - root - INFO - Aplication done
2023-06-23 19:54:11,618 - root - INFO - i am in the main method...
2023-06-23 19:54:11,618 - root - INFO - Calling  spark object
2023-06-23 19:54:11,618 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 19:54:11,619 - Create_pyspark - INFO - master is local
2023-06-23 19:54:23,042 - Create_pyspark - INFO - Spark object created...
2023-06-23 19:54:23,042 - root - INFO - Validating spark object 
2023-06-23 19:54:23,046 - Validate - WARNING - started the get_current_date method...
2023-06-23 19:54:30,901 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 19:54:30,901 - Validate - WARNING - Validation  done ...
2023-06-23 19:54:30,901 - root - INFO - reading file which is of > parquet
2023-06-23 19:54:30,901 - Ingest - WARNING - load_files method  started...   
2023-06-23 19:54:31,841 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 19:54:31,866 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 19:54:33,242 - root - INFO - validating the dataframe...
2023-06-23 19:54:33,243 - Ingest - WARNING - here to count the records in the df_fact
2023-06-23 19:54:34,193 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 19:54:34,193 - root - INFO - Aplication done
2023-06-23 23:10:54,743 - root - INFO - i am in the main method...
2023-06-23 23:10:54,744 - root - INFO - Calling  spark object
2023-06-23 23:10:54,744 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 23:10:54,744 - Create_pyspark - INFO - master is local
2023-06-23 23:11:06,670 - Create_pyspark - INFO - Spark object created...
2023-06-23 23:11:06,670 - root - INFO - Validating spark object 
2023-06-23 23:11:06,671 - Validate - WARNING - started the get_current_date method...
2023-06-23 23:11:13,150 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 23:11:13,150 - Validate - WARNING - Validation  done ...
2023-06-23 23:11:13,151 - root - INFO - reading file which is of > parquet
2023-06-23 23:11:13,151 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:11:14,002 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 23:11:14,023 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 23:11:15,205 - root - INFO - validating the dataframe...
2023-06-23 23:11:15,205 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 23:11:15,955 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 23:11:15,955 - root - INFO - checking for the files in the FACT....
2023-06-23 23:11:15,965 - root - INFO - reading file which is of > csv
2023-06-23 23:11:15,965 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:11:15,981 - root - INFO - Aplication done
2023-06-23 23:14:23,860 - root - INFO - i am in the main method...
2023-06-23 23:14:23,861 - root - INFO - Calling  spark object
2023-06-23 23:14:23,861 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 23:14:23,861 - Create_pyspark - INFO - master is local
2023-06-23 23:14:34,816 - Create_pyspark - INFO - Spark object created...
2023-06-23 23:14:34,817 - root - INFO - Validating spark object 
2023-06-23 23:14:34,817 - Validate - WARNING - started the get_current_date method...
2023-06-23 23:14:41,322 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 23:14:41,322 - Validate - WARNING - Validation  done ...
2023-06-23 23:14:41,323 - root - INFO - reading file which is of > parquet
2023-06-23 23:14:41,323 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:14:42,219 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 23:14:42,244 - root - INFO - displaying  the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-23 23:14:43,586 - root - INFO - validating the dataframe...
2023-06-23 23:14:43,589 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 23:14:44,478 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 23:14:44,478 - root - INFO - checking for the files in the FACT....
2023-06-23 23:14:44,480 - root - INFO - reading file which is of > csv
2023-06-23 23:14:44,480 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:14:44,498 - root - INFO - Aplication done
2023-06-23 23:24:46,657 - root - INFO - i am in the main method...
2023-06-23 23:24:46,658 - root - INFO - Calling  spark object
2023-06-23 23:24:46,658 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 23:24:46,658 - Create_pyspark - INFO - master is local
2023-06-23 23:24:58,680 - Create_pyspark - INFO - Spark object created...
2023-06-23 23:24:58,681 - root - INFO - Validating spark object 
2023-06-23 23:24:58,681 - Validate - WARNING - started the get_current_date method...
2023-06-23 23:25:06,524 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 23:25:06,524 - Validate - WARNING - Validation  done ...
2023-06-23 23:25:06,524 - root - INFO - reading file which is of > parquet
2023-06-23 23:25:06,524 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:25:07,715 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 23:25:07,715 - root - INFO - displaying file
2023-06-23 23:25:08,921 - root - INFO - validating the dataframe...
2023-06-23 23:25:08,922 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 23:25:09,741 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 23:25:09,741 - root - INFO - checking for the files in the FACT....
2023-06-23 23:25:09,758 - root - INFO - reading file which is of > csv
2023-06-23 23:25:09,760 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:25:09,778 - root - INFO - Aplication done
2023-06-23 23:28:05,537 - root - INFO - i am in the main method...
2023-06-23 23:28:05,537 - root - INFO - Calling  spark object
2023-06-23 23:28:05,537 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 23:28:05,537 - Create_pyspark - INFO - master is local
2023-06-23 23:28:15,928 - Create_pyspark - INFO - Spark object created...
2023-06-23 23:28:15,928 - root - INFO - Validating spark object 
2023-06-23 23:28:15,928 - Validate - WARNING - started the get_current_date method...
2023-06-23 23:28:22,455 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 23:28:22,455 - Validate - WARNING - Validation  done ...
2023-06-23 23:28:22,456 - root - INFO - reading file which is of > parquet
2023-06-23 23:28:22,456 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:28:23,329 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 23:28:23,329 - root - INFO - displaying file
2023-06-23 23:28:24,828 - root - INFO - validating the dataframe...
2023-06-23 23:28:24,828 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 23:28:25,670 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 23:28:25,670 - root - INFO - checking for the files in the FACT....
2023-06-23 23:28:25,676 - root - INFO - reading file which is of > csv
2023-06-23 23:28:25,676 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:28:25,693 - root - INFO - Aplication done
2023-06-23 23:33:13,502 - root - INFO - i am in the main method...
2023-06-23 23:33:13,502 - root - INFO - Calling  spark object
2023-06-23 23:33:13,502 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 23:33:13,502 - Create_pyspark - INFO - master is local
2023-06-23 23:33:24,912 - Create_pyspark - INFO - Spark object created...
2023-06-23 23:33:24,912 - root - INFO - Validating spark object 
2023-06-23 23:33:24,913 - Validate - WARNING - started the get_current_date method...
2023-06-23 23:33:31,276 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 23:33:31,277 - Validate - WARNING - Validation  done ...
2023-06-23 23:33:31,277 - root - INFO - reading file which is of > parquet
2023-06-23 23:33:31,278 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:33:32,012 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 23:33:32,012 - root - INFO - displaying file
2023-06-23 23:33:33,236 - root - INFO - validating the dataframe...
2023-06-23 23:33:33,236 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 23:33:34,068 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 23:33:34,068 - root - INFO - checking for the files in the FACT....
2023-06-23 23:33:34,072 - root - INFO - reading file which is of > csv
2023-06-23 23:33:34,074 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:33:39,691 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-23 23:33:39,692 - root - INFO - displaying the df_fact dataframe
2023-06-23 23:33:40,066 - Ingest - WARNING - here to count the records in the df_fact
2023-06-23 23:33:41,189 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-23 23:33:41,190 - root - INFO - Aplication done
2023-06-23 23:34:02,631 - root - INFO - i am in the main method...
2023-06-23 23:34:02,635 - root - INFO - Calling  spark object
2023-06-23 23:34:02,637 - Create_pyspark - INFO - get_spark_object method started
2023-06-23 23:34:02,637 - Create_pyspark - INFO - master is local
2023-06-23 23:34:13,512 - Create_pyspark - INFO - Spark object created...
2023-06-23 23:34:13,512 - root - INFO - Validating spark object 
2023-06-23 23:34:13,513 - Validate - WARNING - started the get_current_date method...
2023-06-23 23:34:19,831 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 23))]
2023-06-23 23:34:19,831 - Validate - WARNING - Validation  done ...
2023-06-23 23:34:19,832 - root - INFO - reading file which is of > parquet
2023-06-23 23:34:19,832 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:34:20,702 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-23 23:34:20,703 - root - INFO - displaying file
2023-06-23 23:34:21,968 - root - INFO - validating the dataframe...
2023-06-23 23:34:21,969 - Ingest - WARNING - here to count the records in the df_city
2023-06-23 23:34:22,748 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-23 23:34:22,748 - root - INFO - checking for the files in the FACT....
2023-06-23 23:34:22,750 - root - INFO - reading file which is of > csv
2023-06-23 23:34:22,751 - Ingest - WARNING - load_files method  started...   
2023-06-23 23:34:28,310 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-23 23:34:28,310 - root - INFO - displaying the df_fact dataframe
2023-06-23 23:34:28,661 - Ingest - WARNING - here to count the records in the df_fact
2023-06-23 23:34:29,781 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-23 23:34:29,781 - root - INFO - Aplication done
2023-06-24 01:17:20,904 - root - INFO - i am in the main method...
2023-06-24 01:17:20,905 - root - INFO - Calling  spark object
2023-06-24 01:17:20,905 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 01:17:20,905 - Create_pyspark - INFO - master is local
2023-06-24 01:17:31,603 - Create_pyspark - INFO - Spark object created...
2023-06-24 01:17:31,603 - root - INFO - Validating spark object 
2023-06-24 01:17:31,603 - Validate - WARNING - started the get_current_date method...
2023-06-24 01:17:37,529 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 01:17:37,529 - Validate - WARNING - Validation  done ...
2023-06-24 01:17:37,530 - root - INFO - reading file which is of > parquet
2023-06-24 01:17:37,530 - Ingest - WARNING - load_files method  started...   
2023-06-24 01:17:38,458 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 01:17:38,458 - root - INFO - displaying file
2023-06-24 01:17:39,672 - root - INFO - validating the dataframe...
2023-06-24 01:17:39,673 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 01:17:40,421 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 01:17:40,422 - root - INFO - checking for the files in the FACT....
2023-06-24 01:17:40,422 - root - INFO - reading file which is of > csv
2023-06-24 01:17:40,423 - Ingest - WARNING - load_files method  started...   
2023-06-24 01:17:45,733 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 01:17:45,734 - root - INFO - displaying the df_fact dataframe
2023-06-24 01:17:46,112 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 01:17:47,138 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 01:17:47,138 - root - INFO - implementing data_processing methods...
2023-06-24 01:17:47,148 - Data_processing - WARNING - data_clean method() start...
2023-06-24 01:17:47,148 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 01:17:47,218 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 01:17:47,249 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 01:17:47,764 - root - INFO - Aplication done
2023-06-24 01:28:24,221 - root - INFO - i am in the main method...
2023-06-24 01:28:24,221 - root - INFO - Calling  spark object
2023-06-24 01:28:24,221 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 01:28:24,221 - Create_pyspark - INFO - master is local
2023-06-24 01:28:35,272 - Create_pyspark - INFO - Spark object created...
2023-06-24 01:28:35,272 - root - INFO - Validating spark object 
2023-06-24 01:28:35,272 - Validate - WARNING - started the get_current_date method...
2023-06-24 01:28:42,251 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 01:28:42,252 - Validate - WARNING - Validation  done ...
2023-06-24 01:28:42,252 - root - INFO - reading file which is of > parquet
2023-06-24 01:28:42,253 - Ingest - WARNING - load_files method  started...   
2023-06-24 01:28:43,364 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 01:28:43,365 - root - INFO - displaying file
2023-06-24 01:28:44,864 - root - INFO - validating the dataframe...
2023-06-24 01:28:44,864 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 01:28:45,748 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 01:28:45,749 - root - INFO - checking for the files in the FACT....
2023-06-24 01:28:45,764 - root - INFO - reading file which is of > csv
2023-06-24 01:28:45,767 - Ingest - WARNING - load_files method  started...   
2023-06-24 01:28:52,777 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 01:28:52,777 - root - INFO - displaying the df_fact dataframe
2023-06-24 01:28:53,329 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 01:28:54,649 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 01:28:54,649 - root - INFO - implementing data_processing methods...
2023-06-24 01:28:54,662 - Data_processing - WARNING - data_clean method() start...
2023-06-24 01:28:54,662 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 01:28:54,728 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 01:28:54,755 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 01:28:54,772 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 01:28:55,347 - root - INFO - Aplication done
2023-06-24 01:40:06,102 - root - INFO - i am in the main method...
2023-06-24 01:40:06,102 - root - INFO - Calling  spark object
2023-06-24 01:40:06,102 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 01:40:06,102 - Create_pyspark - INFO - master is local
2023-06-24 01:40:16,917 - Create_pyspark - INFO - Spark object created...
2023-06-24 01:40:16,918 - root - INFO - Validating spark object 
2023-06-24 01:40:16,918 - Validate - WARNING - started the get_current_date method...
2023-06-24 01:40:22,919 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 01:40:22,919 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 01:40:22,920 - root - INFO - reading file which is of > parquet
2023-06-24 01:40:22,920 - Ingest - WARNING - load_files method  started...   
2023-06-24 01:40:23,696 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 01:40:23,696 - root - INFO - displaying file
2023-06-24 01:40:24,920 - root - INFO - validating the dataframe...
2023-06-24 01:40:24,920 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 01:40:25,674 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 01:40:25,674 - root - INFO - checking for the files in the FACT....
2023-06-24 01:40:25,675 - root - INFO - reading file which is of > csv
2023-06-24 01:40:25,675 - Ingest - WARNING - load_files method  started...   
2023-06-24 01:40:30,891 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 01:40:30,891 - root - INFO - displaying the df_fact dataframe
2023-06-24 01:40:31,316 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 01:40:32,468 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 01:40:32,468 - root - INFO - implementing data_processing methods...
2023-06-24 01:40:32,472 - Data_processing - WARNING - data_clean method() start...
2023-06-24 01:40:32,472 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 01:40:32,522 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 01:40:32,547 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 01:40:32,560 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 01:40:33,016 - root - INFO - validating  schema for the dataframe...
2023-06-24 01:40:33,016 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 01:40:33,017 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 01:40:33,018 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 01:40:33,018 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 01:40:33,018 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 01:40:33,018 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 01:40:33,018 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 01:40:33,018 - Validate - INFO - print_schema done, go frwd...
2023-06-24 01:40:33,018 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 01:40:33,020 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-24 01:40:33,020 - Validate - INFO - 	StructField('presc_lname', StringType(), True)
2023-06-24 01:40:33,020 - Validate - INFO - 	StructField('presc_fname', StringType(), True)
2023-06-24 01:40:33,020 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-24 01:40:33,020 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('years_of_exp', StringType(), True)
2023-06-24 01:40:33,021 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-24 01:40:33,021 - Validate - INFO - print_schema done, go frwd...
2023-06-24 01:40:33,021 - root - INFO - Aplication done
2023-06-24 16:01:04,337 - root - INFO - i am in the main method...
2023-06-24 16:01:04,339 - root - INFO - Calling  spark object
2023-06-24 16:01:04,339 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 16:01:04,339 - Create_pyspark - INFO - master is local
2023-06-24 16:01:16,730 - Create_pyspark - INFO - Spark object created...
2023-06-24 16:01:16,730 - root - INFO - Validating spark object 
2023-06-24 16:01:16,731 - Validate - WARNING - started the get_current_date method...
2023-06-24 16:01:23,996 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 16:01:23,996 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 16:01:23,996 - root - INFO - reading file which is of > parquet
2023-06-24 16:01:23,997 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:01:25,074 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 16:01:25,074 - root - INFO - displaying file
2023-06-24 16:01:26,257 - root - INFO - validating the dataframe...
2023-06-24 16:01:26,258 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 16:01:27,052 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 16:01:27,052 - root - INFO - checking for the files in the FACT....
2023-06-24 16:01:27,067 - root - INFO - reading file which is of > csv
2023-06-24 16:01:27,068 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:01:32,745 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 16:01:32,745 - root - INFO - displaying the df_fact dataframe
2023-06-24 16:01:33,206 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 16:01:34,331 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 16:01:34,332 - root - INFO - implementing data_processing methods...
2023-06-24 16:01:34,347 - Data_processing - WARNING - data_clean method() start...
2023-06-24 16:01:34,347 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 16:01:34,408 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 16:01:34,437 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 16:01:34,449 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-24 16:01:34,489 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 16:01:35,076 - root - INFO - validating  schema for the dataframe...
2023-06-24 16:01:35,090 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 16:01:35,093 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 16:01:35,093 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 16:01:35,094 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 16:01:35,094 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 16:01:35,094 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 16:01:35,094 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 16:01:35,095 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:01:35,095 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 16:01:35,096 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-24 16:01:35,096 - Validate - INFO - 	StructField('presc_lname', StringType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('presc_fname', StringType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-24 16:01:35,097 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-24 16:01:35,097 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:01:35,098 - root - INFO - Aplication done
2023-06-24 16:09:42,580 - root - INFO - i am in the main method...
2023-06-24 16:09:42,580 - root - INFO - Calling  spark object
2023-06-24 16:09:42,580 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 16:09:42,580 - Create_pyspark - INFO - master is local
2023-06-24 16:09:53,094 - Create_pyspark - INFO - Spark object created...
2023-06-24 16:09:53,094 - root - INFO - Validating spark object 
2023-06-24 16:09:53,094 - Validate - WARNING - started the get_current_date method...
2023-06-24 16:09:59,428 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 16:09:59,428 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 16:09:59,429 - root - INFO - reading file which is of > parquet
2023-06-24 16:09:59,429 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:10:00,315 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 16:10:00,315 - root - INFO - displaying file
2023-06-24 16:10:01,555 - root - INFO - validating the dataframe...
2023-06-24 16:10:01,555 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 16:10:02,321 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 16:10:02,321 - root - INFO - checking for the files in the FACT....
2023-06-24 16:10:02,322 - root - INFO - reading file which is of > csv
2023-06-24 16:10:02,322 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:10:07,478 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 16:10:07,478 - root - INFO - displaying the df_fact dataframe
2023-06-24 16:10:07,903 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 16:10:09,011 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 16:10:09,011 - root - INFO - implementing data_processing methods...
2023-06-24 16:10:09,013 - Data_processing - WARNING - data_clean method() start...
2023-06-24 16:10:09,013 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 16:10:09,058 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 16:10:09,080 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 16:10:09,096 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-24 16:10:09,129 - Data_processing - WARNING - concat first and lname
2023-06-24 16:10:09,161 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-24 16:10:09,174 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 16:10:09,854 - root - INFO - validating  schema for the dataframe...
2023-06-24 16:10:09,854 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 16:10:09,856 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 16:10:09,856 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 16:10:09,856 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 16:10:09,856 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 16:10:09,856 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 16:10:09,856 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 16:10:09,857 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:10:09,857 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 16:10:09,858 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-24 16:10:09,858 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-24 16:10:09,859 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-24 16:10:09,859 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:10:09,860 - root - INFO - Aplication done
2023-06-24 16:24:39,145 - root - INFO - i am in the main method...
2023-06-24 16:24:39,145 - root - INFO - Calling  spark object
2023-06-24 16:24:39,146 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 16:24:39,146 - Create_pyspark - INFO - master is local
2023-06-24 16:24:51,192 - Create_pyspark - INFO - Spark object created...
2023-06-24 16:24:51,192 - root - INFO - Validating spark object 
2023-06-24 16:24:51,192 - Validate - WARNING - started the get_current_date method...
2023-06-24 16:24:57,830 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 16:24:57,830 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 16:24:57,831 - root - INFO - reading file which is of > parquet
2023-06-24 16:24:57,832 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:24:59,143 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 16:24:59,144 - root - INFO - displaying file
2023-06-24 16:25:00,742 - root - INFO - validating the dataframe...
2023-06-24 16:25:00,743 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 16:25:01,566 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 16:25:01,567 - root - INFO - checking for the files in the FACT....
2023-06-24 16:25:01,584 - root - INFO - reading file which is of > csv
2023-06-24 16:25:01,585 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:25:07,394 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 16:25:07,394 - root - INFO - displaying the df_fact dataframe
2023-06-24 16:25:07,850 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 16:25:08,980 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 16:25:08,980 - root - INFO - implementing data_processing methods...
2023-06-24 16:25:08,983 - Data_processing - WARNING - data_clean method() start...
2023-06-24 16:25:08,983 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 16:25:09,040 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 16:25:09,061 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 16:25:09,077 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-24 16:25:09,115 - Data_processing - WARNING - concat first and lname
2023-06-24 16:25:09,147 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-24 16:25:09,160 - Data_processing - WARNING - now check for null values in all columns
2023-06-24 16:25:09,430 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-24 16:25:09,482 - Data_processing - WARNING - successfully droped the null values...
2023-06-24 16:25:09,482 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 16:25:35,661 - root - INFO - validating  schema for the dataframe...
2023-06-24 16:25:35,662 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 16:25:35,663 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 16:25:35,663 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 16:25:35,663 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 16:25:35,663 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 16:25:35,663 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 16:25:35,664 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 16:25:35,664 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:25:35,664 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 16:25:35,665 - Validate - INFO - 	StructField('presc_id', LongType(), False)
2023-06-24 16:25:35,665 - Validate - INFO - 	StructField('presc_city', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('presc_state', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('presc_spclt', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('drug_name', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('tx_cnt', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('total_day_supply', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('total_drug_cost', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('years_of_exp', LongType(), False)
2023-06-24 16:25:35,666 - Validate - INFO - 	StructField('Country_name', LongType(), False)
2023-06-24 16:25:35,667 - Validate - INFO - 	StructField('presc_fullname', LongType(), False)
2023-06-24 16:25:35,667 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:25:35,667 - root - INFO - Aplication done
2023-06-24 16:26:17,070 - root - INFO - i am in the main method...
2023-06-24 16:26:17,070 - root - INFO - Calling  spark object
2023-06-24 16:26:17,070 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 16:26:17,070 - Create_pyspark - INFO - master is local
2023-06-24 16:26:28,339 - Create_pyspark - INFO - Spark object created...
2023-06-24 16:26:28,339 - root - INFO - Validating spark object 
2023-06-24 16:26:28,340 - Validate - WARNING - started the get_current_date method...
2023-06-24 16:26:36,894 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 16:26:36,894 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 16:26:36,894 - root - INFO - reading file which is of > parquet
2023-06-24 16:26:36,894 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:26:37,893 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 16:26:37,893 - root - INFO - displaying file
2023-06-24 16:26:39,178 - root - INFO - validating the dataframe...
2023-06-24 16:26:39,184 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 16:26:40,012 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 16:26:40,012 - root - INFO - checking for the files in the FACT....
2023-06-24 16:26:40,014 - root - INFO - reading file which is of > csv
2023-06-24 16:26:40,014 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:26:46,567 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 16:26:46,567 - root - INFO - displaying the df_fact dataframe
2023-06-24 16:26:46,976 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 16:26:48,098 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 16:26:48,098 - root - INFO - implementing data_processing methods...
2023-06-24 16:26:48,107 - Data_processing - WARNING - data_clean method() start...
2023-06-24 16:26:48,107 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 16:26:48,168 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 16:26:48,198 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 16:26:48,215 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-24 16:26:48,259 - Data_processing - WARNING - concat first and lname
2023-06-24 16:26:48,293 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-24 16:26:48,308 - Data_processing - WARNING - now check for null values in all columns
2023-06-24 16:26:48,534 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-24 16:26:48,583 - Data_processing - WARNING - successfully droped the null values...
2023-06-24 16:26:48,583 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 16:27:10,993 - root - INFO - validating  schema for the dataframe...
2023-06-24 16:27:10,995 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 16:27:10,997 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 16:27:10,997 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 16:27:10,997 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 16:27:10,997 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 16:27:10,997 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 16:27:10,997 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 16:27:10,998 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:27:10,998 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 16:27:10,999 - Validate - INFO - 	StructField('presc_id', LongType(), False)
2023-06-24 16:27:10,999 - Validate - INFO - 	StructField('presc_city', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('presc_state', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('presc_spclt', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('drug_name', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('tx_cnt', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('total_day_supply', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('total_drug_cost', LongType(), False)
2023-06-24 16:27:11,000 - Validate - INFO - 	StructField('years_of_exp', LongType(), False)
2023-06-24 16:27:11,001 - Validate - INFO - 	StructField('Country_name', LongType(), False)
2023-06-24 16:27:11,001 - Validate - INFO - 	StructField('presc_fullname', LongType(), False)
2023-06-24 16:27:11,001 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:27:11,001 - root - INFO - Aplication done
2023-06-24 16:28:49,123 - root - INFO - i am in the main method...
2023-06-24 16:28:49,124 - root - INFO - Calling  spark object
2023-06-24 16:28:49,124 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 16:28:49,124 - Create_pyspark - INFO - master is local
2023-06-24 16:29:00,625 - Create_pyspark - INFO - Spark object created...
2023-06-24 16:29:00,625 - root - INFO - Validating spark object 
2023-06-24 16:29:00,625 - Validate - WARNING - started the get_current_date method...
2023-06-24 16:29:07,476 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 16:29:07,476 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 16:29:07,477 - root - INFO - reading file which is of > parquet
2023-06-24 16:29:07,477 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:29:08,522 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 16:29:08,522 - root - INFO - displaying file
2023-06-24 16:29:10,124 - root - INFO - validating the dataframe...
2023-06-24 16:29:10,126 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 16:29:10,989 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 16:29:10,989 - root - INFO - checking for the files in the FACT....
2023-06-24 16:29:10,990 - root - INFO - reading file which is of > csv
2023-06-24 16:29:10,991 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:29:17,010 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 16:29:17,010 - root - INFO - displaying the df_fact dataframe
2023-06-24 16:29:17,557 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 16:29:18,741 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 16:29:18,742 - root - INFO - implementing data_processing methods...
2023-06-24 16:29:18,749 - Data_processing - WARNING - data_clean method() start...
2023-06-24 16:29:18,749 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 16:29:18,815 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 16:29:18,848 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 16:29:18,863 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-24 16:29:18,921 - Data_processing - WARNING - concat first and lname
2023-06-24 16:29:18,952 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-24 16:29:18,965 - Data_processing - WARNING - now check for null values in all columns
2023-06-24 16:29:19,226 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-24 16:29:19,270 - Data_processing - WARNING - successfully droped the null values...
2023-06-24 16:29:19,270 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 16:29:47,682 - root - INFO - validating  schema for the dataframe...
2023-06-24 16:29:47,683 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 16:29:47,685 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 16:29:47,685 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 16:29:47,686 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 16:29:47,686 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 16:29:47,686 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 16:29:47,686 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 16:29:47,686 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:29:47,686 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 16:29:47,687 - Validate - INFO - 	StructField('presc_id', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('presc_city', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('presc_state', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('presc_spclt', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('drug_name', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('tx_cnt', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('total_day_supply', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('total_drug_cost', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('years_of_exp', LongType(), False)
2023-06-24 16:29:47,688 - Validate - INFO - 	StructField('Country_name', LongType(), False)
2023-06-24 16:29:47,689 - Validate - INFO - 	StructField('presc_fullname', LongType(), False)
2023-06-24 16:29:47,689 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:29:47,689 - root - INFO - Aplication done
2023-06-24 16:31:21,178 - root - INFO - i am in the main method...
2023-06-24 16:31:21,180 - root - INFO - Calling  spark object
2023-06-24 16:31:21,180 - Create_pyspark - INFO - get_spark_object method started
2023-06-24 16:31:21,180 - Create_pyspark - INFO - master is local
2023-06-24 16:31:32,903 - Create_pyspark - INFO - Spark object created...
2023-06-24 16:31:32,903 - root - INFO - Validating spark object 
2023-06-24 16:31:32,903 - Validate - WARNING - started the get_current_date method...
2023-06-24 16:31:40,537 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 24))]
2023-06-24 16:31:40,537 - Validate - WARNING - Validation  done , go frwd...
2023-06-24 16:31:40,537 - root - INFO - reading file which is of > parquet
2023-06-24 16:31:40,538 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:31:41,525 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-24 16:31:41,525 - root - INFO - displaying file
2023-06-24 16:31:43,083 - root - INFO - validating the dataframe...
2023-06-24 16:31:43,083 - Ingest - WARNING - here to count the records in the df_city
2023-06-24 16:31:44,054 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-24 16:31:44,054 - root - INFO - checking for the files in the FACT....
2023-06-24 16:31:44,063 - root - INFO - reading file which is of > csv
2023-06-24 16:31:44,064 - Ingest - WARNING - load_files method  started...   
2023-06-24 16:31:51,908 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-24 16:31:51,908 - root - INFO - displaying the df_fact dataframe
2023-06-24 16:31:52,435 - Ingest - WARNING - here to count the records in the df_fact
2023-06-24 16:31:53,903 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-24 16:31:53,903 - root - INFO - implementing data_processing methods...
2023-06-24 16:31:53,915 - Data_processing - WARNING - data_clean method() start...
2023-06-24 16:31:53,915 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-24 16:31:53,968 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-24 16:31:53,985 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-24 16:31:53,996 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-24 16:31:54,029 - Data_processing - WARNING - concat first and lname
2023-06-24 16:31:54,057 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-24 16:31:54,068 - Data_processing - WARNING - now check for null values in all columns
2023-06-24 16:31:54,346 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-24 16:31:54,684 - Data_processing - WARNING - successfully droped the null values...
2023-06-24 16:31:54,684 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-24 16:32:19,446 - root - INFO - validating  schema for the dataframe...
2023-06-24 16:32:19,448 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-24 16:32:19,449 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-24 16:32:19,449 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-24 16:32:19,450 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-24 16:32:19,450 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-24 16:32:19,450 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-24 16:32:19,450 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-24 16:32:19,450 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:32:19,450 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-24 16:32:19,452 - Validate - INFO - 	StructField('presc_id', LongType(), False)
2023-06-24 16:32:19,452 - Validate - INFO - 	StructField('presc_city', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('presc_state', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('presc_spclt', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('drug_name', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('tx_cnt', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('total_day_supply', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('total_drug_cost', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('years_of_exp', LongType(), False)
2023-06-24 16:32:19,453 - Validate - INFO - 	StructField('Country_name', LongType(), False)
2023-06-24 16:32:19,454 - Validate - INFO - 	StructField('presc_fullname', LongType(), False)
2023-06-24 16:32:19,454 - Validate - INFO - print_schema done, go frwd...
2023-06-24 16:32:19,454 - root - INFO - Aplication done
2023-06-25 12:18:06,878 - root - INFO - i am in the main method...
2023-06-25 12:18:06,879 - root - INFO - Calling  spark object
2023-06-25 12:18:06,880 - Create_pyspark - INFO - get_spark_object method started
2023-06-25 12:18:06,880 - Create_pyspark - INFO - master is local
2023-06-25 12:18:18,196 - Create_pyspark - INFO - Spark object created...
2023-06-25 12:18:18,196 - root - INFO - Validating spark object 
2023-06-25 12:18:18,197 - Validate - WARNING - started the get_current_date method...
2023-06-25 12:18:24,414 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 25))]
2023-06-25 12:18:24,414 - Validate - WARNING - Validation  done , go frwd...
2023-06-25 12:18:24,414 - root - INFO - reading file which is of > parquet
2023-06-25 12:18:24,415 - Ingest - WARNING - load_files method  started...   
2023-06-25 12:18:25,299 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-25 12:18:25,300 - root - INFO - displaying file
2023-06-25 12:18:26,478 - root - INFO - validating the dataframe...
2023-06-25 12:18:26,479 - Ingest - WARNING - here to count the records in the df_city
2023-06-25 12:18:27,240 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-25 12:18:27,241 - root - INFO - checking for the files in the FACT....
2023-06-25 12:18:27,242 - root - INFO - reading file which is of > csv
2023-06-25 12:18:27,243 - Ingest - WARNING - load_files method  started...   
2023-06-25 12:18:32,413 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-25 12:18:32,413 - root - INFO - displaying the df_fact dataframe
2023-06-25 12:18:32,808 - Ingest - WARNING - here to count the records in the df_fact
2023-06-25 12:18:33,827 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-25 12:18:33,827 - root - INFO - implementing data_processing methods...
2023-06-25 12:18:33,833 - Data_processing - WARNING - data_clean method() start...
2023-06-25 12:18:33,833 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-25 12:18:33,884 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-25 12:18:33,912 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-25 12:18:33,925 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-25 12:18:33,950 - Data_processing - WARNING - concat first and lname
2023-06-25 12:18:33,981 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-25 12:18:33,997 - Data_processing - WARNING - now check for null values in all columns
2023-06-25 12:18:33,997 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-25 12:18:34,013 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-25 12:18:37,581 - Data_processing - WARNING - successfully droped the null values...
2023-06-25 12:18:37,581 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-25 12:18:38,036 - root - INFO - validating  schema for the dataframe...
2023-06-25 12:18:38,037 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-25 12:18:38,038 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-25 12:18:38,038 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-25 12:18:38,038 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-25 12:18:38,038 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-25 12:18:38,038 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-25 12:18:38,038 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-25 12:18:38,039 - Validate - INFO - print_schema done, go frwd...
2023-06-25 12:18:38,039 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-25 12:18:38,040 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-25 12:18:38,040 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-25 12:18:38,040 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-25 12:18:38,040 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-25 12:18:38,041 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-25 12:18:38,041 - Validate - INFO - print_schema done, go frwd...
2023-06-25 12:18:38,254 - root - INFO - checking for null values in dataframe ...after processing
2023-06-25 12:18:38,254 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-25 12:18:38,427 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-25 12:18:56,976 - root - INFO - Aplication done
2023-06-25 12:30:13,799 - root - INFO - i am in the main method...
2023-06-25 12:30:13,800 - root - INFO - Calling  spark object
2023-06-25 12:30:13,800 - Create_pyspark - INFO - get_spark_object method started
2023-06-25 12:30:13,800 - Create_pyspark - INFO - master is local
2023-06-25 12:30:24,966 - Create_pyspark - INFO - Spark object created...
2023-06-25 12:30:24,966 - root - INFO - Validating spark object 
2023-06-25 12:30:24,966 - Validate - WARNING - started the get_current_date method...
2023-06-25 12:30:32,153 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 25))]
2023-06-25 12:30:32,153 - Validate - WARNING - Validation  done , go frwd...
2023-06-25 12:30:32,154 - root - INFO - reading file which is of > parquet
2023-06-25 12:30:32,154 - Ingest - WARNING - load_files method  started...   
2023-06-25 12:30:33,018 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-25 12:30:33,019 - root - INFO - displaying file
2023-06-25 12:30:34,399 - root - INFO - validating the dataframe...
2023-06-25 12:30:34,399 - Ingest - WARNING - here to count the records in the df_city
2023-06-25 12:30:35,279 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-25 12:30:35,279 - root - INFO - checking for the files in the FACT....
2023-06-25 12:30:35,285 - root - INFO - reading file which is of > csv
2023-06-25 12:30:35,286 - Ingest - WARNING - load_files method  started...   
2023-06-25 12:30:41,877 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-25 12:30:41,878 - root - INFO - displaying the df_fact dataframe
2023-06-25 12:30:42,312 - Ingest - WARNING - here to count the records in the df_fact
2023-06-25 12:30:43,642 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-25 12:30:43,642 - root - INFO - implementing data_processing methods...
2023-06-25 12:30:43,652 - Data_processing - WARNING - data_clean method() start...
2023-06-25 12:30:43,652 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-25 12:30:43,712 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-25 12:30:43,736 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-25 12:30:43,755 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-25 12:30:43,808 - Data_processing - WARNING - concat first and lname
2023-06-25 12:30:43,852 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-25 12:30:43,882 - Data_processing - WARNING - now check for null values in all columns
2023-06-25 12:30:43,882 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-25 12:30:43,931 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-25 12:30:48,058 - Data_processing - WARNING - successfully droped the null values...
2023-06-25 12:30:48,058 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-25 12:30:48,682 - root - INFO - validating  schema for the dataframe...
2023-06-25 12:30:48,682 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-25 12:30:48,684 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-25 12:30:48,684 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-25 12:30:48,684 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-25 12:30:48,684 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-25 12:30:48,684 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-25 12:30:48,685 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-25 12:30:48,685 - Validate - INFO - print_schema done, go frwd...
2023-06-25 12:30:48,685 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-25 12:30:48,686 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-25 12:30:48,687 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-25 12:30:48,688 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-25 12:30:48,688 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-25 12:30:48,688 - Validate - INFO - print_schema done, go frwd...
2023-06-25 12:30:48,944 - root - INFO - checking for null values in dataframe ...after processing
2023-06-25 12:30:48,944 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-25 12:30:49,151 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-25 12:31:14,381 - root - INFO - data_transformation executing...
2023-06-25 12:31:14,399 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-25 12:31:14,402 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-25 12:31:14,486 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-25 12:31:14,554 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-25 12:31:14,624 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-25 12:31:14,625 - root - INFO - displaying the df_report_1
2023-06-25 12:31:28,922 - root - INFO - Aplication done
2023-06-26 17:29:01,547 - root - INFO - i am in the main method...
2023-06-26 17:29:01,552 - root - INFO - Calling  spark object
2023-06-26 17:29:01,563 - Create_pyspark - INFO - get_spark_object method started
2023-06-26 17:29:01,563 - Create_pyspark - INFO - master is local
2023-06-26 17:29:15,396 - Create_pyspark - INFO - Spark object created...
2023-06-26 17:29:15,396 - root - INFO - Validating spark object 
2023-06-26 17:29:15,396 - Validate - WARNING - started the get_current_date method...
2023-06-26 17:29:29,785 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 26))]
2023-06-26 17:29:29,785 - Validate - WARNING - Validation  done , go frwd...
2023-06-26 17:29:29,785 - root - INFO - reading file which is of > parquet
2023-06-26 17:29:29,786 - Ingest - WARNING - load_files method  started...   
2023-06-26 17:29:31,912 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-26 17:29:31,912 - root - INFO - displaying file
2023-06-26 17:29:34,062 - root - INFO - validating the dataframe...
2023-06-26 17:29:34,062 - Ingest - WARNING - here to count the records in the df_city
2023-06-26 17:29:35,052 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-26 17:29:35,052 - root - INFO - checking for the files in the FACT....
2023-06-26 17:29:35,054 - root - INFO - reading file which is of > csv
2023-06-26 17:29:35,054 - Ingest - WARNING - load_files method  started...   
2023-06-26 17:29:40,824 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-26 17:29:40,825 - root - INFO - displaying the df_fact dataframe
2023-06-26 17:29:41,291 - Ingest - WARNING - here to count the records in the df_fact
2023-06-26 17:29:42,513 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-26 17:29:42,513 - root - INFO - implementing data_processing methods...
2023-06-26 17:29:42,522 - Data_processing - WARNING - data_clean method() start...
2023-06-26 17:29:42,522 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-26 17:29:42,591 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-26 17:29:42,609 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-26 17:29:42,625 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-26 17:29:42,661 - Data_processing - WARNING - concat first and lname
2023-06-26 17:29:42,695 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-26 17:29:42,707 - Data_processing - WARNING - now check for null values in all columns
2023-06-26 17:29:42,708 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-26 17:29:42,739 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-26 17:29:46,725 - Data_processing - WARNING - successfully droped the null values...
2023-06-26 17:29:46,725 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-26 17:29:47,536 - root - INFO - validating  schema for the dataframe...
2023-06-26 17:29:47,536 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-26 17:29:47,538 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-26 17:29:47,538 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-26 17:29:47,538 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-26 17:29:47,538 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-26 17:29:47,539 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-26 17:29:47,539 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-26 17:29:47,539 - Validate - INFO - print_schema done, go frwd...
2023-06-26 17:29:47,539 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-26 17:29:47,541 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-26 17:29:47,541 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-26 17:29:47,541 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-26 17:29:47,541 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-26 17:29:47,541 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-26 17:29:47,542 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-26 17:29:47,542 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-26 17:29:47,542 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-26 17:29:47,542 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-26 17:29:47,542 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-26 17:29:47,542 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-26 17:29:47,542 - Validate - INFO - print_schema done, go frwd...
2023-06-26 17:29:47,822 - root - INFO - checking for null values in dataframe ...after processing
2023-06-26 17:29:47,822 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-26 17:29:48,205 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-26 17:30:12,863 - root - INFO - data_transformation executing...
2023-06-26 17:30:12,864 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-26 17:30:12,865 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-26 17:30:12,929 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-26 17:30:12,977 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-26 17:30:13,040 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-26 17:30:13,040 - root - INFO - displaying the df_report_1
2023-06-26 17:30:23,143 - root - INFO - Aplication done
2023-06-27 16:34:24,098 - root - INFO - i am in the main method...
2023-06-27 16:34:24,099 - root - INFO - Calling  spark object
2023-06-27 16:34:24,099 - Create_pyspark - INFO - get_spark_object method started
2023-06-27 16:34:24,099 - Create_pyspark - INFO - master is local
2023-06-27 16:34:36,731 - Create_pyspark - INFO - Spark object created...
2023-06-27 16:34:36,731 - root - INFO - Validating spark object 
2023-06-27 16:34:36,731 - Validate - WARNING - started the get_current_date method...
2023-06-27 16:34:44,429 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 27))]
2023-06-27 16:34:44,429 - Validate - WARNING - Validation  done , go frwd...
2023-06-27 16:34:44,430 - root - INFO - reading file which is of > parquet
2023-06-27 16:34:44,430 - Ingest - WARNING - load_files method  started...   
2023-06-27 16:34:45,837 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-27 16:34:45,838 - root - INFO - displaying file
2023-06-27 16:34:47,643 - root - INFO - validating the dataframe...
2023-06-27 16:34:47,644 - Ingest - WARNING - here to count the records in the df_city
2023-06-27 16:34:48,765 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-27 16:34:48,765 - root - INFO - checking for the files in the FACT....
2023-06-27 16:34:48,774 - root - INFO - reading file which is of > csv
2023-06-27 16:34:48,774 - Ingest - WARNING - load_files method  started...   
2023-06-27 16:34:56,327 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-27 16:34:56,328 - root - INFO - displaying the df_fact dataframe
2023-06-27 16:34:57,160 - Ingest - WARNING - here to count the records in the df_fact
2023-06-27 16:34:58,988 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-27 16:34:58,989 - root - INFO - implementing data_processing methods...
2023-06-27 16:34:58,996 - Data_processing - WARNING - data_clean method() start...
2023-06-27 16:34:58,996 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-27 16:34:59,061 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-27 16:34:59,079 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-27 16:34:59,094 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-27 16:34:59,139 - Data_processing - WARNING - concat first and lname
2023-06-27 16:34:59,176 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-27 16:34:59,191 - Data_processing - WARNING - now check for null values in all columns
2023-06-27 16:34:59,191 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-27 16:34:59,224 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-27 16:35:03,381 - Data_processing - WARNING - successfully droped the null values...
2023-06-27 16:35:03,381 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-27 16:35:03,858 - root - INFO - validating  schema for the dataframe...
2023-06-27 16:35:03,858 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-27 16:35:03,860 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-27 16:35:03,860 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-27 16:35:03,860 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-27 16:35:03,860 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-27 16:35:03,860 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-27 16:35:03,860 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-27 16:35:03,860 - Validate - INFO - print_schema done, go frwd...
2023-06-27 16:35:03,860 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-27 16:35:03,862 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-27 16:35:03,862 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-27 16:35:03,862 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-27 16:35:03,862 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-27 16:35:03,862 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-27 16:35:03,862 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-27 16:35:03,863 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-27 16:35:03,863 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-27 16:35:03,863 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-27 16:35:03,863 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-27 16:35:03,863 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-27 16:35:03,863 - Validate - INFO - print_schema done, go frwd...
2023-06-27 16:35:04,078 - root - INFO - checking for null values in dataframe ...after processing
2023-06-27 16:35:04,079 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-27 16:35:04,303 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-27 16:35:26,180 - root - INFO - data_transformation executing...
2023-06-27 16:35:26,180 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-27 16:35:26,181 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-27 16:35:26,255 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-27 16:35:26,300 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-27 16:35:26,359 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-27 16:35:26,359 - root - INFO - displaying the df_report_1
2023-06-27 16:35:33,884 - root - INFO - i am in the main method...
2023-06-27 16:35:33,885 - root - INFO - Calling  spark object
2023-06-27 16:35:33,885 - Create_pyspark - INFO - get_spark_object method started
2023-06-27 16:35:33,885 - Create_pyspark - INFO - master is local
2023-06-27 16:35:44,345 - Create_pyspark - INFO - Spark object created...
2023-06-27 16:35:44,345 - root - INFO - Validating spark object 
2023-06-27 16:35:44,345 - Validate - WARNING - started the get_current_date method...
2023-06-27 16:35:50,030 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 27))]
2023-06-27 16:35:50,030 - Validate - WARNING - Validation  done , go frwd...
2023-06-27 16:35:50,030 - root - INFO - reading file which is of > parquet
2023-06-27 16:35:50,030 - Ingest - WARNING - load_files method  started...   
2023-06-27 16:35:50,925 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-27 16:35:50,925 - root - INFO - displaying file
2023-06-27 16:35:52,281 - root - INFO - validating the dataframe...
2023-06-27 16:35:52,281 - Ingest - WARNING - here to count the records in the df_city
2023-06-27 16:35:53,176 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-27 16:35:53,176 - root - INFO - checking for the files in the FACT....
2023-06-27 16:35:53,178 - root - INFO - reading file which is of > csv
2023-06-27 16:35:53,180 - Ingest - WARNING - load_files method  started...   
2023-06-27 16:36:00,705 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-27 16:36:00,706 - root - INFO - displaying the df_fact dataframe
2023-06-27 16:36:01,222 - Ingest - WARNING - here to count the records in the df_fact
2023-06-27 16:36:02,764 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-27 16:36:02,764 - root - INFO - implementing data_processing methods...
2023-06-27 16:36:02,766 - Data_processing - WARNING - data_clean method() start...
2023-06-27 16:36:02,766 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-27 16:36:02,832 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-27 16:36:02,862 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-27 16:36:02,878 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-27 16:36:02,920 - Data_processing - WARNING - concat first and lname
2023-06-27 16:36:02,951 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-27 16:36:02,971 - Data_processing - WARNING - now check for null values in all columns
2023-06-27 16:36:02,971 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-27 16:36:03,022 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-27 16:36:07,570 - Data_processing - WARNING - successfully droped the null values...
2023-06-27 16:36:07,570 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-27 16:36:08,250 - root - INFO - validating  schema for the dataframe...
2023-06-27 16:36:08,251 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-27 16:36:08,253 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-27 16:36:08,254 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-27 16:36:08,254 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-27 16:36:08,254 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-27 16:36:08,254 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-27 16:36:08,254 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-27 16:36:08,254 - Validate - INFO - print_schema done, go frwd...
2023-06-27 16:36:08,254 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-27 16:36:08,256 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-27 16:36:08,257 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-27 16:36:08,258 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-27 16:36:08,258 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-27 16:36:08,258 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-27 16:36:08,258 - Validate - INFO - print_schema done, go frwd...
2023-06-27 16:36:08,524 - root - INFO - checking for null values in dataframe ...after processing
2023-06-27 16:36:08,525 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-27 16:36:08,744 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-27 16:36:30,700 - root - INFO - data_transformation executing...
2023-06-27 16:36:30,701 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-27 16:36:30,702 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-27 16:36:30,748 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-27 16:36:30,803 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-27 16:36:30,862 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-27 16:36:30,862 - root - INFO - displaying the df_report_1
2023-06-27 16:36:39,951 - root - INFO - Aplication done
2023-06-27 17:06:11,878 - root - INFO - i am in the main method...
2023-06-27 17:06:11,878 - root - INFO - Calling  spark object
2023-06-27 17:06:11,878 - Create_pyspark - INFO - get_spark_object method started
2023-06-27 17:06:11,879 - Create_pyspark - INFO - master is local
2023-06-27 17:06:22,484 - Create_pyspark - INFO - Spark object created...
2023-06-27 17:06:22,484 - root - INFO - Validating spark object 
2023-06-27 17:06:22,484 - Validate - WARNING - started the get_current_date method...
2023-06-27 17:06:28,488 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 27))]
2023-06-27 17:06:28,488 - Validate - WARNING - Validation  done , go frwd...
2023-06-27 17:06:28,488 - root - INFO - reading file which is of > parquet
2023-06-27 17:06:28,488 - Ingest - WARNING - load_files method  started...   
2023-06-27 17:06:29,282 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-27 17:06:29,282 - root - INFO - displaying file
2023-06-27 17:06:30,413 - root - INFO - validating the dataframe...
2023-06-27 17:06:30,414 - Ingest - WARNING - here to count the records in the df_city
2023-06-27 17:06:31,219 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-27 17:06:31,219 - root - INFO - checking for the files in the FACT....
2023-06-27 17:06:31,221 - root - INFO - reading file which is of > csv
2023-06-27 17:06:31,222 - Ingest - WARNING - load_files method  started...   
2023-06-27 17:06:36,545 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-27 17:06:36,545 - root - INFO - displaying the df_fact dataframe
2023-06-27 17:06:36,937 - Ingest - WARNING - here to count the records in the df_fact
2023-06-27 17:06:38,163 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-27 17:06:38,163 - root - INFO - implementing data_processing methods...
2023-06-27 17:06:38,165 - Data_processing - WARNING - data_clean method() start...
2023-06-27 17:06:38,165 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-27 17:06:38,233 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-27 17:06:38,261 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-27 17:06:38,277 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-27 17:06:38,323 - Data_processing - WARNING - concat first and lname
2023-06-27 17:06:38,353 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-27 17:06:38,368 - Data_processing - WARNING - now check for null values in all columns
2023-06-27 17:06:38,368 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-27 17:06:38,400 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-27 17:06:42,725 - Data_processing - WARNING - successfully droped the null values...
2023-06-27 17:06:42,726 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-27 17:06:43,323 - root - INFO - validating  schema for the dataframe...
2023-06-27 17:06:43,323 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-27 17:06:43,325 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-27 17:06:43,325 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-27 17:06:43,325 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-27 17:06:43,325 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-27 17:06:43,325 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-27 17:06:43,325 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-27 17:06:43,325 - Validate - INFO - print_schema done, go frwd...
2023-06-27 17:06:43,325 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-27 17:06:43,327 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-27 17:06:43,328 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-27 17:06:43,328 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-27 17:06:43,328 - Validate - INFO - print_schema done, go frwd...
2023-06-27 17:06:43,578 - root - INFO - checking for null values in dataframe ...after processing
2023-06-27 17:06:43,578 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-27 17:06:43,813 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-27 17:07:04,832 - root - INFO - data_transformation executing...
2023-06-27 17:07:04,833 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-27 17:07:04,834 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-27 17:07:04,903 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-27 17:07:04,972 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-27 17:07:05,079 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-27 17:07:05,079 - root - INFO - displaying the df_report_1
2023-06-27 17:07:05,097 - root - INFO - displaying data_report2 method....
2023-06-27 17:07:05,097 - Data_transformation - WARNING - executing data_report2 method...
2023-06-27 17:07:05,098 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-27 17:07:05,330 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-27 17:07:16,804 - root - INFO - extracting files to Output...
2023-06-27 17:07:36,649 - root - INFO - extracting files to output completed.....
2023-06-27 17:07:36,653 - root - INFO - writing into hive table
2023-06-27 17:07:36,657 - root - INFO - successfully written into Hive
2023-06-27 17:07:36,659 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-27 17:07:36,659 - root - INFO - successfully data inserted into table...
2023-06-27 17:07:36,670 - root - INFO - Aplication done
2023-06-27 17:09:24,232 - root - INFO - i am in the main method...
2023-06-27 17:09:24,232 - root - INFO - Calling  spark object
2023-06-27 17:09:24,232 - Create_pyspark - INFO - get_spark_object method started
2023-06-27 17:09:24,232 - Create_pyspark - INFO - master is local
2023-06-27 17:09:34,488 - Create_pyspark - INFO - Spark object created...
2023-06-27 17:09:34,488 - root - INFO - Validating spark object 
2023-06-27 17:09:34,488 - Validate - WARNING - started the get_current_date method...
2023-06-27 17:09:40,555 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 27))]
2023-06-27 17:09:40,555 - Validate - WARNING - Validation  done , go frwd...
2023-06-27 17:09:40,556 - root - INFO - reading file which is of > parquet
2023-06-27 17:09:40,557 - Ingest - WARNING - load_files method  started...   
2023-06-27 17:09:41,304 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-27 17:09:41,304 - root - INFO - displaying file
2023-06-27 17:09:42,515 - root - INFO - validating the dataframe...
2023-06-27 17:09:42,515 - Ingest - WARNING - here to count the records in the df_city
2023-06-27 17:09:43,252 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-27 17:09:43,252 - root - INFO - checking for the files in the FACT....
2023-06-27 17:09:43,254 - root - INFO - reading file which is of > csv
2023-06-27 17:09:43,254 - Ingest - WARNING - load_files method  started...   
2023-06-27 17:09:48,364 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-27 17:09:48,364 - root - INFO - displaying the df_fact dataframe
2023-06-27 17:09:48,719 - Ingest - WARNING - here to count the records in the df_fact
2023-06-27 17:09:49,715 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-27 17:09:49,715 - root - INFO - implementing data_processing methods...
2023-06-27 17:09:49,722 - Data_processing - WARNING - data_clean method() start...
2023-06-27 17:09:49,723 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-27 17:09:49,782 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-27 17:09:49,809 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-27 17:09:49,827 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-27 17:09:49,862 - Data_processing - WARNING - concat first and lname
2023-06-27 17:09:49,888 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-27 17:09:49,898 - Data_processing - WARNING - now check for null values in all columns
2023-06-27 17:09:49,898 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-27 17:09:49,926 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-27 17:09:53,500 - Data_processing - WARNING - successfully droped the null values...
2023-06-27 17:09:53,501 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-27 17:09:54,114 - root - INFO - validating  schema for the dataframe...
2023-06-27 17:09:54,115 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-27 17:09:54,116 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-27 17:09:54,116 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-27 17:09:54,116 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-27 17:09:54,116 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-27 17:09:54,140 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-27 17:09:54,140 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-27 17:09:54,140 - Validate - INFO - print_schema done, go frwd...
2023-06-27 17:09:54,140 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-27 17:09:54,141 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-27 17:09:54,141 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-27 17:09:54,141 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-27 17:09:54,141 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-27 17:09:54,142 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-27 17:09:54,142 - Validate - INFO - print_schema done, go frwd...
2023-06-27 17:09:54,318 - root - INFO - checking for null values in dataframe ...after processing
2023-06-27 17:09:54,318 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-27 17:09:54,506 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-27 17:10:13,997 - root - INFO - data_transformation executing...
2023-06-27 17:10:13,998 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-27 17:10:13,999 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-27 17:10:14,060 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-27 17:10:14,127 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-27 17:10:14,203 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-27 17:10:14,204 - root - INFO - displaying the df_report_1
2023-06-27 17:10:14,204 - root - INFO - displaying data_report2 method....
2023-06-27 17:10:14,205 - Data_transformation - WARNING - executing data_report2 method...
2023-06-27 17:10:14,205 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-27 17:10:14,352 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-27 17:10:25,201 - root - INFO - extracting files to Output...
2023-06-27 17:10:47,861 - root - INFO - extracting files to output completed.....
2023-06-27 17:10:47,865 - root - INFO - writing into hive table
2023-06-27 17:10:47,866 - root - INFO - successfully written into Hive
2023-06-27 17:10:47,868 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-27 17:10:47,869 - root - INFO - successfully data inserted into table...
2023-06-27 17:10:47,870 - root - INFO - Aplication done
2023-06-27 19:10:19,028 - root - INFO - i am in the main method...
2023-06-27 19:10:19,028 - root - INFO - Calling  spark object
2023-06-27 19:10:19,028 - Create_pyspark - INFO - get_spark_object method started
2023-06-27 19:10:19,028 - Create_pyspark - INFO - master is local
2023-06-27 19:10:31,266 - Create_pyspark - INFO - Spark object created...
2023-06-27 19:10:31,266 - root - INFO - Validating spark object 
2023-06-27 19:10:31,266 - Validate - WARNING - started the get_current_date method...
2023-06-27 19:10:38,533 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 27))]
2023-06-27 19:10:38,533 - Validate - WARNING - Validation  done , go frwd...
2023-06-27 19:10:38,533 - root - INFO - reading file which is of > parquet
2023-06-27 19:10:38,533 - Ingest - WARNING - load_files method  started...   
2023-06-27 19:10:39,503 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-27 19:10:39,511 - root - INFO - displaying file
2023-06-27 19:10:40,902 - root - INFO - validating the dataframe...
2023-06-27 19:10:40,902 - Ingest - WARNING - here to count the records in the df_city
2023-06-27 19:10:41,838 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-27 19:10:41,838 - root - INFO - checking for the files in the FACT....
2023-06-27 19:10:41,838 - root - INFO - reading file which is of > csv
2023-06-27 19:10:41,838 - Ingest - WARNING - load_files method  started...   
2023-06-27 19:10:48,127 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-27 19:10:48,127 - root - INFO - displaying the df_fact dataframe
2023-06-27 19:10:48,559 - Ingest - WARNING - here to count the records in the df_fact
2023-06-27 19:10:49,839 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-27 19:10:49,839 - root - INFO - implementing data_processing methods...
2023-06-27 19:10:49,847 - Data_processing - WARNING - data_clean method() start...
2023-06-27 19:10:49,847 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-27 19:10:49,919 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-27 19:10:49,943 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-27 19:10:49,959 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-27 19:10:49,991 - Data_processing - WARNING - concat first and lname
2023-06-27 19:10:50,023 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-27 19:10:50,039 - Data_processing - WARNING - now check for null values in all columns
2023-06-27 19:10:50,039 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-27 19:10:50,063 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-27 19:10:54,614 - Data_processing - WARNING - successfully droped the null values...
2023-06-27 19:10:54,614 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-27 19:10:55,190 - root - INFO - validating  schema for the dataframe...
2023-06-27 19:10:55,190 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - print_schema done, go frwd...
2023-06-27 19:10:55,190 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-27 19:10:55,190 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-27 19:10:55,190 - Validate - INFO - print_schema done, go frwd...
2023-06-27 19:10:55,470 - root - INFO - checking for null values in dataframe ...after processing
2023-06-27 19:10:55,470 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-27 19:10:55,766 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-27 19:11:19,124 - root - INFO - data_transformation executing...
2023-06-27 19:11:19,124 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-27 19:11:19,124 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-27 19:11:19,204 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-27 19:11:19,260 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-27 19:11:19,324 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-27 19:11:19,324 - root - INFO - displaying the df_report_1
2023-06-27 19:11:19,324 - root - INFO - displaying data_report2 method....
2023-06-27 19:11:19,324 - Data_transformation - WARNING - executing data_report2 method...
2023-06-27 19:11:19,324 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-27 19:11:19,460 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-27 19:11:30,763 - root - INFO - extracting files to Output...
2023-06-27 19:11:53,103 - root - INFO - extracting files to output completed.....
2023-06-27 19:11:53,111 - root - INFO - writing into hive table
2023-06-27 19:11:53,111 - root - INFO - successfully written into Hive
2023-06-27 19:11:53,119 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-27 19:11:53,119 - root - INFO - successfully data inserted into table...
2023-06-27 19:11:53,119 - root - INFO - Aplication done
2023-06-27 19:16:13,000 - root - INFO - i am in the main method...
2023-06-27 19:16:13,000 - root - INFO - Calling  spark object
2023-06-27 19:16:13,000 - Create_pyspark - INFO - get_spark_object method started
2023-06-27 19:16:13,000 - Create_pyspark - INFO - master is local
2023-06-27 19:16:23,667 - Create_pyspark - INFO - Spark object created...
2023-06-27 19:16:23,667 - root - INFO - Validating spark object 
2023-06-27 19:16:23,667 - Validate - WARNING - started the get_current_date method...
2023-06-27 19:16:30,603 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 27))]
2023-06-27 19:16:30,603 - Validate - WARNING - Validation  done , go frwd...
2023-06-27 19:16:30,603 - root - INFO - reading file which is of > parquet
2023-06-27 19:16:30,603 - Ingest - WARNING - load_files method  started...   
2023-06-27 19:16:31,539 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-27 19:16:31,539 - root - INFO - displaying file
2023-06-27 19:16:32,827 - root - INFO - validating the dataframe...
2023-06-27 19:16:32,835 - Ingest - WARNING - here to count the records in the df_city
2023-06-27 19:16:33,755 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-27 19:16:33,755 - root - INFO - checking for the files in the FACT....
2023-06-27 19:16:33,755 - root - INFO - reading file which is of > csv
2023-06-27 19:16:33,755 - Ingest - WARNING - load_files method  started...   
2023-06-27 19:16:40,034 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-27 19:16:40,034 - root - INFO - displaying the df_fact dataframe
2023-06-27 19:16:40,498 - Ingest - WARNING - here to count the records in the df_fact
2023-06-27 19:16:41,754 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-27 19:16:41,754 - root - INFO - implementing data_processing methods...
2023-06-27 19:16:41,762 - Data_processing - WARNING - data_clean method() start...
2023-06-27 19:16:41,762 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-27 19:16:41,826 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-27 19:16:41,850 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-27 19:16:41,874 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-27 19:16:41,914 - Data_processing - WARNING - concat first and lname
2023-06-27 19:16:41,946 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-27 19:16:41,954 - Data_processing - WARNING - now check for null values in all columns
2023-06-27 19:16:41,954 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-27 19:16:41,986 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-27 19:16:45,985 - Data_processing - WARNING - successfully droped the null values...
2023-06-27 19:16:45,985 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-27 19:16:46,609 - root - INFO - validating  schema for the dataframe...
2023-06-27 19:16:46,609 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-27 19:16:46,609 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-27 19:16:46,609 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-27 19:16:46,609 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-27 19:16:46,609 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-27 19:16:46,609 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-27 19:16:46,609 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-27 19:16:46,609 - Validate - INFO - print_schema done, go frwd...
2023-06-27 19:16:46,609 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-27 19:16:46,617 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-27 19:16:46,617 - Validate - INFO - print_schema done, go frwd...
2023-06-27 19:16:46,849 - root - INFO - checking for null values in dataframe ...after processing
2023-06-27 19:16:46,849 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-27 19:16:47,073 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-27 19:17:07,456 - root - INFO - data_transformation executing...
2023-06-27 19:17:07,456 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-27 19:17:07,464 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-27 19:17:07,544 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-27 19:17:07,616 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-27 19:17:07,688 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-27 19:17:07,688 - root - INFO - displaying the df_report_1
2023-06-27 19:17:07,696 - root - INFO - displaying data_report2 method....
2023-06-27 19:17:07,696 - Data_transformation - WARNING - executing data_report2 method...
2023-06-27 19:17:07,696 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-27 19:17:07,872 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-27 19:17:17,713 - root - INFO - extracting files to Output...
2023-06-27 19:17:38,296 - root - INFO - extracting files to output completed.....
2023-06-27 19:17:38,304 - root - INFO - writing into hive table
2023-06-27 19:17:38,304 - root - INFO - successfully written into Hive
2023-06-27 19:17:38,312 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-27 19:17:38,312 - root - INFO - successfully data inserted into table...
2023-06-27 19:17:38,312 - root - INFO - Aplication done
2023-06-28 00:26:51,027 - root - INFO - i am in the main method...
2023-06-28 00:26:51,027 - root - INFO - Calling  spark object
2023-06-28 00:26:51,027 - Create_pyspark - INFO - get_spark_object method started
2023-06-28 00:26:51,027 - Create_pyspark - INFO - master is local
2023-06-28 00:27:02,598 - Create_pyspark - INFO - Spark object created...
2023-06-28 00:27:02,598 - root - INFO - Validating spark object 
2023-06-28 00:27:02,598 - Validate - WARNING - started the get_current_date method...
2023-06-28 00:27:09,373 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 28))]
2023-06-28 00:27:09,373 - Validate - WARNING - Validation  done , go frwd...
2023-06-28 00:27:09,373 - root - INFO - reading file which is of > parquet
2023-06-28 00:27:09,373 - Ingest - WARNING - load_files method  started...   
2023-06-28 00:27:10,194 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-28 00:27:10,194 - root - INFO - displaying file
2023-06-28 00:27:11,399 - root - INFO - validating the dataframe...
2023-06-28 00:27:11,400 - Ingest - WARNING - here to count the records in the df_city
2023-06-28 00:27:12,205 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-28 00:27:12,205 - root - INFO - checking for the files in the FACT....
2023-06-28 00:27:12,209 - root - INFO - reading file which is of > csv
2023-06-28 00:27:12,211 - Ingest - WARNING - load_files method  started...   
2023-06-28 00:27:17,340 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-28 00:27:17,341 - root - INFO - displaying the df_fact dataframe
2023-06-28 00:27:17,698 - Ingest - WARNING - here to count the records in the df_fact
2023-06-28 00:27:18,884 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-28 00:27:18,884 - root - INFO - implementing data_processing methods...
2023-06-28 00:27:18,888 - Data_processing - WARNING - data_clean method() start...
2023-06-28 00:27:18,888 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-28 00:27:18,946 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-28 00:27:18,971 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-28 00:27:18,983 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-28 00:27:19,012 - Data_processing - WARNING - concat first and lname
2023-06-28 00:27:19,031 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-28 00:27:19,046 - Data_processing - WARNING - now check for null values in all columns
2023-06-28 00:27:19,046 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-28 00:27:19,062 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-28 00:27:22,765 - Data_processing - WARNING - successfully droped the null values...
2023-06-28 00:27:22,766 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-28 00:27:23,242 - root - INFO - validating  schema for the dataframe...
2023-06-28 00:27:23,242 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-28 00:27:23,242 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-28 00:27:23,242 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-28 00:27:23,242 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-28 00:27:23,242 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-28 00:27:23,242 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-28 00:27:23,242 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-28 00:27:23,242 - Validate - INFO - print_schema done, go frwd...
2023-06-28 00:27:23,242 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-28 00:27:23,258 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-28 00:27:23,258 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-28 00:27:23,258 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-28 00:27:23,258 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-28 00:27:23,258 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-28 00:27:23,259 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-28 00:27:23,259 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-28 00:27:23,259 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-28 00:27:23,259 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-28 00:27:23,259 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-28 00:27:23,259 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-28 00:27:23,259 - Validate - INFO - print_schema done, go frwd...
2023-06-28 00:27:23,453 - root - INFO - checking for null values in dataframe ...after processing
2023-06-28 00:27:23,454 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-28 00:27:23,680 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-28 00:27:44,217 - root - INFO - data_transformation executing...
2023-06-28 00:27:44,218 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-28 00:27:44,219 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-28 00:27:44,269 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-28 00:27:44,323 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-28 00:27:44,383 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-28 00:27:44,383 - root - INFO - displaying the df_report_1
2023-06-28 00:27:44,383 - root - INFO - displaying data_report2 method....
2023-06-28 00:27:44,383 - Data_transformation - WARNING - executing data_report2 method...
2023-06-28 00:27:44,383 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-28 00:27:44,519 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-28 00:27:55,571 - root - INFO - extracting files to Output...
2023-06-28 00:28:23,182 - root - INFO - extracting files to output completed.....
2023-06-28 00:28:23,189 - root - INFO - writing into hive table
2023-06-28 00:28:49,826 - root - INFO - Aplication done
2023-06-28 00:32:07,402 - root - INFO - i am in the main method...
2023-06-28 00:32:07,402 - root - INFO - Calling  spark object
2023-06-28 00:32:07,402 - Create_pyspark - INFO - get_spark_object method started
2023-06-28 00:32:07,402 - Create_pyspark - INFO - master is local
2023-06-28 00:32:20,322 - Create_pyspark - INFO - Spark object created...
2023-06-28 00:32:20,322 - root - INFO - Validating spark object 
2023-06-28 00:32:20,323 - Validate - WARNING - started the get_current_date method...
2023-06-28 00:32:28,781 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 28))]
2023-06-28 00:32:28,781 - Validate - WARNING - Validation  done , go frwd...
2023-06-28 00:32:28,781 - root - INFO - reading file which is of > parquet
2023-06-28 00:32:28,781 - Ingest - WARNING - load_files method  started...   
2023-06-28 00:32:29,752 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-28 00:32:29,752 - root - INFO - displaying file
2023-06-28 00:32:31,244 - root - INFO - validating the dataframe...
2023-06-28 00:32:31,244 - Ingest - WARNING - here to count the records in the df_city
2023-06-28 00:32:32,411 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-28 00:32:32,411 - root - INFO - checking for the files in the FACT....
2023-06-28 00:32:32,439 - root - INFO - reading file which is of > csv
2023-06-28 00:32:32,448 - Ingest - WARNING - load_files method  started...   
2023-06-28 00:32:42,885 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-28 00:32:42,885 - root - INFO - displaying the df_fact dataframe
2023-06-28 00:32:43,455 - Ingest - WARNING - here to count the records in the df_fact
2023-06-28 00:32:45,750 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-28 00:32:45,750 - root - INFO - implementing data_processing methods...
2023-06-28 00:32:45,759 - Data_processing - WARNING - data_clean method() start...
2023-06-28 00:32:45,760 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-28 00:32:45,822 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-28 00:32:45,853 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-28 00:32:45,871 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-28 00:32:45,932 - Data_processing - WARNING - concat first and lname
2023-06-28 00:32:45,965 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-28 00:32:45,982 - Data_processing - WARNING - now check for null values in all columns
2023-06-28 00:32:45,982 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-28 00:32:46,029 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-28 00:32:53,375 - Data_processing - WARNING - successfully droped the null values...
2023-06-28 00:32:53,375 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-28 00:32:54,222 - root - INFO - validating  schema for the dataframe...
2023-06-28 00:32:54,222 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-28 00:32:54,224 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-28 00:32:54,224 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-28 00:32:54,224 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-28 00:32:54,224 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-28 00:32:54,225 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-28 00:32:54,225 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-28 00:32:54,225 - Validate - INFO - print_schema done, go frwd...
2023-06-28 00:32:54,225 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-28 00:32:54,227 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-28 00:32:54,227 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-28 00:32:54,227 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-28 00:32:54,228 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-28 00:32:54,229 - Validate - INFO - print_schema done, go frwd...
2023-06-28 00:32:54,471 - root - INFO - checking for null values in dataframe ...after processing
2023-06-28 00:32:54,472 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-28 00:32:54,674 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-28 00:33:21,457 - root - INFO - data_transformation executing...
2023-06-28 00:33:21,457 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-28 00:33:21,458 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-28 00:33:21,521 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-28 00:33:21,577 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-28 00:33:21,652 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-28 00:33:21,652 - root - INFO - displaying the df_report_1
2023-06-28 00:33:21,655 - root - INFO - displaying data_report2 method....
2023-06-28 00:33:21,655 - Data_transformation - WARNING - executing data_report2 method...
2023-06-28 00:33:21,655 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-28 00:33:21,799 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-28 00:33:32,983 - root - INFO - extracting files to Output...
2023-06-28 00:33:52,857 - root - INFO - extracting files to output completed.....
2023-06-28 00:33:52,858 - root - INFO - writing into hive table
2023-06-28 00:46:38,049 - root - INFO - i am in the main method...
2023-06-28 00:46:38,050 - root - INFO - Calling  spark object
2023-06-28 00:46:38,050 - Create_pyspark - INFO - get_spark_object method started
2023-06-28 00:46:38,050 - Create_pyspark - INFO - master is local
2023-06-28 00:46:51,415 - Create_pyspark - INFO - Spark object created...
2023-06-28 00:46:51,415 - root - INFO - Validating spark object 
2023-06-28 00:46:51,415 - Validate - WARNING - started the get_current_date method...
2023-06-28 00:47:00,979 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 28))]
2023-06-28 00:47:00,979 - Validate - WARNING - Validation  done , go frwd...
2023-06-28 00:47:00,980 - root - INFO - reading file which is of > parquet
2023-06-28 00:47:00,980 - Ingest - WARNING - load_files method  started...   
2023-06-28 00:47:01,994 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-28 00:47:01,994 - root - INFO - displaying file
2023-06-28 00:47:03,877 - root - INFO - validating the dataframe...
2023-06-28 00:47:03,877 - Ingest - WARNING - here to count the records in the df_city
2023-06-28 00:47:04,853 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-28 00:47:04,854 - root - INFO - checking for the files in the FACT....
2023-06-28 00:47:04,855 - root - INFO - reading file which is of > csv
2023-06-28 00:47:04,855 - Ingest - WARNING - load_files method  started...   
2023-06-28 00:47:10,527 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-28 00:47:10,528 - root - INFO - displaying the df_fact dataframe
2023-06-28 00:47:11,063 - Ingest - WARNING - here to count the records in the df_fact
2023-06-28 00:47:12,225 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-28 00:47:12,225 - root - INFO - implementing data_processing methods...
2023-06-28 00:47:12,233 - Data_processing - WARNING - data_clean method() start...
2023-06-28 00:47:12,233 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-28 00:47:12,304 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-28 00:47:12,329 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-28 00:47:12,345 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-28 00:47:12,385 - Data_processing - WARNING - concat first and lname
2023-06-28 00:47:12,420 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-28 00:47:12,432 - Data_processing - WARNING - now check for null values in all columns
2023-06-28 00:47:12,433 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-28 00:47:12,468 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-28 00:47:18,429 - Data_processing - WARNING - successfully droped the null values...
2023-06-28 00:47:18,429 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-28 00:47:19,227 - root - INFO - validating  schema for the dataframe...
2023-06-28 00:47:19,227 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-28 00:47:19,229 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-28 00:47:19,229 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-28 00:47:19,229 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-28 00:47:19,229 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-28 00:47:19,229 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-28 00:47:19,229 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-28 00:47:19,230 - Validate - INFO - print_schema done, go frwd...
2023-06-28 00:47:19,230 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-28 00:47:19,242 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-28 00:47:19,243 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-28 00:47:19,243 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-28 00:47:19,243 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-28 00:47:19,243 - Validate - INFO - print_schema done, go frwd...
2023-06-28 00:47:19,552 - root - INFO - checking for null values in dataframe ...after processing
2023-06-28 00:47:19,553 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-28 00:47:19,885 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-28 00:47:46,434 - root - INFO - data_transformation executing...
2023-06-28 00:47:46,434 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-28 00:47:46,435 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-28 00:47:46,498 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-28 00:47:46,537 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-28 00:47:46,599 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-28 00:47:46,599 - root - INFO - displaying the df_report_1
2023-06-28 00:47:46,615 - root - INFO - displaying data_report2 method....
2023-06-28 00:47:46,615 - Data_transformation - WARNING - executing data_report2 method...
2023-06-28 00:47:46,615 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-28 00:47:46,736 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-28 00:47:58,359 - root - INFO - extracting files to Output...
2023-06-28 00:48:25,330 - root - INFO - extracting files to output completed.....
2023-06-28 00:48:25,331 - root - INFO - writing into hive table
2023-06-28 00:48:50,348 - root - INFO - Aplication done
2023-06-28 01:13:50,067 - root - INFO - i am in the main method...
2023-06-28 01:13:50,068 - root - INFO - Calling  spark object
2023-06-28 01:13:50,068 - Create_pyspark - INFO - get_spark_object method started
2023-06-28 01:13:50,068 - Create_pyspark - INFO - master is local
2023-06-28 01:14:04,221 - Create_pyspark - INFO - Spark object created...
2023-06-28 01:14:04,221 - root - INFO - Validating spark object 
2023-06-28 01:14:04,221 - Validate - WARNING - started the get_current_date method...
2023-06-28 01:14:12,835 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 28))]
2023-06-28 01:14:12,835 - Validate - WARNING - Validation  done , go frwd...
2023-06-28 01:14:12,836 - root - INFO - reading file which is of > parquet
2023-06-28 01:14:12,836 - Ingest - WARNING - load_files method  started...   
2023-06-28 01:14:13,850 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-28 01:14:13,851 - root - INFO - displaying file
2023-06-28 01:14:15,711 - root - INFO - validating the dataframe...
2023-06-28 01:14:15,711 - Ingest - WARNING - here to count the records in the df_city
2023-06-28 01:14:16,804 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-28 01:14:16,804 - root - INFO - checking for the files in the FACT....
2023-06-28 01:14:16,806 - root - INFO - reading file which is of > csv
2023-06-28 01:14:16,806 - Ingest - WARNING - load_files method  started...   
2023-06-28 01:14:23,188 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-28 01:14:23,188 - root - INFO - displaying the df_fact dataframe
2023-06-28 01:14:23,623 - Ingest - WARNING - here to count the records in the df_fact
2023-06-28 01:14:24,877 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-28 01:14:24,877 - root - INFO - implementing data_processing methods...
2023-06-28 01:14:24,897 - Data_processing - WARNING - data_clean method() start...
2023-06-28 01:14:24,897 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-28 01:14:24,953 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-28 01:14:24,972 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-28 01:14:24,987 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-28 01:14:25,028 - Data_processing - WARNING - concat first and lname
2023-06-28 01:14:25,056 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-28 01:14:25,070 - Data_processing - WARNING - now check for null values in all columns
2023-06-28 01:14:25,070 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-28 01:14:25,105 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-28 01:14:29,305 - Data_processing - WARNING - successfully droped the null values...
2023-06-28 01:14:29,305 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-28 01:14:29,970 - root - INFO - validating  schema for the dataframe...
2023-06-28 01:14:29,970 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-28 01:14:29,972 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-28 01:14:29,972 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-28 01:14:29,972 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-28 01:14:29,972 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-28 01:14:29,973 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-28 01:14:29,973 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-28 01:14:29,973 - Validate - INFO - print_schema done, go frwd...
2023-06-28 01:14:29,973 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-28 01:14:29,975 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-28 01:14:29,975 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-28 01:14:29,975 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-28 01:14:29,975 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-28 01:14:29,975 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-28 01:14:29,975 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-28 01:14:29,976 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-28 01:14:29,976 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-28 01:14:29,976 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-28 01:14:29,976 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-28 01:14:29,976 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-28 01:14:29,976 - Validate - INFO - print_schema done, go frwd...
2023-06-28 01:14:30,266 - root - INFO - checking for null values in dataframe ...after processing
2023-06-28 01:14:30,266 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-28 01:14:30,476 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-28 01:14:57,245 - root - INFO - data_transformation executing...
2023-06-28 01:14:57,246 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-28 01:14:57,247 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-28 01:14:57,316 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-28 01:14:57,392 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-28 01:14:57,490 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-28 01:14:57,490 - root - INFO - displaying the df_report_1
2023-06-28 01:14:57,491 - root - INFO - displaying data_report2 method....
2023-06-28 01:14:57,492 - Data_transformation - WARNING - executing data_report2 method...
2023-06-28 01:14:57,493 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-28 01:14:57,673 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-28 01:15:08,825 - root - INFO - extracting files to Output...
2023-06-28 01:15:36,990 - root - INFO - extracting files to output completed.....
2023-06-28 01:15:36,997 - root - INFO - writing into hive table
2023-06-28 01:16:02,159 - root - INFO - Aplication done
2023-06-28 16:35:48,532 - root - INFO - i am in the main method...
2023-06-28 16:35:48,532 - root - INFO - Calling  spark object
2023-06-28 16:35:48,532 - Create_pyspark - INFO - get_spark_object method started
2023-06-28 16:35:48,532 - Create_pyspark - INFO - master is local
2023-06-28 16:36:05,819 - root - INFO - i am in the main method...
2023-06-28 16:36:05,820 - root - INFO - Calling  spark object
2023-06-28 16:36:05,820 - Create_pyspark - INFO - get_spark_object method started
2023-06-28 16:36:05,820 - Create_pyspark - INFO - master is local
2023-06-28 16:36:18,183 - Create_pyspark - INFO - Spark object created...
2023-06-28 16:36:18,183 - root - INFO - Validating spark object 
2023-06-28 16:36:18,184 - Validate - WARNING - started the get_current_date method...
2023-06-28 16:36:26,340 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 28))]
2023-06-28 16:36:26,341 - Validate - WARNING - Validation  done , go frwd...
2023-06-28 16:36:26,341 - root - INFO - reading file which is of > parquet
2023-06-28 16:36:26,341 - Ingest - WARNING - load_files method  started...   
2023-06-28 16:36:27,234 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-06-28 16:36:27,234 - root - INFO - displaying file
2023-06-28 16:36:28,438 - root - INFO - validating the dataframe...
2023-06-28 16:36:28,438 - Ingest - WARNING - here to count the records in the df_city
2023-06-28 16:36:29,326 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-06-28 16:36:29,326 - root - INFO - checking for the files in the FACT....
2023-06-28 16:36:29,327 - root - INFO - reading file which is of > csv
2023-06-28 16:36:29,327 - Ingest - WARNING - load_files method  started...   
2023-06-28 16:36:35,724 - Ingest - WARNING - dataframe created successfully which is of csv
2023-06-28 16:36:35,724 - root - INFO - displaying the df_fact dataframe
2023-06-28 16:36:36,171 - Ingest - WARNING - here to count the records in the df_fact
2023-06-28 16:36:37,468 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-06-28 16:36:37,469 - root - INFO - implementing data_processing methods...
2023-06-28 16:36:37,469 - Data_processing - WARNING - data_clean method() start...
2023-06-28 16:36:37,470 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-06-28 16:36:37,532 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-06-28 16:36:37,552 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-06-28 16:36:37,568 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-06-28 16:36:37,592 - Data_processing - WARNING - concat first and lname
2023-06-28 16:36:37,631 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-06-28 16:36:37,646 - Data_processing - WARNING - now check for null values in all columns
2023-06-28 16:36:37,646 - Data_processing - WARNING - drop the null values in the respective columns...
2023-06-28 16:36:37,722 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-06-28 16:36:41,871 - Data_processing - WARNING - successfully droped the null values...
2023-06-28 16:36:41,871 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-06-28 16:36:42,369 - root - INFO - validating  schema for the dataframe...
2023-06-28 16:36:42,369 - Validate - WARNING - print schema method executing....df_city_sel
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('city', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - print_schema done, go frwd...
2023-06-28 16:36:42,369 - Validate - WARNING - print schema method executing....df_presc_sel
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-06-28 16:36:42,369 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-06-28 16:36:42,369 - Validate - INFO - print_schema done, go frwd...
2023-06-28 16:36:42,636 - root - INFO - checking for null values in dataframe ...after processing
2023-06-28 16:36:42,636 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-06-28 16:36:42,883 - Validate - WARNING - check_for_nulls executed successfully....
2023-06-28 16:37:10,770 - root - INFO - data_transformation executing...
2023-06-28 16:37:10,796 - Data_transformation - WARNING - processing the data_report1 method..
2023-06-28 16:37:10,797 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-28 16:37:10,867 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-06-28 16:37:10,950 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-28 16:37:11,045 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-06-28 16:37:11,045 - root - INFO - displaying the df_report_1
2023-06-28 16:37:11,051 - root - INFO - displaying data_report2 method....
2023-06-28 16:37:11,053 - Data_transformation - WARNING - executing data_report2 method...
2023-06-28 16:37:11,053 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-28 16:37:11,253 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-06-28 16:37:24,155 - root - INFO - extracting files to Output...
2023-06-28 16:37:58,722 - root - INFO - extracting files to output completed.....
2023-06-28 16:37:58,741 - root - INFO - writing into hive table
2023-06-28 16:38:26,289 - root - INFO - Aplication done
2023-11-15 01:03:31,491 - root - INFO - i am in the main method...
2023-11-15 01:03:31,492 - root - INFO - Calling  spark object
2023-11-15 01:03:31,492 - Create_pyspark - INFO - get_spark_object method started
2023-11-15 01:03:31,492 - Create_pyspark - INFO - master is local
2023-11-19 21:08:15,749 - root - INFO - I am in the main method...
2023-11-19 21:08:15,749 - root - INFO - Calling  spark object
2023-11-19 21:08:15,750 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 21:08:15,750 - Create_pyspark - INFO - master is local
2023-11-19 21:08:23,371 - Create_pyspark - INFO - Spark object created...
2023-11-19 21:08:23,372 - root - INFO - Validating spark object 
2023-11-19 21:08:23,372 - Validate - WARNING - started the get_current_date method...
2023-11-19 21:08:30,085 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 21:08:30,086 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 21:08:30,086 - root - INFO - reading file which is of > parquet
2023-11-19 21:08:30,086 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:08:30,950 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 21:08:30,950 - root - INFO - displaying file
2023-11-19 21:08:32,121 - root - INFO - validating the dataframe...
2023-11-19 21:08:32,122 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 21:08:33,001 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 21:08:33,002 - root - INFO - checking for the files in the FACT....
2023-11-19 21:08:33,003 - root - INFO - reading file which is of > csv
2023-11-19 21:08:33,004 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:08:38,309 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 21:08:38,309 - root - INFO - displaying the df_fact dataframe
2023-11-19 21:08:38,676 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 21:08:39,786 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 21:08:39,786 - root - INFO - implementing data_processing methods...
2023-11-19 21:08:39,808 - Data_processing - WARNING - data_clean method() start...
2023-11-19 21:08:39,808 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 21:08:39,879 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 21:08:39,905 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 21:08:39,920 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 21:08:39,952 - Data_processing - WARNING - concat first and lname
2023-11-19 21:08:39,995 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 21:08:40,009 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 21:08:40,009 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 21:08:40,035 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 21:08:43,245 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 21:08:43,245 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 21:08:43,697 - root - INFO - validating  schema for the dataframe...
2023-11-19 21:08:43,697 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:08:43,697 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 21:08:43,697 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 21:08:43,697 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:08:43,901 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 21:08:43,902 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 21:08:44,108 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 21:09:06,527 - root - INFO - data_transformation executing...
2023-11-19 21:09:06,528 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 21:09:06,530 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 21:09:06,614 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 21:09:06,729 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 21:09:06,916 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 21:09:06,917 - root - INFO - displaying the df_report_1
2023-11-19 21:09:06,921 - root - INFO - displaying data_report2 method....
2023-11-19 21:09:06,924 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 21:09:06,924 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 21:09:07,207 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 21:09:20,014 - root - INFO - extracting files to Output...
2023-11-19 21:09:48,398 - root - INFO - extracting files to output completed.....
2023-11-19 21:09:48,400 - root - INFO - writing into hive table
2023-11-19 21:10:14,260 - root - INFO - Aplication done
2023-11-19 21:29:06,293 - root - INFO - I am in the main method...
2023-11-19 21:29:06,293 - root - INFO - Calling  spark object
2023-11-19 21:29:06,294 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 21:29:06,294 - Create_pyspark - INFO - master is local
2023-11-19 21:29:12,189 - Create_pyspark - INFO - Spark object created...
2023-11-19 21:29:12,189 - root - INFO - Validating spark object 
2023-11-19 21:29:12,190 - Validate - WARNING - started the get_current_date method...
2023-11-19 21:29:22,448 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 21:29:22,449 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 21:29:22,449 - root - INFO - reading file which is of > parquet
2023-11-19 21:29:22,449 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:29:23,720 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 21:29:23,720 - root - INFO - displaying file
2023-11-19 21:29:25,976 - root - INFO - validating the dataframe...
2023-11-19 21:29:25,980 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 21:29:26,749 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 21:29:26,749 - root - INFO - checking for the files in the FACT....
2023-11-19 21:29:26,749 - root - INFO - reading file which is of > csv
2023-11-19 21:29:26,749 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:29:31,950 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 21:29:31,951 - root - INFO - displaying the df_fact dataframe
2023-11-19 21:29:32,325 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 21:29:33,450 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 21:29:33,451 - root - INFO - implementing data_processing methods...
2023-11-19 21:29:33,454 - Data_processing - WARNING - data_clean method() start...
2023-11-19 21:29:33,454 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 21:29:33,499 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 21:29:33,518 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 21:29:33,533 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 21:29:33,564 - Data_processing - WARNING - concat first and lname
2023-11-19 21:29:33,582 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 21:29:33,598 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 21:29:33,598 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 21:29:33,613 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 21:29:37,292 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 21:29:37,292 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 21:29:37,769 - root - INFO - validating  schema for the dataframe...
2023-11-19 21:29:37,769 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:29:37,769 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 21:29:37,769 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 21:29:37,769 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:29:38,017 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 21:29:38,018 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 21:29:38,223 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 21:29:58,656 - root - INFO - data_transformation executing...
2023-11-19 21:29:58,657 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 21:29:58,658 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 21:29:58,722 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 21:29:58,788 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 21:29:58,852 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 21:29:58,852 - root - INFO - displaying the df_report_1
2023-11-19 21:29:58,869 - root - INFO - displaying data_report2 method....
2023-11-19 21:29:58,870 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 21:29:58,870 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 21:29:59,034 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 21:30:08,969 - root - INFO - extracting files to Output...
2023-11-19 21:30:30,564 - root - INFO - extracting files to output completed.....
2023-11-19 21:30:30,571 - root - INFO - writing into hive table
2023-11-19 21:30:30,572 - root - INFO - successfully written into Hive
2023-11-19 21:30:30,572 - root - INFO - successfully data inserted into table...
2023-11-19 21:30:30,573 - root - INFO - Aplication done
2023-11-19 21:33:30,793 - root - INFO - I am in the main method...
2023-11-19 21:33:30,793 - root - INFO - Calling  spark object
2023-11-19 21:33:30,793 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 21:33:30,793 - Create_pyspark - INFO - master is local
2023-11-19 21:33:36,315 - Create_pyspark - INFO - Spark object created...
2023-11-19 21:33:36,315 - root - INFO - Validating spark object 
2023-11-19 21:33:36,315 - Validate - WARNING - started the get_current_date method...
2023-11-19 21:33:44,309 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 21:33:44,309 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 21:33:44,310 - root - INFO - reading file which is of > parquet
2023-11-19 21:33:44,310 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:33:45,240 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 21:33:45,240 - root - INFO - displaying file
2023-11-19 21:33:45,248 - root - INFO - validating the dataframe...
2023-11-19 21:33:45,248 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 21:33:46,756 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 21:33:46,756 - root - INFO - checking for the files in the FACT....
2023-11-19 21:33:46,757 - root - INFO - reading file which is of > csv
2023-11-19 21:33:46,757 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:33:52,200 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 21:33:52,200 - root - INFO - displaying the df_fact dataframe
2023-11-19 21:33:52,200 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 21:33:53,467 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 21:33:53,468 - root - INFO - implementing data_processing methods...
2023-11-19 21:33:53,478 - Data_processing - WARNING - data_clean method() start...
2023-11-19 21:33:53,479 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 21:33:53,534 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 21:33:53,563 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 21:33:53,581 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 21:33:53,627 - Data_processing - WARNING - concat first and lname
2023-11-19 21:33:53,657 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 21:33:53,670 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 21:33:53,670 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 21:33:53,698 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 21:33:57,143 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 21:33:57,144 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 21:33:57,144 - root - INFO - validating  schema for the dataframe...
2023-11-19 21:33:57,146 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 21:33:57,147 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 21:33:57,148 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 21:33:57,148 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 21:33:57,148 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 21:33:57,148 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 21:33:57,148 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 21:33:57,148 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:33:57,148 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 21:33:57,150 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 21:33:57,150 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 21:33:57,150 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 21:33:57,150 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 21:33:57,150 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 21:33:57,151 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 21:33:57,151 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 21:33:57,151 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 21:33:57,151 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 21:33:57,151 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 21:33:57,151 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 21:33:57,151 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:33:57,151 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 21:33:57,153 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 21:33:57,408 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 21:33:57,408 - root - INFO - data_transformation executing...
2023-11-19 21:33:57,413 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 21:33:57,414 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 21:33:57,471 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 21:33:57,529 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 21:33:57,601 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 21:33:57,601 - root - INFO - displaying the df_report_1
2023-11-19 21:34:05,094 - root - INFO - displaying data_report2 method....
2023-11-19 21:34:05,095 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 21:34:05,095 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 21:34:05,259 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 21:34:14,215 - root - INFO - extracting files to Output...
2023-11-19 21:34:31,855 - root - INFO - extracting files to output completed.....
2023-11-19 21:34:31,856 - root - INFO - writing into hive table
2023-11-19 21:34:31,857 - root - INFO - successfully written into Hive
2023-11-19 21:34:31,858 - root - INFO - successfully data inserted into table...
2023-11-19 21:34:31,859 - root - INFO - Aplication done
2023-11-19 21:42:45,546 - root - INFO - I am in the main method...
2023-11-19 21:42:45,546 - root - INFO - Calling  spark object
2023-11-19 21:42:45,546 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 21:42:45,546 - Create_pyspark - INFO - master is local
2023-11-19 21:42:52,319 - Create_pyspark - INFO - Spark object created...
2023-11-19 21:42:52,319 - root - INFO - Validating spark object 
2023-11-19 21:42:52,319 - Validate - WARNING - started the get_current_date method...
2023-11-19 21:43:00,180 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 21:43:00,180 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 21:43:00,180 - root - INFO - reading file which is of > parquet
2023-11-19 21:43:00,181 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:43:01,314 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 21:43:01,314 - root - INFO - displaying file
2023-11-19 21:43:01,324 - root - INFO - validating the dataframe...
2023-11-19 21:43:01,325 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 21:43:02,735 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 21:43:02,735 - root - INFO - checking for the files in the FACT....
2023-11-19 21:43:02,735 - root - INFO - reading file which is of > csv
2023-11-19 21:43:02,735 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:43:08,475 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 21:43:08,475 - root - INFO - displaying the df_fact dataframe
2023-11-19 21:43:08,475 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 21:43:09,777 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 21:43:09,778 - root - INFO - implementing data_processing methods...
2023-11-19 21:43:09,793 - Data_processing - WARNING - data_clean method() start...
2023-11-19 21:43:09,793 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 21:43:09,852 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 21:43:09,874 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 21:43:09,890 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 21:43:09,921 - Data_processing - WARNING - concat first and lname
2023-11-19 21:43:09,952 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 21:43:09,968 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 21:43:09,968 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 21:43:09,999 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 21:43:13,638 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 21:43:13,639 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 21:43:13,639 - root - INFO - validating  schema for the dataframe...
2023-11-19 21:43:13,640 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 21:43:13,641 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 21:43:13,641 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 21:43:13,641 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 21:43:13,641 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 21:43:13,642 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 21:43:13,642 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 21:43:13,642 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:43:13,642 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 21:43:13,643 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 21:43:13,643 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 21:43:13,643 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 21:43:13,644 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 21:43:13,644 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 21:43:13,644 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 21:43:13,644 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 21:43:13,645 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 21:43:13,645 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 21:43:13,645 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 21:43:13,645 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 21:43:13,645 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:43:13,645 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 21:43:13,646 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 21:43:13,831 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 21:43:13,831 - root - INFO - data_transformation executing...
2023-11-19 21:43:13,831 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 21:43:13,842 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 21:43:13,892 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 21:43:13,919 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 21:43:13,981 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 21:43:13,981 - root - INFO - displaying the df_report_1
2023-11-19 21:43:25,997 - root - INFO - displaying data_report2 method....
2023-11-19 21:43:25,998 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 21:43:25,998 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 21:43:26,300 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 21:43:46,018 - root - INFO - extracting files to Output...
2023-11-19 21:44:08,597 - root - INFO - extracting files to output completed.....
2023-11-19 21:44:08,598 - root - INFO - writing into hive table
2023-11-19 21:44:08,598 - root - INFO - successfully written into Hive
2023-11-19 21:44:08,599 - root - INFO - successfully data inserted into table...
2023-11-19 21:44:08,599 - root - INFO - Aplication done
2023-11-19 21:57:02,141 - root - INFO - I am in the main method...
2023-11-19 21:57:02,141 - root - INFO - Calling  spark object
2023-11-19 21:57:02,141 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 21:57:02,141 - Create_pyspark - INFO - master is local
2023-11-19 21:57:08,290 - Create_pyspark - INFO - Spark object created...
2023-11-19 21:57:08,290 - root - INFO - Validating spark object 
2023-11-19 21:57:08,290 - Validate - WARNING - started the get_current_date method...
2023-11-19 21:57:14,817 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 21:57:14,817 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 21:57:14,817 - root - INFO - reading file which is of > parquet
2023-11-19 21:57:14,817 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:57:15,651 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 21:57:15,651 - root - INFO - displaying file
2023-11-19 21:57:15,651 - root - INFO - validating the dataframe...
2023-11-19 21:57:15,651 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 21:57:16,950 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 21:57:16,950 - root - INFO - checking for the files in the FACT....
2023-11-19 21:57:16,950 - root - INFO - reading file which is of > csv
2023-11-19 21:57:16,950 - Ingest - WARNING - load_files method  started...   
2023-11-19 21:57:22,019 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 21:57:22,019 - root - INFO - displaying the df_fact dataframe
2023-11-19 21:57:22,020 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 21:57:23,227 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 21:57:23,227 - root - INFO - implementing data_processing methods...
2023-11-19 21:57:23,237 - Data_processing - WARNING - data_clean method() start...
2023-11-19 21:57:23,237 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 21:57:23,287 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 21:57:23,314 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 21:57:23,329 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 21:57:23,356 - Data_processing - WARNING - concat first and lname
2023-11-19 21:57:23,388 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 21:57:23,403 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 21:57:23,403 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 21:57:23,434 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 21:57:27,288 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 21:57:27,289 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 21:57:27,289 - root - INFO - validating  schema for the dataframe...
2023-11-19 21:57:27,293 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 21:57:27,295 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 21:57:27,295 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 21:57:27,295 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 21:57:27,295 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 21:57:27,295 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 21:57:27,295 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 21:57:27,295 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:57:27,295 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 21:57:27,297 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 21:57:27,298 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 21:57:27,298 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 21:57:27,298 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 21:57:27,298 - Validate - INFO - print_schema done, go frwd...
2023-11-19 21:57:27,298 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 21:57:27,299 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 21:57:27,536 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 21:57:27,536 - root - INFO - data_transformation executing...
2023-11-19 21:57:27,552 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 21:57:27,552 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 21:57:27,605 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 21:57:27,645 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 21:57:27,722 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 21:57:27,722 - root - INFO - displaying the df_report_1
2023-11-19 21:57:37,703 - root - INFO - displaying data_report2 method....
2023-11-19 21:57:37,704 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 21:57:37,704 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 21:57:37,881 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 21:57:50,362 - root - INFO - extracting files to Output...
2023-11-19 21:58:09,696 - root - INFO - extracting files to output completed.....
2023-11-19 21:58:09,698 - root - INFO - writing into hive table
2023-11-19 21:58:09,699 - root - INFO - successfully written into Hive
2023-11-19 21:58:09,701 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 21:58:09,851 - root - INFO - Aplication done
2023-11-19 22:04:01,227 - root - INFO - I am in the main method...
2023-11-19 22:04:01,227 - root - INFO - Calling  spark object
2023-11-19 22:04:01,227 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:04:01,227 - Create_pyspark - INFO - master is local
2023-11-19 22:04:07,046 - Create_pyspark - INFO - Spark object created...
2023-11-19 22:04:07,046 - root - INFO - Validating spark object 
2023-11-19 22:04:07,062 - Validate - WARNING - started the get_current_date method...
2023-11-19 22:04:13,663 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 22:04:13,663 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 22:04:13,663 - root - INFO - reading file which is of > parquet
2023-11-19 22:04:13,663 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:04:14,946 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 22:04:14,946 - root - INFO - displaying file
2023-11-19 22:04:14,948 - root - INFO - validating the dataframe...
2023-11-19 22:04:14,951 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 22:04:16,201 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 22:04:16,202 - root - INFO - checking for the files in the FACT....
2023-11-19 22:04:16,202 - root - INFO - reading file which is of > csv
2023-11-19 22:04:16,203 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:04:22,253 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 22:04:22,254 - root - INFO - displaying the df_fact dataframe
2023-11-19 22:04:22,254 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 22:04:24,135 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 22:04:24,135 - root - INFO - implementing data_processing methods...
2023-11-19 22:04:24,194 - Data_processing - WARNING - data_clean method() start...
2023-11-19 22:04:24,194 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 22:04:24,274 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 22:04:24,324 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 22:04:24,370 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 22:04:24,554 - Data_processing - WARNING - concat first and lname
2023-11-19 22:04:24,636 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 22:04:24,670 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 22:04:24,671 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 22:04:24,927 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 22:04:29,117 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 22:04:29,117 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 22:04:29,117 - root - INFO - validating  schema for the dataframe...
2023-11-19 22:04:29,118 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 22:04:29,119 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 22:04:29,119 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 22:04:29,119 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 22:04:29,119 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 22:04:29,119 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 22:04:29,119 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 22:04:29,119 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:04:29,119 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 22:04:29,120 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 22:04:29,121 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 22:04:29,121 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:04:29,121 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 22:04:29,121 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 22:04:29,327 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 22:04:29,327 - root - INFO - data_transformation executing...
2023-11-19 22:04:29,328 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 22:04:29,329 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 22:04:29,369 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 22:04:29,416 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 22:04:29,491 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 22:04:29,491 - root - INFO - displaying the df_report_1
2023-11-19 22:04:41,781 - root - INFO - displaying data_report2 method....
2023-11-19 22:04:41,784 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 22:04:41,785 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 22:04:41,978 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 22:04:57,923 - root - INFO - extracting files to Output...
2023-11-19 22:05:23,067 - root - INFO - extracting files to output completed.....
2023-11-19 22:05:23,074 - root - INFO - writing into hive table
2023-11-19 22:05:23,074 - root - INFO - successfully written into Hive
2023-11-19 22:05:23,076 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 22:05:23,170 - root - INFO - Aplication done
2023-11-19 22:12:06,931 - root - INFO - I am in the main method...
2023-11-19 22:12:06,932 - root - INFO - Calling  spark object
2023-11-19 22:12:06,932 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:12:06,932 - Create_pyspark - INFO - master is local
2023-11-19 22:12:14,202 - Create_pyspark - INFO - Spark object created...
2023-11-19 22:12:14,203 - root - INFO - Validating spark object 
2023-11-19 22:12:14,203 - Validate - WARNING - started the get_current_date method...
2023-11-19 22:12:21,612 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 22:12:21,612 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 22:12:21,613 - root - INFO - reading file which is of > parquet
2023-11-19 22:12:21,613 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:12:22,526 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 22:12:22,526 - root - INFO - displaying file
2023-11-19 22:12:22,527 - root - INFO - validating the dataframe...
2023-11-19 22:12:22,527 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 22:12:23,907 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 22:12:23,907 - root - INFO - checking for the files in the FACT....
2023-11-19 22:12:23,910 - root - INFO - reading file which is of > csv
2023-11-19 22:12:23,910 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:12:29,763 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 22:12:29,763 - root - INFO - displaying the df_fact dataframe
2023-11-19 22:12:29,763 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 22:12:31,216 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 22:12:31,217 - root - INFO - implementing data_processing methods...
2023-11-19 22:12:31,233 - Data_processing - WARNING - data_clean method() start...
2023-11-19 22:12:31,234 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 22:12:31,289 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 22:12:31,312 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 22:12:31,343 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 22:12:31,390 - Data_processing - WARNING - concat first and lname
2023-11-19 22:12:31,421 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 22:12:31,437 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 22:12:31,437 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 22:12:31,468 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 22:12:35,168 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 22:12:35,169 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 22:12:35,169 - root - INFO - validating  schema for the dataframe...
2023-11-19 22:12:35,171 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 22:12:35,174 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 22:12:35,174 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 22:12:35,174 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 22:12:35,175 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 22:12:35,175 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 22:12:35,175 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 22:12:35,175 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:12:35,175 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 22:12:35,176 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 22:12:35,177 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 22:12:35,178 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 22:12:35,178 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 22:12:35,178 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:12:35,178 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 22:12:35,181 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 22:12:35,446 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 22:12:35,446 - root - INFO - data_transformation executing...
2023-11-19 22:12:35,454 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 22:12:35,456 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 22:12:35,507 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 22:12:35,539 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 22:12:35,617 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 22:12:35,617 - root - INFO - displaying the df_report_1
2023-11-19 22:12:46,007 - root - INFO - displaying data_report2 method....
2023-11-19 22:12:46,012 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 22:12:46,012 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 22:12:46,192 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 22:13:00,402 - root - INFO - extracting files to Output...
2023-11-19 22:13:23,683 - root - INFO - extracting files to output completed.....
2023-11-19 22:13:23,692 - root - INFO - writing into hive table
2023-11-19 22:13:23,694 - root - INFO - successfully written into Hive
2023-11-19 22:13:23,697 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 22:13:23,829 - root - INFO - Aplication done
2023-11-19 22:36:34,110 - root - INFO - I am in the main method...
2023-11-19 22:36:34,110 - root - INFO - Calling  spark object
2023-11-19 22:36:34,110 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:36:34,110 - Create_pyspark - INFO - master is local
2023-11-19 22:36:45,016 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-11-19 22:36:45,056 - root - INFO - Aplication done
2023-11-19 22:41:57,729 - root - INFO - I am in the main method...
2023-11-19 22:41:57,729 - root - INFO - Calling  spark object
2023-11-19 22:41:57,729 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:41:57,736 - Create_pyspark - INFO - master is local
2023-11-19 22:42:05,720 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-11-19 22:42:05,785 - root - INFO - Aplication done
2023-11-19 22:43:22,688 - root - INFO - I am in the main method...
2023-11-19 22:43:22,688 - root - INFO - Calling  spark object
2023-11-19 22:43:22,688 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:43:22,688 - Create_pyspark - INFO - master is local
2023-11-19 22:43:29,083 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-11-19 22:43:29,133 - root - INFO - Aplication done
2023-11-19 22:44:59,999 - root - INFO - I am in the main method...
2023-11-19 22:44:59,999 - root - INFO - Calling  spark object
2023-11-19 22:44:59,999 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:44:59,999 - Create_pyspark - INFO - master is local
2023-11-19 22:45:06,309 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "F:\pyspark_end_to_end\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-11-19 22:45:06,357 - root - INFO - Aplication done
2023-11-19 22:48:36,495 - root - INFO - I am in the main method...
2023-11-19 22:48:36,495 - root - INFO - Calling  spark object
2023-11-19 22:48:36,495 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:48:36,495 - Create_pyspark - INFO - master is local
2023-11-19 22:48:42,219 - Create_pyspark - INFO - Spark object created...
2023-11-19 22:48:42,219 - root - INFO - Validating spark object 
2023-11-19 22:48:42,235 - Validate - WARNING - started the get_current_date method...
2023-11-19 22:48:48,616 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 22:48:48,616 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 22:48:48,616 - root - INFO - reading file which is of > parquet
2023-11-19 22:48:48,616 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:48:49,511 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 22:48:49,511 - root - INFO - displaying file
2023-11-19 22:48:49,511 - root - INFO - validating the dataframe...
2023-11-19 22:48:49,511 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 22:48:50,729 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 22:48:50,729 - root - INFO - checking for the files in the FACT....
2023-11-19 22:48:50,729 - root - INFO - reading file which is of > csv
2023-11-19 22:48:50,745 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:48:55,921 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 22:48:55,921 - root - INFO - displaying the df_fact dataframe
2023-11-19 22:48:55,921 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 22:48:57,133 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 22:48:57,133 - root - INFO - implementing data_processing methods...
2023-11-19 22:48:57,141 - Data_processing - WARNING - data_clean method() start...
2023-11-19 22:48:57,141 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 22:48:57,197 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 22:48:57,221 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 22:48:57,237 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 22:48:57,284 - Data_processing - WARNING - concat first and lname
2023-11-19 22:48:57,315 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 22:48:57,331 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 22:48:57,331 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 22:48:57,346 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 22:49:01,042 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 22:49:01,042 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 22:49:01,042 - root - INFO - validating  schema for the dataframe...
2023-11-19 22:49:01,042 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:49:01,050 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 22:49:01,050 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 22:49:01,050 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:49:01,050 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 22:49:01,058 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 22:49:01,226 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 22:49:01,226 - root - INFO - data_transformation executing...
2023-11-19 22:49:01,226 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 22:49:01,226 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 22:49:01,291 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 22:49:01,315 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 22:49:01,405 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 22:49:01,405 - root - INFO - displaying the df_report_1
2023-11-19 22:49:01,413 - root - INFO - displaying data_report2 method....
2023-11-19 22:49:01,413 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 22:49:01,413 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 22:49:01,564 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 22:49:01,564 - root - INFO - extracting files to Output...
2023-11-19 22:49:21,624 - root - INFO - extracting files to output completed.....
2023-11-19 22:49:21,624 - root - INFO - writing into hive table
2023-11-19 22:49:21,632 - root - INFO - successfully written into Hive
2023-11-19 22:49:21,632 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 22:49:21,857 - root - INFO - Aplication done
2023-11-19 22:52:23,245 - root - INFO - I am in the main method...
2023-11-19 22:52:23,245 - root - INFO - Calling  spark object
2023-11-19 22:52:23,245 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:52:23,245 - Create_pyspark - INFO - master is local
2023-11-19 22:52:29,503 - Create_pyspark - INFO - Spark object created...
2023-11-19 22:52:29,503 - root - INFO - Validating spark object 
2023-11-19 22:52:29,503 - Validate - WARNING - started the get_current_date method...
2023-11-19 22:52:35,715 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 22:52:35,715 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 22:52:35,715 - root - INFO - reading file which is of > parquet
2023-11-19 22:52:35,715 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:52:36,636 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 22:52:36,636 - root - INFO - displaying file
2023-11-19 22:52:36,636 - root - INFO - validating the dataframe...
2023-11-19 22:52:36,636 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 22:52:37,731 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 22:52:37,731 - root - INFO - checking for the files in the FACT....
2023-11-19 22:52:37,739 - root - INFO - reading file which is of > csv
2023-11-19 22:52:37,739 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:52:42,851 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 22:52:42,851 - root - INFO - displaying the df_fact dataframe
2023-11-19 22:52:42,851 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 22:52:44,144 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 22:52:44,144 - root - INFO - implementing data_processing methods...
2023-11-19 22:52:44,144 - Data_processing - WARNING - data_clean method() start...
2023-11-19 22:52:44,144 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 22:52:44,200 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 22:52:44,224 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 22:52:44,232 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 22:52:44,282 - Data_processing - WARNING - concat first and lname
2023-11-19 22:52:44,306 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 22:52:44,312 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 22:52:44,312 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 22:52:44,343 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 22:52:47,695 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 22:52:47,695 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 22:52:47,695 - root - INFO - validating  schema for the dataframe...
2023-11-19 22:52:47,695 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:52:47,695 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 22:52:47,695 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 22:52:47,695 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:52:47,695 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 22:52:47,695 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 22:52:47,863 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 22:52:47,863 - root - INFO - data_transformation executing...
2023-11-19 22:52:47,863 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 22:52:47,863 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 22:52:47,910 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 22:52:47,950 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 22:52:48,005 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 22:52:48,005 - root - INFO - displaying the df_report_1
2023-11-19 22:52:48,005 - root - INFO - displaying data_report2 method....
2023-11-19 22:52:48,005 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 22:52:48,005 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 22:52:48,125 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 22:52:48,125 - root - INFO - extracting files to Output...
2023-11-19 22:53:08,742 - root - INFO - extracting files to output completed.....
2023-11-19 22:53:08,754 - root - INFO - writing into hive table
2023-11-19 22:53:08,754 - root - INFO - successfully written into Hive
2023-11-19 22:53:08,754 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 22:53:08,875 - root - INFO - Aplication done
2023-11-19 22:57:18,038 - root - INFO - I am in the main method...
2023-11-19 22:57:18,038 - root - INFO - Calling  spark object
2023-11-19 22:57:18,038 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 22:57:18,038 - Create_pyspark - INFO - master is local
2023-11-19 22:57:23,992 - Create_pyspark - INFO - Spark object created...
2023-11-19 22:57:23,992 - root - INFO - Validating spark object 
2023-11-19 22:57:23,992 - Validate - WARNING - started the get_current_date method...
2023-11-19 22:57:30,493 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 22:57:30,493 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 22:57:30,493 - root - INFO - reading file which is of > parquet
2023-11-19 22:57:30,493 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:57:31,378 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 22:57:31,378 - root - INFO - displaying file
2023-11-19 22:57:31,378 - root - INFO - validating the dataframe...
2023-11-19 22:57:31,378 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 22:57:32,545 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 22:57:32,545 - root - INFO - checking for the files in the FACT....
2023-11-19 22:57:32,547 - root - INFO - reading file which is of > csv
2023-11-19 22:57:32,547 - Ingest - WARNING - load_files method  started...   
2023-11-19 22:57:38,238 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 22:57:38,238 - root - INFO - displaying the df_fact dataframe
2023-11-19 22:57:38,238 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 22:57:39,320 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 22:57:39,320 - root - INFO - implementing data_processing methods...
2023-11-19 22:57:39,328 - Data_processing - WARNING - data_clean method() start...
2023-11-19 22:57:39,328 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 22:57:39,384 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 22:57:39,408 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 22:57:39,424 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 22:57:39,476 - Data_processing - WARNING - concat first and lname
2023-11-19 22:57:39,492 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 22:57:39,507 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 22:57:39,507 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 22:57:39,539 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 22:57:43,292 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 22:57:43,292 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 22:57:43,292 - root - INFO - validating  schema for the dataframe...
2023-11-19 22:57:43,300 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:57:43,300 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 22:57:43,300 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 22:57:43,300 - Validate - INFO - print_schema done, go frwd...
2023-11-19 22:57:43,300 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 22:57:43,300 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 22:57:43,503 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 22:57:43,503 - root - INFO - data_transformation executing...
2023-11-19 22:57:43,516 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 22:57:43,516 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 22:57:43,572 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 22:57:43,612 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 22:57:43,674 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 22:57:43,674 - root - INFO - displaying the df_report_1
2023-11-19 22:57:43,674 - root - INFO - displaying data_report2 method....
2023-11-19 22:57:43,674 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 22:57:43,674 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 22:57:43,813 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 22:57:43,813 - root - INFO - extracting files to Output...
2023-11-19 22:58:03,359 - root - INFO - extracting files to output completed.....
2023-11-19 22:58:03,369 - root - INFO - writing into hive table
2023-11-19 22:58:03,369 - root - INFO - successfully written into Hive
2023-11-19 22:58:03,369 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 22:58:03,473 - root - INFO - Aplication done
2023-11-19 23:01:04,331 - root - INFO - I am in the main method...
2023-11-19 23:01:04,336 - root - INFO - Calling  spark object
2023-11-19 23:01:04,336 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 23:01:04,337 - Create_pyspark - INFO - master is local
2023-11-19 23:01:15,043 - Create_pyspark - INFO - Spark object created...
2023-11-19 23:01:15,043 - root - INFO - Validating spark object 
2023-11-19 23:01:15,043 - Validate - WARNING - started the get_current_date method...
2023-11-19 23:01:20,426 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 23:01:20,426 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 23:01:20,426 - root - INFO - reading file which is of > parquet
2023-11-19 23:01:20,426 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:01:21,275 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 23:01:21,275 - root - INFO - displaying file
2023-11-19 23:01:21,275 - root - INFO - validating the dataframe...
2023-11-19 23:01:21,275 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 23:01:22,297 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 23:01:22,297 - root - INFO - checking for the files in the FACT....
2023-11-19 23:01:22,300 - root - INFO - reading file which is of > csv
2023-11-19 23:01:22,300 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:01:27,495 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 23:01:27,503 - root - INFO - displaying the df_fact dataframe
2023-11-19 23:01:27,503 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 23:01:28,733 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 23:01:28,733 - root - INFO - implementing data_processing methods...
2023-11-19 23:01:28,733 - Data_processing - WARNING - data_clean method() start...
2023-11-19 23:01:28,733 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 23:01:28,797 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 23:01:28,821 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 23:01:28,837 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 23:01:28,884 - Data_processing - WARNING - concat first and lname
2023-11-19 23:01:28,915 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 23:01:28,931 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 23:01:28,931 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 23:01:28,962 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 23:01:32,536 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 23:01:32,536 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 23:01:32,536 - root - INFO - validating  schema for the dataframe...
2023-11-19 23:01:32,536 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 23:01:32,536 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 23:01:32,536 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 23:01:32,536 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 23:01:32,536 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 23:01:32,536 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 23:01:32,536 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 23:01:32,536 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:01:32,536 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 23:01:32,544 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 23:01:32,544 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:01:32,544 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 23:01:32,544 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 23:01:32,755 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 23:01:32,755 - root - INFO - data_transformation executing...
2023-11-19 23:01:32,755 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 23:01:32,755 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 23:01:32,802 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 23:01:32,853 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 23:01:32,916 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 23:01:32,916 - root - INFO - displaying the df_report_1
2023-11-19 23:01:32,916 - root - INFO - displaying data_report2 method....
2023-11-19 23:01:32,916 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 23:01:32,916 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 23:01:33,019 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 23:01:33,019 - root - INFO - extracting files to Output...
2023-11-19 23:01:53,021 - root - INFO - extracting files to output completed.....
2023-11-19 23:01:53,029 - root - INFO - writing into hive table
2023-11-19 23:01:53,029 - root - INFO - successfully written into Hive
2023-11-19 23:01:53,029 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 23:01:53,228 - root - INFO - Aplication done
2023-11-19 23:05:02,007 - root - INFO - I am in the main method...
2023-11-19 23:05:02,007 - root - INFO - Calling  spark object
2023-11-19 23:05:02,007 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 23:05:02,007 - Create_pyspark - INFO - master is local
2023-11-19 23:05:07,682 - Create_pyspark - INFO - Spark object created...
2023-11-19 23:05:07,682 - root - INFO - Validating spark object 
2023-11-19 23:05:07,682 - Validate - WARNING - started the get_current_date method...
2023-11-19 23:05:13,644 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 23:05:13,644 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 23:05:13,644 - root - INFO - reading file which is of > parquet
2023-11-19 23:05:13,644 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:05:14,440 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 23:05:14,440 - root - INFO - displaying file
2023-11-19 23:05:14,440 - root - INFO - validating the dataframe...
2023-11-19 23:05:14,440 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 23:05:15,501 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 23:05:15,501 - root - INFO - checking for the files in the FACT....
2023-11-19 23:05:15,506 - root - INFO - reading file which is of > csv
2023-11-19 23:05:15,506 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:05:21,238 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 23:05:21,238 - root - INFO - displaying the df_fact dataframe
2023-11-19 23:05:21,238 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 23:05:22,396 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 23:05:22,396 - root - INFO - implementing data_processing methods...
2023-11-19 23:05:22,396 - Data_processing - WARNING - data_clean method() start...
2023-11-19 23:05:22,396 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 23:05:22,452 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 23:05:22,484 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 23:05:22,492 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 23:05:22,540 - Data_processing - WARNING - concat first and lname
2023-11-19 23:05:22,560 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 23:05:22,576 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 23:05:22,576 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 23:05:22,601 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 23:05:25,920 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 23:05:25,920 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 23:05:25,920 - root - INFO - validating  schema for the dataframe...
2023-11-19 23:05:25,931 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 23:05:25,931 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 23:05:25,931 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 23:05:25,931 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 23:05:25,931 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 23:05:25,931 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 23:05:25,931 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 23:05:25,931 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:05:25,931 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 23:05:25,939 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 23:05:25,939 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:05:25,939 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 23:05:25,939 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 23:05:26,152 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 23:05:26,152 - root - INFO - data_transformation executing...
2023-11-19 23:05:26,152 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 23:05:26,152 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 23:05:26,206 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 23:05:26,246 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 23:05:26,302 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 23:05:26,302 - root - INFO - displaying the df_report_1
2023-11-19 23:05:26,302 - root - INFO - displaying data_report2 method....
2023-11-19 23:05:26,302 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 23:05:26,302 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 23:05:26,425 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 23:05:26,425 - root - INFO - extracting files to Output...
2023-11-19 23:05:46,113 - root - INFO - extracting files to output completed.....
2023-11-19 23:05:46,113 - root - INFO - writing into hive table
2023-11-19 23:05:46,113 - root - INFO - successfully written into Hive
2023-11-19 23:05:46,121 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 23:05:46,233 - root - INFO - Aplication done
2023-11-19 23:06:45,625 - root - INFO - I am in the main method...
2023-11-19 23:06:45,625 - root - INFO - Calling  spark object
2023-11-19 23:06:45,625 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 23:06:45,625 - Create_pyspark - INFO - master is local
2023-11-19 23:06:51,147 - Create_pyspark - INFO - Spark object created...
2023-11-19 23:06:51,147 - root - INFO - Validating spark object 
2023-11-19 23:06:51,147 - Validate - WARNING - started the get_current_date method...
2023-11-19 23:06:56,795 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 23:06:56,795 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 23:06:56,795 - root - INFO - reading file which is of > parquet
2023-11-19 23:06:56,795 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:06:57,791 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 23:06:57,791 - root - INFO - displaying file
2023-11-19 23:06:57,795 - root - INFO - validating the dataframe...
2023-11-19 23:06:57,795 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 23:06:58,885 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 23:06:58,885 - root - INFO - checking for the files in the FACT....
2023-11-19 23:06:58,885 - root - INFO - reading file which is of > csv
2023-11-19 23:06:58,885 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:07:03,895 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 23:07:03,895 - root - INFO - displaying the df_fact dataframe
2023-11-19 23:07:03,895 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 23:07:05,026 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 23:07:05,026 - root - INFO - implementing data_processing methods...
2023-11-19 23:07:05,026 - Data_processing - WARNING - data_clean method() start...
2023-11-19 23:07:05,026 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 23:07:05,090 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 23:07:05,114 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 23:07:05,123 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 23:07:05,169 - Data_processing - WARNING - concat first and lname
2023-11-19 23:07:05,201 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 23:07:05,216 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 23:07:05,216 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 23:07:05,252 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 23:07:09,703 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 23:07:09,703 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 23:07:09,703 - root - INFO - validating  schema for the dataframe...
2023-11-19 23:07:09,703 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 23:07:09,703 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 23:07:09,703 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 23:07:09,703 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 23:07:09,703 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 23:07:09,703 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 23:07:09,703 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 23:07:09,703 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:07:09,703 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 23:07:09,711 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 23:07:09,711 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:07:09,711 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 23:07:09,719 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 23:07:09,935 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 23:07:09,935 - root - INFO - data_transformation executing...
2023-11-19 23:07:09,935 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 23:07:09,935 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 23:07:09,983 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 23:07:10,023 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 23:07:10,087 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 23:07:10,087 - root - INFO - displaying the df_report_1
2023-11-19 23:07:10,087 - root - INFO - displaying data_report2 method....
2023-11-19 23:07:10,087 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 23:07:10,087 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 23:07:10,215 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 23:07:10,215 - root - INFO - extracting files to Output...
2023-11-19 23:07:29,947 - root - INFO - extracting files to output completed.....
2023-11-19 23:07:29,955 - root - INFO - writing into hive table
2023-11-19 23:07:29,955 - root - INFO - successfully written into Hive
2023-11-19 23:07:29,955 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 23:07:30,163 - root - INFO - Aplication done
2023-11-19 23:11:44,769 - root - INFO - I am in the main method...
2023-11-19 23:11:44,769 - root - INFO - Calling  spark object
2023-11-19 23:11:44,769 - Create_pyspark - INFO - get_spark_object method started
2023-11-19 23:11:44,769 - Create_pyspark - INFO - master is local
2023-11-19 23:11:50,424 - Create_pyspark - INFO - Spark object created...
2023-11-19 23:11:50,424 - root - INFO - Validating spark object 
2023-11-19 23:11:50,424 - Validate - WARNING - started the get_current_date method...
2023-11-19 23:11:56,255 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 19))]
2023-11-19 23:11:56,255 - Validate - WARNING - Validation  done , go frwd...
2023-11-19 23:11:56,255 - root - INFO - reading file which is of > parquet
2023-11-19 23:11:56,255 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:11:57,028 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-19 23:11:57,028 - root - INFO - displaying file
2023-11-19 23:11:57,028 - root - INFO - validating the dataframe...
2023-11-19 23:11:57,028 - Ingest - WARNING - here to count the records in the df_city
2023-11-19 23:11:58,135 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-19 23:11:58,135 - root - INFO - checking for the files in the FACT....
2023-11-19 23:11:58,135 - root - INFO - reading file which is of > csv
2023-11-19 23:11:58,135 - Ingest - WARNING - load_files method  started...   
2023-11-19 23:12:03,201 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-19 23:12:03,201 - root - INFO - displaying the df_fact dataframe
2023-11-19 23:12:03,201 - Ingest - WARNING - here to count the records in the df_fact
2023-11-19 23:12:04,269 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-19 23:12:04,269 - root - INFO - implementing data_processing methods...
2023-11-19 23:12:04,269 - Data_processing - WARNING - data_clean method() start...
2023-11-19 23:12:04,269 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-19 23:12:04,325 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-19 23:12:04,357 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-19 23:12:04,373 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-19 23:12:04,413 - Data_processing - WARNING - concat first and lname
2023-11-19 23:12:04,444 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-19 23:12:04,460 - Data_processing - WARNING - now check for null values in all columns
2023-11-19 23:12:04,460 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-19 23:12:04,491 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-19 23:12:07,815 - Data_processing - WARNING - successfully droped the null values...
2023-11-19 23:12:07,815 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-19 23:12:07,815 - root - INFO - validating  schema for the dataframe...
2023-11-19 23:12:07,815 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-19 23:12:07,815 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-19 23:12:07,815 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-19 23:12:07,815 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-19 23:12:07,815 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-19 23:12:07,815 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-19 23:12:07,815 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-19 23:12:07,815 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:12:07,815 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-19 23:12:07,823 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-19 23:12:07,823 - Validate - INFO - print_schema done, go frwd...
2023-11-19 23:12:07,823 - root - INFO - checking for null values in dataframe ...after processing
2023-11-19 23:12:07,823 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-19 23:12:08,014 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-19 23:12:08,014 - root - INFO - data_transformation executing...
2023-11-19 23:12:08,026 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-19 23:12:08,026 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-19 23:12:08,066 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-19 23:12:08,106 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-19 23:12:08,172 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-19 23:12:08,172 - root - INFO - displaying the df_report_1
2023-11-19 23:12:08,172 - root - INFO - displaying data_report2 method....
2023-11-19 23:12:08,172 - Data_transformation - WARNING - executing data_report2 method...
2023-11-19 23:12:08,172 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-19 23:12:08,290 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-19 23:12:08,290 - root - INFO - extracting files to Output...
2023-11-19 23:12:27,433 - root - INFO - extracting files to output completed.....
2023-11-19 23:12:27,441 - root - INFO - writing into hive table
2023-11-19 23:12:27,441 - root - INFO - successfully written into Hive
2023-11-19 23:12:27,441 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-19 23:12:42,511 - root - INFO - Aplication done
2023-11-20 00:52:57,194 - root - INFO - I am in the main method...
2023-11-20 00:52:57,195 - root - INFO - Calling  spark object
2023-11-20 00:52:57,196 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 00:52:57,196 - Create_pyspark - INFO - master is local
2023-11-20 00:53:11,178 - Create_pyspark - INFO - Spark object created...
2023-11-20 00:53:11,178 - root - INFO - Validating spark object 
2023-11-20 00:53:11,183 - Validate - WARNING - started the get_current_date method...
2023-11-20 00:53:19,702 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 00:53:19,702 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 00:53:19,702 - root - INFO - reading file which is of > parquet
2023-11-20 00:53:19,702 - Ingest - WARNING - load_files method  started...   
2023-11-20 00:53:20,785 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 00:53:20,786 - root - INFO - displaying file
2023-11-20 00:53:20,787 - root - INFO - validating the dataframe...
2023-11-20 00:53:20,789 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 00:53:22,991 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 00:53:22,992 - root - INFO - checking for the files in the FACT....
2023-11-20 00:53:22,992 - root - INFO - reading file which is of > csv
2023-11-20 00:53:22,992 - Ingest - WARNING - load_files method  started...   
2023-11-20 00:53:32,284 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 00:53:32,284 - root - INFO - displaying the df_fact dataframe
2023-11-20 00:53:32,284 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 00:53:33,622 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 00:53:33,622 - root - INFO - implementing data_processing methods...
2023-11-20 00:53:33,632 - Data_processing - WARNING - data_clean method() start...
2023-11-20 00:53:33,632 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 00:53:33,697 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 00:53:33,731 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 00:53:33,750 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 00:53:33,808 - Data_processing - WARNING - concat first and lname
2023-11-20 00:53:33,846 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 00:53:33,862 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 00:53:33,863 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 00:53:33,894 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 00:53:38,677 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 00:53:38,677 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 00:53:38,678 - root - INFO - validating  schema for the dataframe...
2023-11-20 00:53:38,680 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 00:53:38,682 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 00:53:38,682 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 00:53:38,683 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 00:53:38,683 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 00:53:38,683 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 00:53:38,683 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 00:53:38,683 - Validate - INFO - print_schema done, go frwd...
2023-11-20 00:53:38,683 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 00:53:38,685 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 00:53:38,685 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 00:53:38,685 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 00:53:38,685 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 00:53:38,685 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 00:53:38,686 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 00:53:38,686 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 00:53:38,686 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 00:53:38,686 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 00:53:38,686 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 00:53:38,686 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 00:53:38,686 - Validate - INFO - print_schema done, go frwd...
2023-11-20 00:53:38,686 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 00:53:38,686 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 00:53:38,901 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 00:53:38,901 - root - INFO - data_transformation executing...
2023-11-20 00:53:38,901 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 00:53:38,901 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 00:53:38,967 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 00:53:38,999 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 00:53:39,095 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 00:53:39,095 - root - INFO - displaying the df_report_1
2023-11-20 00:53:39,107 - root - INFO - displaying data_report2 method....
2023-11-20 00:53:39,107 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 00:53:39,107 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 00:53:39,375 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 00:53:39,375 - root - INFO - extracting files to Output...
2023-11-20 00:54:07,487 - root - INFO - extracting files to output completed.....
2023-11-20 00:54:07,489 - root - INFO - writing into hive table
2023-11-20 00:54:07,489 - root - INFO - successfully written into Hive
2023-11-20 00:54:07,491 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 00:54:07,659 - root - INFO - Aplication done
2023-11-20 00:55:26,451 - root - INFO - I am in the main method...
2023-11-20 00:55:26,451 - root - INFO - Calling  spark object
2023-11-20 00:55:26,452 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 00:55:26,452 - Create_pyspark - INFO - master is local
2023-11-20 00:55:36,839 - Create_pyspark - INFO - Spark object created...
2023-11-20 00:55:36,839 - root - INFO - Validating spark object 
2023-11-20 00:55:36,839 - Validate - WARNING - started the get_current_date method...
2023-11-20 00:55:42,673 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 00:55:42,673 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 00:55:42,673 - root - INFO - reading file which is of > parquet
2023-11-20 00:55:42,673 - Ingest - WARNING - load_files method  started...   
2023-11-20 00:55:43,408 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 00:55:43,408 - root - INFO - displaying file
2023-11-20 00:55:43,408 - root - INFO - validating the dataframe...
2023-11-20 00:55:43,408 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 00:55:44,383 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 00:55:44,383 - root - INFO - checking for the files in the FACT....
2023-11-20 00:55:44,383 - root - INFO - reading file which is of > csv
2023-11-20 00:55:44,383 - Ingest - WARNING - load_files method  started...   
2023-11-20 00:55:49,659 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 00:55:49,659 - root - INFO - displaying the df_fact dataframe
2023-11-20 00:55:49,659 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 00:55:50,923 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 00:55:50,924 - root - INFO - implementing data_processing methods...
2023-11-20 00:55:50,929 - Data_processing - WARNING - data_clean method() start...
2023-11-20 00:55:50,929 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 00:55:50,992 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 00:55:51,019 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 00:55:51,031 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 00:55:51,078 - Data_processing - WARNING - concat first and lname
2023-11-20 00:55:51,093 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 00:55:51,122 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 00:55:51,122 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 00:55:51,148 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 00:55:54,929 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 00:55:54,929 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 00:55:54,929 - root - INFO - validating  schema for the dataframe...
2023-11-20 00:55:54,930 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 00:55:54,931 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 00:55:54,931 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 00:55:54,931 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 00:55:54,931 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 00:55:54,931 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 00:55:54,932 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 00:55:54,932 - Validate - INFO - print_schema done, go frwd...
2023-11-20 00:55:54,932 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 00:55:54,933 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 00:55:54,934 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 00:55:54,934 - Validate - INFO - print_schema done, go frwd...
2023-11-20 00:55:54,935 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 00:55:54,935 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 00:55:55,104 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 00:55:55,104 - root - INFO - data_transformation executing...
2023-11-20 00:55:55,104 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 00:55:55,116 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 00:55:55,158 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 00:55:55,199 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 00:55:55,256 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 00:55:55,256 - root - INFO - displaying the df_report_1
2023-11-20 00:55:55,256 - root - INFO - displaying data_report2 method....
2023-11-20 00:55:55,271 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 00:55:55,271 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 00:55:55,409 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 00:55:55,409 - root - INFO - extracting files to Output...
2023-11-20 00:56:17,296 - root - INFO - extracting files to output completed.....
2023-11-20 00:56:17,297 - root - INFO - writing into hive table
2023-11-20 00:56:17,297 - root - INFO - successfully written into Hive
2023-11-20 00:56:17,299 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 00:56:17,403 - root - INFO - Aplication done
2023-11-20 00:59:59,429 - root - INFO - I am in the main method...
2023-11-20 00:59:59,429 - root - INFO - Calling  spark object
2023-11-20 00:59:59,429 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 00:59:59,429 - Create_pyspark - INFO - master is local
2023-11-20 01:00:10,557 - Create_pyspark - INFO - Spark object created...
2023-11-20 01:00:10,557 - root - INFO - Validating spark object 
2023-11-20 01:00:10,558 - Validate - WARNING - started the get_current_date method...
2023-11-20 01:00:18,628 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 01:00:18,628 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 01:00:18,628 - root - INFO - reading file which is of > parquet
2023-11-20 01:00:18,636 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:00:19,871 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 01:00:19,872 - root - INFO - displaying file
2023-11-20 01:00:19,872 - root - INFO - validating the dataframe...
2023-11-20 01:00:19,872 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 01:00:21,258 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 01:00:21,259 - root - INFO - checking for the files in the FACT....
2023-11-20 01:00:21,266 - root - INFO - reading file which is of > csv
2023-11-20 01:00:21,266 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:00:27,040 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 01:00:27,040 - root - INFO - displaying the df_fact dataframe
2023-11-20 01:00:27,042 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 01:00:28,394 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 01:00:28,394 - root - INFO - implementing data_processing methods...
2023-11-20 01:00:28,407 - Data_processing - WARNING - data_clean method() start...
2023-11-20 01:00:28,407 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 01:00:28,475 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 01:00:28,504 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 01:00:28,526 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 01:00:28,584 - Data_processing - WARNING - concat first and lname
2023-11-20 01:00:28,625 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 01:00:28,642 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 01:00:28,643 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 01:00:28,678 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 01:00:32,157 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 01:00:32,157 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 01:00:32,157 - root - INFO - validating  schema for the dataframe...
2023-11-20 01:00:32,159 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 01:00:32,160 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 01:00:32,160 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 01:00:32,160 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 01:00:32,160 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 01:00:32,161 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 01:00:32,161 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 01:00:32,161 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:00:32,161 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 01:00:32,167 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 01:00:32,168 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 01:00:32,168 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 01:00:32,168 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 01:00:32,168 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 01:00:32,168 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:00:32,168 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 01:00:32,169 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 01:00:32,395 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 01:00:32,395 - root - INFO - data_transformation executing...
2023-11-20 01:00:32,415 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 01:00:32,416 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 01:00:32,468 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 01:00:32,521 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 01:00:32,595 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 01:00:32,595 - root - INFO - displaying the df_report_1
2023-11-20 01:00:32,609 - root - INFO - displaying data_report2 method....
2023-11-20 01:00:32,609 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 01:00:32,609 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 01:00:32,740 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 01:00:32,740 - root - INFO - extracting files to Output...
2023-11-20 01:00:54,604 - root - INFO - extracting files to output completed.....
2023-11-20 01:00:54,605 - root - INFO - writing into hive table
2023-11-20 01:00:54,606 - root - INFO - successfully written into Hive
2023-11-20 01:00:54,608 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 01:00:54,700 - root - INFO - Aplication done
2023-11-20 01:05:17,651 - root - INFO - I am in the main method...
2023-11-20 01:05:17,651 - root - INFO - Calling  spark object
2023-11-20 01:05:17,651 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 01:05:17,651 - Create_pyspark - INFO - master is local
2023-11-20 01:05:28,479 - Create_pyspark - INFO - Spark object created...
2023-11-20 01:05:28,479 - root - INFO - Validating spark object 
2023-11-20 01:05:28,479 - Validate - WARNING - started the get_current_date method...
2023-11-20 01:05:34,325 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 01:05:34,325 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 01:05:34,325 - root - INFO - reading file which is of > parquet
2023-11-20 01:05:34,326 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:05:35,306 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 01:05:35,306 - root - INFO - displaying file
2023-11-20 01:05:35,307 - root - INFO - validating the dataframe...
2023-11-20 01:05:35,307 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 01:05:36,462 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 01:05:36,462 - root - INFO - checking for the files in the FACT....
2023-11-20 01:05:36,462 - root - INFO - reading file which is of > csv
2023-11-20 01:05:36,462 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:05:40,237 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 01:05:40,237 - root - INFO - displaying the df_fact dataframe
2023-11-20 01:05:40,238 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 01:05:41,625 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 01:05:41,625 - root - INFO - implementing data_processing methods...
2023-11-20 01:05:41,633 - Data_processing - WARNING - data_clean method() start...
2023-11-20 01:05:41,633 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 01:05:41,690 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 01:05:41,723 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 01:05:41,741 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 01:05:41,776 - Data_processing - WARNING - concat first and lname
2023-11-20 01:05:41,807 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 01:05:41,823 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 01:05:41,823 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 01:05:41,854 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 01:05:44,484 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 01:05:44,484 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 01:05:44,484 - root - INFO - validating  schema for the dataframe...
2023-11-20 01:05:44,499 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 01:05:44,500 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 01:05:44,501 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 01:05:44,501 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 01:05:44,501 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 01:05:44,501 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 01:05:44,501 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 01:05:44,501 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:05:44,501 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 01:05:44,503 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 01:05:44,503 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 01:05:44,503 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 01:05:44,503 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 01:05:44,503 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 01:05:44,504 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 01:05:44,504 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 01:05:44,504 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 01:05:44,504 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 01:05:44,504 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 01:05:44,504 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 01:05:44,504 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:05:44,504 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 01:05:44,504 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 01:05:44,702 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 01:05:44,702 - root - INFO - data_transformation executing...
2023-11-20 01:05:44,702 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 01:05:44,702 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 01:05:44,754 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 01:05:44,809 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 01:05:44,871 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 01:05:44,871 - root - INFO - displaying the df_report_1
2023-11-20 01:05:44,876 - root - INFO - displaying data_report2 method....
2023-11-20 01:05:44,876 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 01:05:44,876 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 01:05:44,990 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 01:05:44,990 - root - INFO - extracting files to Output...
2023-11-20 01:06:06,127 - root - INFO - extracting files to output completed.....
2023-11-20 01:06:06,129 - root - INFO - writing into hive table
2023-11-20 01:06:06,131 - root - INFO - successfully written into Hive
2023-11-20 01:06:06,133 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 01:06:06,224 - root - INFO - Aplication done
2023-11-20 01:08:39,243 - root - INFO - I am in the main method...
2023-11-20 01:08:39,243 - root - INFO - Calling  spark object
2023-11-20 01:08:39,244 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 01:08:39,244 - Create_pyspark - INFO - master is local
2023-11-20 01:08:50,296 - Create_pyspark - INFO - Spark object created...
2023-11-20 01:08:50,296 - root - INFO - Validating spark object 
2023-11-20 01:08:50,296 - Validate - WARNING - started the get_current_date method...
2023-11-20 01:08:56,282 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 01:08:56,282 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 01:08:56,282 - root - INFO - reading file which is of > parquet
2023-11-20 01:08:56,282 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:08:57,144 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 01:08:57,144 - root - INFO - displaying file
2023-11-20 01:08:57,144 - root - INFO - validating the dataframe...
2023-11-20 01:08:57,144 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 01:08:59,165 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 01:08:59,166 - root - INFO - checking for the files in the FACT....
2023-11-20 01:08:59,211 - root - INFO - reading file which is of > csv
2023-11-20 01:08:59,211 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:09:04,644 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 01:09:04,644 - root - INFO - displaying the df_fact dataframe
2023-11-20 01:09:04,645 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 01:09:05,958 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 01:09:05,958 - root - INFO - implementing data_processing methods...
2023-11-20 01:09:05,972 - Data_processing - WARNING - data_clean method() start...
2023-11-20 01:09:05,972 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 01:09:06,038 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 01:09:06,090 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 01:09:06,120 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 01:09:06,176 - Data_processing - WARNING - concat first and lname
2023-11-20 01:09:06,257 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 01:09:06,279 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 01:09:06,279 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 01:09:06,326 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 01:09:09,606 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 01:09:09,606 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 01:09:09,606 - root - INFO - validating  schema for the dataframe...
2023-11-20 01:09:09,614 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 01:09:09,615 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 01:09:09,616 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 01:09:09,616 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 01:09:09,616 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 01:09:09,616 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 01:09:09,616 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 01:09:09,616 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:09:09,616 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 01:09:09,618 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 01:09:09,618 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 01:09:09,618 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 01:09:09,618 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 01:09:09,618 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 01:09:09,619 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 01:09:09,619 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 01:09:09,619 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 01:09:09,619 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 01:09:09,619 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 01:09:09,619 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 01:09:09,619 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:09:09,619 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 01:09:09,620 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 01:09:09,895 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 01:09:09,895 - root - INFO - data_transformation executing...
2023-11-20 01:09:09,905 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 01:09:09,906 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 01:09:09,961 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 01:09:10,018 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 01:09:10,116 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 01:09:10,116 - root - INFO - displaying the df_report_1
2023-11-20 01:09:10,116 - root - INFO - displaying data_report2 method....
2023-11-20 01:09:10,119 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 01:09:10,119 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 01:09:10,258 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 01:09:10,258 - root - INFO - extracting files to Output...
2023-11-20 01:09:33,378 - root - INFO - extracting files to output completed.....
2023-11-20 01:09:33,382 - root - INFO - writing into hive table
2023-11-20 01:09:33,382 - root - INFO - successfully written into Hive
2023-11-20 01:09:33,384 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 01:09:33,479 - root - INFO - Aplication done
2023-11-20 01:11:19,415 - root - INFO - I am in the main method...
2023-11-20 01:11:19,415 - root - INFO - Calling  spark object
2023-11-20 01:11:19,415 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 01:11:19,415 - Create_pyspark - INFO - master is local
2023-11-20 01:11:30,469 - Create_pyspark - INFO - Spark object created...
2023-11-20 01:11:30,469 - root - INFO - Validating spark object 
2023-11-20 01:11:30,469 - Validate - WARNING - started the get_current_date method...
2023-11-20 01:11:37,422 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 01:11:37,422 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 01:11:37,422 - root - INFO - reading file which is of > parquet
2023-11-20 01:11:37,422 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:11:38,631 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 01:11:38,631 - root - INFO - displaying file
2023-11-20 01:11:38,632 - root - INFO - validating the dataframe...
2023-11-20 01:11:38,633 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 01:11:40,302 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 01:11:40,302 - root - INFO - checking for the files in the FACT....
2023-11-20 01:11:40,305 - root - INFO - reading file which is of > csv
2023-11-20 01:11:40,306 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:11:45,690 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 01:11:45,691 - root - INFO - displaying the df_fact dataframe
2023-11-20 01:11:45,691 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 01:11:47,924 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 01:11:47,924 - root - INFO - implementing data_processing methods...
2023-11-20 01:11:47,940 - Data_processing - WARNING - data_clean method() start...
2023-11-20 01:11:47,940 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 01:11:48,017 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 01:11:48,047 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 01:11:48,071 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 01:11:48,148 - Data_processing - WARNING - concat first and lname
2023-11-20 01:11:48,215 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 01:11:48,296 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 01:11:48,296 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 01:11:48,343 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 01:11:51,414 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 01:11:51,414 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 01:11:51,415 - root - INFO - validating  schema for the dataframe...
2023-11-20 01:11:51,415 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 01:11:51,417 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 01:11:51,417 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 01:11:51,417 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 01:11:51,417 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 01:11:51,417 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 01:11:51,417 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 01:11:51,417 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:11:51,418 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 01:11:51,419 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 01:11:51,420 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 01:11:51,421 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 01:11:51,421 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:11:51,421 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 01:11:51,421 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 01:11:51,618 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 01:11:51,634 - root - INFO - data_transformation executing...
2023-11-20 01:11:51,634 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 01:11:51,634 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 01:11:51,680 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 01:11:51,707 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 01:11:51,808 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 01:11:51,808 - root - INFO - displaying the df_report_1
2023-11-20 01:11:51,808 - root - INFO - displaying data_report2 method....
2023-11-20 01:11:51,808 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 01:11:51,808 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 01:11:51,924 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 01:11:51,924 - root - INFO - extracting files to Output...
2023-11-20 01:12:13,180 - root - INFO - extracting files to output completed.....
2023-11-20 01:12:13,181 - root - INFO - writing into hive table
2023-11-20 01:12:13,181 - root - INFO - successfully written into Hive
2023-11-20 01:12:13,185 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 01:12:13,279 - root - INFO - Aplication done
2023-11-20 01:15:57,731 - root - INFO - I am in the main method...
2023-11-20 01:15:57,731 - root - INFO - Calling  spark object
2023-11-20 01:15:57,732 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 01:15:57,732 - Create_pyspark - INFO - master is local
2023-11-20 01:16:08,497 - Create_pyspark - INFO - Spark object created...
2023-11-20 01:16:08,497 - root - INFO - Validating spark object 
2023-11-20 01:16:08,497 - Validate - WARNING - started the get_current_date method...
2023-11-20 01:16:14,460 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 01:16:14,460 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 01:16:14,460 - root - INFO - reading file which is of > parquet
2023-11-20 01:16:14,476 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:16:15,417 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 01:16:15,417 - root - INFO - displaying file
2023-11-20 01:16:15,418 - root - INFO - validating the dataframe...
2023-11-20 01:16:15,418 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 01:16:16,579 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 01:16:16,579 - root - INFO - checking for the files in the FACT....
2023-11-20 01:16:16,579 - root - INFO - reading file which is of > csv
2023-11-20 01:16:16,594 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:16:21,063 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 01:16:21,063 - root - INFO - displaying the df_fact dataframe
2023-11-20 01:16:21,075 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 01:16:22,652 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 01:16:22,652 - root - INFO - implementing data_processing methods...
2023-11-20 01:16:22,660 - Data_processing - WARNING - data_clean method() start...
2023-11-20 01:16:22,660 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 01:16:22,722 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 01:16:22,747 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 01:16:22,767 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 01:16:22,823 - Data_processing - WARNING - concat first and lname
2023-11-20 01:16:22,854 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 01:16:22,867 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 01:16:22,867 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 01:16:22,901 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 01:16:26,677 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 01:16:26,677 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 01:16:26,678 - root - INFO - validating  schema for the dataframe...
2023-11-20 01:16:26,688 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 01:16:26,690 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 01:16:26,690 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 01:16:26,690 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 01:16:26,690 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 01:16:26,690 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 01:16:26,690 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 01:16:26,691 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:16:26,691 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 01:16:26,697 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 01:16:26,697 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 01:16:26,698 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 01:16:26,698 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:16:26,699 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 01:16:26,710 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 01:16:27,001 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 01:16:27,001 - root - INFO - data_transformation executing...
2023-11-20 01:16:27,013 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 01:16:27,014 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 01:16:27,064 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 01:16:27,106 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 01:16:27,177 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 01:16:27,177 - root - INFO - displaying the df_report_1
2023-11-20 01:16:27,177 - root - INFO - displaying data_report2 method....
2023-11-20 01:16:27,177 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 01:16:27,188 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 01:16:27,323 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 01:16:27,323 - root - INFO - extracting files to Output...
2023-11-20 01:16:48,816 - root - INFO - extracting files to output completed.....
2023-11-20 01:16:48,817 - root - INFO - writing into hive table
2023-11-20 01:16:48,817 - root - INFO - successfully written into Hive
2023-11-20 01:16:48,819 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 01:16:48,965 - root - INFO - Aplication done
2023-11-20 01:19:35,005 - root - INFO - I am in the main method...
2023-11-20 01:19:35,005 - root - INFO - Calling  spark object
2023-11-20 01:19:35,005 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 01:19:35,005 - Create_pyspark - INFO - master is local
2023-11-20 01:19:46,179 - root - INFO - I am in the main method...
2023-11-20 01:19:46,179 - root - INFO - Calling  spark object
2023-11-20 01:19:46,179 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 01:19:46,179 - Create_pyspark - INFO - master is local
2023-11-20 01:19:58,212 - Create_pyspark - INFO - Spark object created...
2023-11-20 01:19:58,213 - root - INFO - Validating spark object 
2023-11-20 01:19:58,213 - Validate - WARNING - started the get_current_date method...
2023-11-20 01:20:03,823 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 01:20:03,823 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 01:20:03,823 - root - INFO - reading file which is of > parquet
2023-11-20 01:20:03,823 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:20:04,582 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 01:20:04,582 - root - INFO - displaying file
2023-11-20 01:20:04,583 - root - INFO - validating the dataframe...
2023-11-20 01:20:04,583 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 01:20:05,671 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 01:20:05,671 - root - INFO - checking for the files in the FACT....
2023-11-20 01:20:05,671 - root - INFO - reading file which is of > csv
2023-11-20 01:20:05,672 - Ingest - WARNING - load_files method  started...   
2023-11-20 01:20:09,467 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 01:20:09,468 - root - INFO - displaying the df_fact dataframe
2023-11-20 01:20:09,468 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 01:20:10,318 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 01:20:10,319 - root - INFO - implementing data_processing methods...
2023-11-20 01:20:10,331 - Data_processing - WARNING - data_clean method() start...
2023-11-20 01:20:10,331 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 01:20:10,399 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 01:20:10,432 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 01:20:10,453 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 01:20:10,506 - Data_processing - WARNING - concat first and lname
2023-11-20 01:20:10,547 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 01:20:10,563 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 01:20:10,563 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 01:20:10,595 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 01:20:13,036 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 01:20:13,036 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 01:20:13,036 - root - INFO - validating  schema for the dataframe...
2023-11-20 01:20:13,043 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 01:20:13,045 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 01:20:13,045 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 01:20:13,045 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 01:20:13,045 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 01:20:13,045 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 01:20:13,046 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 01:20:13,046 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:20:13,046 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 01:20:13,047 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 01:20:13,047 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 01:20:13,048 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 01:20:13,048 - Validate - INFO - print_schema done, go frwd...
2023-11-20 01:20:13,048 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 01:20:13,049 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 01:20:13,294 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 01:20:13,294 - root - INFO - data_transformation executing...
2023-11-20 01:20:13,296 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 01:20:13,297 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 01:20:13,348 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 01:20:13,392 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 01:20:13,459 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 01:20:13,459 - root - INFO - displaying the df_report_1
2023-11-20 01:20:13,460 - root - INFO - displaying data_report2 method....
2023-11-20 01:20:13,461 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 01:20:13,461 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 01:20:13,601 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 01:20:13,601 - root - INFO - extracting files to Output...
2023-11-20 01:20:32,020 - root - INFO - extracting files to output completed.....
2023-11-20 01:20:32,021 - root - INFO - writing into hive table
2023-11-20 01:20:32,021 - root - INFO - successfully written into Hive
2023-11-20 01:20:32,023 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 01:20:39,404 - root - INFO - Now write DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into SQL Server
2023-11-20 01:20:45,625 - root - INFO - successfully data inserted into table Sql server...
2023-11-20 01:20:45,626 - root - INFO - Aplication done
2023-11-20 21:36:47,137 - root - INFO - I am in the main method...
2023-11-20 21:36:47,137 - root - INFO - Calling  spark object
2023-11-20 21:36:47,138 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 21:36:47,138 - Create_pyspark - INFO - master is local
2023-11-20 21:36:58,978 - Create_pyspark - INFO - Spark object created...
2023-11-20 21:36:58,978 - root - INFO - Validating spark object 
2023-11-20 21:36:58,978 - Validate - WARNING - started the get_current_date method...
2023-11-20 21:37:05,358 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 21:37:05,358 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 21:37:05,359 - root - INFO - reading file which is of > parquet
2023-11-20 21:37:05,359 - Ingest - WARNING - load_files method  started...   
2023-11-20 21:37:06,398 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 21:37:06,398 - root - INFO - displaying file
2023-11-20 21:37:06,400 - root - INFO - validating the dataframe...
2023-11-20 21:37:06,401 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 21:37:07,501 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-20 21:37:07,501 - root - INFO - checking for the files in the FACT....
2023-11-20 21:37:07,503 - root - INFO - reading file which is of > csv
2023-11-20 21:37:07,503 - Ingest - WARNING - load_files method  started...   
2023-11-20 21:37:11,438 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 21:37:11,439 - root - INFO - displaying the df_fact dataframe
2023-11-20 21:37:11,439 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 21:37:12,636 - Ingest - WARNING - Number  of records present in the DataFrame[npi: int, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: int, total_claim_count: int, total_30_day_fill_count: double, total_day_supply: int, total_drug_cost: double, bene_count_ge65: int, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: int, ge65_suppress_flag: string, total_30_day_fill_count_ge65: double, total_day_supply_ge65: int, total_drug_cost_ge65: double, years_of_exp: string] are :: 1329329 
2023-11-20 21:37:12,636 - root - INFO - implementing data_processing methods...
2023-11-20 21:37:12,637 - Data_processing - WARNING - data_clean method() start...
2023-11-20 21:37:12,637 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 21:37:12,690 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 21:37:12,719 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 21:37:12,741 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 21:37:12,791 - Data_processing - WARNING - concat first and lname
2023-11-20 21:37:12,825 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 21:37:12,839 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 21:37:12,839 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 21:37:12,868 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 21:37:15,362 - Data_processing - WARNING - successfully droped the null values...
2023-11-20 21:37:15,363 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-20 21:37:15,363 - root - INFO - validating  schema for the dataframe...
2023-11-20 21:37:15,363 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-20 21:37:15,364 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-20 21:37:15,365 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-20 21:37:15,365 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-20 21:37:15,365 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-20 21:37:15,365 - Validate - INFO - 	StructField('population', IntegerType(), True)
2023-11-20 21:37:15,365 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-20 21:37:15,366 - Validate - INFO - print_schema done, go frwd...
2023-11-20 21:37:15,366 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-20 21:37:15,367 - Validate - INFO - 	StructField('presc_id', IntegerType(), True)
2023-11-20 21:37:15,367 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-20 21:37:15,367 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-20 21:37:15,367 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('tx_cnt', IntegerType(), True)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('total_day_supply', IntegerType(), True)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('total_drug_cost', DoubleType(), True)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-20 21:37:15,368 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-20 21:37:15,368 - Validate - INFO - print_schema done, go frwd...
2023-11-20 21:37:15,368 - root - INFO - checking for null values in dataframe ...after processing
2023-11-20 21:37:15,369 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-20 21:37:15,579 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-20 21:37:15,579 - root - INFO - data_transformation executing...
2023-11-20 21:37:15,580 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-20 21:37:15,581 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-11-20 21:37:15,635 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-20 21:37:15,681 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-20 21:37:15,758 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-20 21:37:15,759 - root - INFO - displaying the df_report_1
2023-11-20 21:37:15,763 - root - INFO - displaying data_report2 method....
2023-11-20 21:37:15,766 - Data_transformation - WARNING - executing data_report2 method...
2023-11-20 21:37:15,766 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-20 21:37:15,908 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-20 21:37:15,908 - root - INFO - extracting files to Output...
2023-11-20 21:37:36,033 - root - INFO - extracting files to output completed.....
2023-11-20 21:37:36,041 - root - INFO - writing into hive table
2023-11-20 21:37:36,044 - root - INFO - successfully written into Hive
2023-11-20 21:37:36,047 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into SQL Server
2023-11-20 21:37:45,832 - root - INFO - Now write DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into SQL Server
2023-11-20 21:37:53,235 - root - INFO - successfully data inserted into table Sql server...
2023-11-20 21:37:53,236 - root - INFO - Aplication done
2023-11-20 22:36:03,043 - root - INFO - I am in the main method...
2023-11-20 22:36:03,044 - root - INFO - Calling  spark object
2023-11-20 22:36:03,044 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 22:36:03,044 - Create_pyspark - INFO - master is local
2023-11-20 22:36:15,269 - Create_pyspark - INFO - Spark object created...
2023-11-20 22:36:15,269 - root - INFO - Validating spark object 
2023-11-20 22:36:15,269 - Validate - WARNING - started the get_current_date method...
2023-11-20 22:36:22,211 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 22:36:22,211 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 22:36:22,212 - root - INFO - reading file which is of > parquet
2023-11-20 22:36:22,212 - Ingest - WARNING - load_files method  started...   
2023-11-20 22:36:23,189 - root - INFO - Aplication done
2023-11-20 22:45:24,754 - root - INFO - I am in the main method...
2023-11-20 22:45:24,754 - root - INFO - Calling  spark object
2023-11-20 22:45:24,754 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 22:45:24,754 - Create_pyspark - INFO - master is local
2023-11-20 22:45:31,175 - root - INFO - I am in the main method...
2023-11-20 22:45:31,176 - root - INFO - Calling  spark object
2023-11-20 22:45:31,176 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 22:45:31,176 - Create_pyspark - INFO - master is local
2023-11-20 22:45:37,165 - Create_pyspark - INFO - Spark object created...
2023-11-20 22:45:37,165 - root - INFO - Validating spark object 
2023-11-20 22:45:37,165 - Validate - WARNING - started the get_current_date method...
2023-11-20 22:45:43,807 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 22:45:43,807 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 22:45:43,807 - root - INFO - reading file which is of > parquet
2023-11-20 22:45:43,808 - Ingest - WARNING - load_files method  started...   
2023-11-20 22:45:45,129 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 22:45:45,129 - root - INFO - displaying file
2023-11-20 22:45:48,379 - root - INFO - validating the dataframe...
2023-11-20 22:45:48,380 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 22:45:49,151 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-20 22:45:49,151 - root - INFO - checking for the files in the FACT....
2023-11-20 22:45:49,157 - root - INFO - reading file which is of > csv
2023-11-20 22:45:49,158 - Ingest - WARNING - load_files method  started...   
2023-11-20 22:45:53,926 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 22:45:53,926 - root - INFO - displaying the df_fact dataframe
2023-11-20 22:45:55,657 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 22:45:56,646 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-20 22:45:56,646 - root - INFO - implementing data_processing methods...
2023-11-20 22:45:56,652 - Data_processing - WARNING - data_clean method() start...
2023-11-20 22:45:56,652 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 22:45:56,714 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 22:45:56,731 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 22:45:56,743 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 22:45:56,786 - Data_processing - WARNING - concat first and lname
2023-11-20 22:45:56,820 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 22:45:56,831 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 22:45:56,832 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 22:45:56,857 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 22:46:26,200 - root - INFO - Aplication done
2023-11-20 23:35:45,969 - root - INFO - I am in the main method...
2023-11-20 23:35:45,970 - root - INFO - Calling  spark object
2023-11-20 23:35:45,971 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:35:45,971 - Create_pyspark - INFO - master is local
2023-11-20 23:35:57,789 - Create_pyspark - INFO - Spark object created...
2023-11-20 23:35:57,789 - root - INFO - Validating spark object 
2023-11-20 23:35:57,789 - Validate - WARNING - started the get_current_date method...
2023-11-20 23:36:05,711 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 23:36:05,711 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 23:36:05,711 - root - INFO - reading file which is of > parquet
2023-11-20 23:36:05,712 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:36:07,197 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 23:36:07,197 - root - INFO - displaying file
2023-11-20 23:36:11,104 - root - INFO - validating the dataframe city...
2023-11-20 23:36:11,104 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 23:36:12,250 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-20 23:36:12,251 - root - INFO - checking for the files in the FACT....
2023-11-20 23:36:12,259 - root - INFO - reading file which is of > csv
2023-11-20 23:36:12,260 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:36:16,889 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 23:36:16,889 - root - INFO - displaying the df_fact dataframe
2023-11-20 23:36:19,166 - root - INFO - validating the dataframe fact...
2023-11-20 23:36:19,177 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 23:36:20,188 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-20 23:36:20,189 - root - INFO - implementing data_processing methods...
2023-11-20 23:36:20,198 - root - INFO - Decrypt Data frame city
2023-11-20 23:36:20,440 - root - INFO - Aplication done
2023-11-20 23:39:13,656 - root - INFO - I am in the main method...
2023-11-20 23:39:13,657 - root - INFO - Calling  spark object
2023-11-20 23:39:13,657 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:39:13,657 - Create_pyspark - INFO - master is local
2023-11-20 23:39:24,983 - Create_pyspark - INFO - Spark object created...
2023-11-20 23:39:24,983 - root - INFO - Validating spark object 
2023-11-20 23:39:24,983 - Validate - WARNING - started the get_current_date method...
2023-11-20 23:39:33,656 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 23:39:33,656 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 23:39:33,657 - root - INFO - reading file which is of > parquet
2023-11-20 23:39:33,657 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:39:35,198 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 23:39:35,198 - root - INFO - displaying file
2023-11-20 23:39:39,602 - root - INFO - validating the dataframe city...
2023-11-20 23:39:39,602 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 23:39:40,523 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-20 23:39:40,524 - root - INFO - checking for the files in the FACT....
2023-11-20 23:39:40,533 - root - INFO - reading file which is of > csv
2023-11-20 23:39:40,534 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:39:45,319 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 23:39:45,319 - root - INFO - displaying the df_fact dataframe
2023-11-20 23:39:47,915 - root - INFO - validating the dataframe fact...
2023-11-20 23:39:47,961 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 23:39:49,016 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-20 23:39:49,016 - root - INFO - implementing data_processing methods...
2023-11-20 23:39:49,027 - root - INFO - Decrypt Data frame city
2023-11-20 23:39:54,698 - root - INFO - Decrypt Data frame presc
2023-11-20 23:40:04,517 - Data_processing - WARNING - data_clean method() start...
2023-11-20 23:40:04,518 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 23:40:04,597 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 23:40:04,611 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 23:40:04,620 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 23:40:04,672 - Data_processing - WARNING - concat first and lname
2023-11-20 23:40:04,709 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 23:40:04,723 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 23:40:04,723 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 23:40:04,750 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 23:40:39,117 - root - INFO - Aplication done
2023-11-20 23:43:02,341 - root - INFO - I am in the main method...
2023-11-20 23:43:02,342 - root - INFO - Calling  spark object
2023-11-20 23:43:02,342 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:43:02,342 - Create_pyspark - INFO - master is local
2023-11-20 23:43:07,523 - root - INFO - I am in the main method...
2023-11-20 23:43:07,524 - root - INFO - Calling  spark object
2023-11-20 23:43:07,526 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:43:07,526 - Create_pyspark - INFO - master is local
2023-11-20 23:43:21,039 - Create_pyspark - INFO - Spark object created...
2023-11-20 23:43:21,040 - root - INFO - Validating spark object 
2023-11-20 23:43:21,040 - Validate - WARNING - started the get_current_date method...
2023-11-20 23:43:26,865 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 23:43:26,865 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 23:43:26,866 - root - INFO - reading file which is of > parquet
2023-11-20 23:43:26,866 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:43:28,058 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 23:43:28,058 - root - INFO - displaying file
2023-11-20 23:43:31,885 - root - INFO - validating the dataframe city...
2023-11-20 23:43:31,888 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 23:43:32,898 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-20 23:43:32,898 - root - INFO - checking for the files in the FACT....
2023-11-20 23:43:32,904 - root - INFO - reading file which is of > csv
2023-11-20 23:43:32,905 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:43:36,978 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 23:43:36,978 - root - INFO - displaying the df_fact dataframe
2023-11-20 23:43:39,045 - root - INFO - validating the dataframe fact...
2023-11-20 23:43:39,045 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 23:43:40,003 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-20 23:43:40,003 - root - INFO - implementing data_processing methods...
2023-11-20 23:43:40,013 - root - INFO - Decrypt Data frame city
2023-11-20 23:43:40,210 - root - INFO - Decrypt Data frame presc
2023-11-20 23:43:40,483 - Data_processing - WARNING - data_clean method() start...
2023-11-20 23:43:40,483 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 23:43:40,509 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 23:43:40,521 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 23:43:40,529 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 23:43:40,556 - Data_processing - WARNING - concat first and lname
2023-11-20 23:43:40,579 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 23:43:40,590 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 23:43:40,590 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 23:43:40,613 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 23:44:10,250 - root - INFO - Aplication done
2023-11-20 23:44:56,303 - root - INFO - I am in the main method...
2023-11-20 23:44:56,304 - root - INFO - Calling  spark object
2023-11-20 23:44:56,304 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:44:56,304 - Create_pyspark - INFO - master is local
2023-11-20 23:45:09,231 - Create_pyspark - INFO - Spark object created...
2023-11-20 23:45:09,231 - root - INFO - Validating spark object 
2023-11-20 23:45:09,231 - Validate - WARNING - started the get_current_date method...
2023-11-20 23:45:15,334 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 23:45:15,334 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 23:45:15,335 - root - INFO - reading file which is of > parquet
2023-11-20 23:45:15,335 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:45:16,620 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 23:45:16,620 - root - INFO - displaying file
2023-11-20 23:45:20,338 - root - INFO - validating the dataframe city...
2023-11-20 23:45:20,341 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 23:45:21,265 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-20 23:45:21,265 - root - INFO - checking for the files in the FACT....
2023-11-20 23:45:21,280 - root - INFO - reading file which is of > csv
2023-11-20 23:45:21,281 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:45:28,546 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 23:45:28,546 - root - INFO - displaying the df_fact dataframe
2023-11-20 23:45:32,896 - root - INFO - validating the dataframe fact...
2023-11-20 23:45:32,897 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 23:45:34,463 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-20 23:45:34,463 - root - INFO - implementing data_processing methods...
2023-11-20 23:45:34,471 - root - INFO - Decrypt Data frame city
2023-11-20 23:45:34,660 - root - INFO - Decrypt Data frame presc
2023-11-20 23:45:35,079 - Data_processing - WARNING - data_clean method() start...
2023-11-20 23:45:35,079 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-20 23:45:35,134 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-20 23:45:35,155 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-20 23:45:35,167 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-20 23:45:35,219 - Data_processing - WARNING - concat first and lname
2023-11-20 23:45:35,253 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-20 23:45:35,266 - Data_processing - WARNING - now check for null values in all columns
2023-11-20 23:45:35,266 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-20 23:45:35,298 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-20 23:46:08,357 - root - INFO - Aplication done
2023-11-20 23:55:24,983 - root - INFO - I am in the main method...
2023-11-20 23:55:24,984 - root - INFO - Calling  spark object
2023-11-20 23:55:24,984 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:55:24,984 - Create_pyspark - INFO - master is local
2023-11-20 23:55:36,250 - Create_pyspark - INFO - Spark object created...
2023-11-20 23:55:36,250 - root - INFO - Validating spark object 
2023-11-20 23:55:36,252 - Validate - WARNING - started the get_current_date method...
2023-11-20 23:55:45,691 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 20))]
2023-11-20 23:55:45,691 - Validate - WARNING - Validation  done , go frwd...
2023-11-20 23:55:45,692 - root - INFO - reading file which is of > parquet
2023-11-20 23:55:45,693 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:55:47,227 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-20 23:55:47,228 - root - INFO - displaying file
2023-11-20 23:55:50,821 - root - INFO - validating the dataframe city...
2023-11-20 23:55:50,821 - Ingest - WARNING - here to count the records in the df_city
2023-11-20 23:55:51,783 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-20 23:55:51,784 - root - INFO - checking for the files in the FACT....
2023-11-20 23:55:51,789 - root - INFO - reading file which is of > csv
2023-11-20 23:55:51,790 - Ingest - WARNING - load_files method  started...   
2023-11-20 23:55:57,401 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-20 23:55:57,402 - root - INFO - displaying the df_fact dataframe
2023-11-20 23:55:59,514 - root - INFO - validating the dataframe fact...
2023-11-20 23:55:59,561 - Ingest - WARNING - here to count the records in the df_fact
2023-11-20 23:56:00,584 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-20 23:56:00,584 - root - INFO - implementing data_processing methods...
2023-11-20 23:56:00,591 - root - INFO - Decrypt Data frame city
2023-11-20 23:56:00,603 - root - INFO - Aplication done
2023-11-20 23:59:57,180 - root - INFO - I am in the main method...
2023-11-20 23:59:57,181 - root - INFO - Calling  spark object
2023-11-20 23:59:57,181 - Create_pyspark - INFO - get_spark_object method started
2023-11-20 23:59:57,181 - Create_pyspark - INFO - master is local
2023-11-21 00:00:08,892 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:00:08,892 - root - INFO - Validating spark object 
2023-11-21 00:00:08,892 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:00:16,119 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:00:16,119 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:00:16,119 - root - INFO - reading file which is of > parquet
2023-11-21 00:00:16,119 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:00:17,509 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:00:17,509 - root - INFO - displaying file
2023-11-21 00:00:22,242 - root - INFO - validating the dataframe city...
2023-11-21 00:00:22,243 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:00:23,370 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:00:23,370 - root - INFO - checking for the files in the FACT....
2023-11-21 00:00:23,379 - root - INFO - reading file which is of > csv
2023-11-21 00:00:23,379 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:00:27,803 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:00:27,804 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:00:29,788 - root - INFO - validating the dataframe fact...
2023-11-21 00:00:29,788 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:00:30,647 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:00:30,648 - root - INFO - implementing data_processing methods...
2023-11-21 00:00:30,650 - root - INFO - Decrypt Data frame city
2023-11-21 00:00:32,632 - root - INFO - Decrypt Data frame presc
2023-11-21 00:00:36,248 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:00:36,248 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:00:36,304 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:00:36,324 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:00:36,332 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:00:36,375 - Data_processing - WARNING - concat first and lname
2023-11-21 00:00:36,403 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:00:36,415 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:00:36,415 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:00:36,441 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:01:06,290 - root - INFO - Aplication done
2023-11-21 00:06:37,817 - root - INFO - I am in the main method...
2023-11-21 00:06:37,818 - root - INFO - Calling  spark object
2023-11-21 00:06:37,818 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:06:37,819 - Create_pyspark - INFO - master is local
2023-11-21 00:06:48,812 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:06:48,812 - root - INFO - Validating spark object 
2023-11-21 00:06:48,812 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:06:54,781 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:06:54,781 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:06:54,781 - root - INFO - reading file which is of > parquet
2023-11-21 00:06:54,781 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:06:55,948 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:06:55,948 - root - INFO - displaying file
2023-11-21 00:06:59,508 - root - INFO - validating the dataframe city...
2023-11-21 00:06:59,518 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:07:00,732 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:07:00,732 - root - INFO - checking for the files in the FACT....
2023-11-21 00:07:00,737 - root - INFO - reading file which is of > csv
2023-11-21 00:07:00,738 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:07:05,717 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:07:05,717 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:07:08,470 - root - INFO - validating the dataframe fact...
2023-11-21 00:07:08,471 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:07:09,427 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:07:09,427 - root - INFO - implementing data_processing methods...
2023-11-21 00:07:09,442 - root - INFO - Decrypt Data frame city
2023-11-21 00:07:11,787 - root - INFO - Decrypt Data frame presc
2023-11-21 00:07:14,971 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:07:14,971 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:07:15,021 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:07:15,040 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:07:15,051 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:07:15,094 - Data_processing - WARNING - concat first and lname
2023-11-21 00:07:15,121 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:07:15,133 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:07:15,133 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:07:15,157 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:07:43,748 - root - INFO - Aplication done
2023-11-21 00:12:36,355 - root - INFO - I am in the main method...
2023-11-21 00:12:36,356 - root - INFO - Calling  spark object
2023-11-21 00:12:36,356 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:12:36,356 - Create_pyspark - INFO - master is local
2023-11-21 00:12:47,798 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:12:47,799 - root - INFO - Validating spark object 
2023-11-21 00:12:47,799 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:13:00,264 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:13:00,264 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:13:00,264 - root - INFO - reading file which is of > parquet
2023-11-21 00:13:00,265 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:13:01,984 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:13:01,984 - root - INFO - displaying file
2023-11-21 00:13:02,000 - root - INFO - validating the dataframe city...
2023-11-21 00:13:02,000 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:13:03,644 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:13:03,644 - root - INFO - checking for the files in the FACT....
2023-11-21 00:13:03,652 - root - INFO - reading file which is of > csv
2023-11-21 00:13:03,652 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:13:08,290 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:13:08,290 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:13:08,303 - root - INFO - validating the dataframe fact...
2023-11-21 00:13:08,303 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:13:09,753 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:13:09,753 - root - INFO - implementing data_processing methods...
2023-11-21 00:13:09,764 - root - INFO - Decrypt Data frame city
2023-11-21 00:13:10,005 - root - INFO - Decrypt Data frame presc
2023-11-21 00:13:10,400 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:13:10,400 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:13:10,455 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:13:10,491 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:13:10,504 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:13:10,539 - Data_processing - WARNING - concat first and lname
2023-11-21 00:13:10,570 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:13:10,582 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:13:10,582 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:13:10,623 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:13:42,747 - root - INFO - Aplication done
2023-11-21 00:19:53,526 - root - INFO - I am in the main method...
2023-11-21 00:19:53,526 - root - INFO - Calling  spark object
2023-11-21 00:19:53,527 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:19:53,527 - Create_pyspark - INFO - master is local
2023-11-21 00:20:06,903 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:20:06,903 - root - INFO - Validating spark object 
2023-11-21 00:20:06,903 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:20:12,464 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:20:12,464 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:20:12,464 - root - INFO - reading file which is of > parquet
2023-11-21 00:20:12,464 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:20:13,883 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:20:13,884 - root - INFO - displaying file
2023-11-21 00:20:13,901 - root - INFO - validating the dataframe city...
2023-11-21 00:20:13,901 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:20:15,242 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:20:15,243 - root - INFO - checking for the files in the FACT....
2023-11-21 00:20:15,243 - root - INFO - reading file which is of > csv
2023-11-21 00:20:15,245 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:20:19,361 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:20:19,361 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:20:19,363 - root - INFO - validating the dataframe fact...
2023-11-21 00:20:19,364 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:20:20,300 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:20:20,300 - root - INFO - implementing data_processing methods...
2023-11-21 00:20:20,300 - root - INFO - Decrypt Data frame city
2023-11-21 00:20:20,482 - root - INFO - Decrypt Data frame presc
2023-11-21 00:20:20,805 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:20:20,805 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:20:20,838 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:20:20,859 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:20:20,871 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:20:20,913 - Data_processing - WARNING - concat first and lname
2023-11-21 00:20:20,944 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:20:20,956 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:20:20,956 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:20:20,984 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:20:47,874 - root - INFO - Aplication done
2023-11-21 00:22:04,166 - root - INFO - I am in the main method...
2023-11-21 00:22:04,166 - root - INFO - Calling  spark object
2023-11-21 00:22:04,167 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:22:04,167 - Create_pyspark - INFO - master is local
2023-11-21 00:22:17,412 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:22:17,412 - root - INFO - Validating spark object 
2023-11-21 00:22:17,446 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:22:23,024 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:22:23,024 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:22:23,024 - root - INFO - reading file which is of > parquet
2023-11-21 00:22:23,024 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:22:24,377 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:22:24,377 - root - INFO - displaying file
2023-11-21 00:22:24,379 - root - INFO - validating the dataframe city...
2023-11-21 00:22:24,379 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:22:25,658 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:22:25,658 - root - INFO - checking for the files in the FACT....
2023-11-21 00:22:25,661 - root - INFO - reading file which is of > csv
2023-11-21 00:22:25,662 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:22:29,830 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:22:29,830 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:22:29,838 - root - INFO - validating the dataframe fact...
2023-11-21 00:22:29,838 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:22:31,337 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:22:31,337 - root - INFO - implementing data_processing methods...
2023-11-21 00:22:31,346 - root - INFO - Decrypt Data frame city
2023-11-21 00:22:31,578 - root - INFO - Decrypt Data frame presc
2023-11-21 00:22:31,844 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:22:31,844 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:22:31,874 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:22:31,885 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:22:31,892 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:22:31,921 - Data_processing - WARNING - concat first and lname
2023-11-21 00:22:31,939 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:22:31,948 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:22:31,948 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:22:31,968 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:23:00,925 - root - INFO - Aplication done
2023-11-21 00:35:40,421 - root - INFO - I am in the main method...
2023-11-21 00:35:40,421 - root - INFO - Calling  spark object
2023-11-21 00:35:40,422 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:35:40,422 - Create_pyspark - INFO - master is local
2023-11-21 00:35:53,719 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:35:53,719 - root - INFO - Validating spark object 
2023-11-21 00:35:53,719 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:35:58,644 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:35:58,644 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:35:58,644 - root - INFO - reading file which is of > parquet
2023-11-21 00:35:58,644 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:35:59,753 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:35:59,753 - root - INFO - displaying file
2023-11-21 00:35:59,769 - root - INFO - validating the dataframe city...
2023-11-21 00:35:59,769 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:36:00,919 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:36:00,919 - root - INFO - checking for the files in the FACT....
2023-11-21 00:36:00,925 - root - INFO - reading file which is of > csv
2023-11-21 00:36:00,925 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:36:04,904 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:36:04,904 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:36:04,904 - root - INFO - validating the dataframe fact...
2023-11-21 00:36:04,904 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:36:06,110 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:36:06,111 - root - INFO - implementing data_processing methods...
2023-11-21 00:36:06,119 - root - INFO - Decrypt Data frame city
2023-11-21 00:36:06,303 - root - INFO - Decrypt Data frame presc
2023-11-21 00:36:06,636 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:36:06,636 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:36:06,699 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:36:06,715 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:36:06,730 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:36:06,761 - Data_processing - WARNING - concat first and lname
2023-11-21 00:36:06,793 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:36:06,793 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:36:06,793 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:36:06,824 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:36:34,600 - root - INFO - Aplication done
2023-11-21 00:38:37,223 - root - INFO - I am in the main method...
2023-11-21 00:38:37,224 - root - INFO - Calling  spark object
2023-11-21 00:38:37,224 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:38:37,224 - Create_pyspark - INFO - master is local
2023-11-21 00:38:50,277 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:38:50,277 - root - INFO - Validating spark object 
2023-11-21 00:38:50,278 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:38:55,457 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:38:55,457 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:38:55,457 - root - INFO - reading file which is of > parquet
2023-11-21 00:38:55,457 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:38:56,991 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:38:56,991 - root - INFO - displaying file
2023-11-21 00:38:56,991 - root - INFO - validating the dataframe city...
2023-11-21 00:38:56,991 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:38:58,384 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:38:58,384 - root - INFO - checking for the files in the FACT....
2023-11-21 00:38:58,384 - root - INFO - reading file which is of > csv
2023-11-21 00:38:58,384 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:39:02,590 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:39:02,590 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:39:02,590 - root - INFO - validating the dataframe fact...
2023-11-21 00:39:02,594 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:39:03,704 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:39:03,704 - root - INFO - implementing data_processing methods...
2023-11-21 00:39:03,713 - root - INFO - Decrypt Data frame city
2023-11-21 00:39:03,883 - root - INFO - Decrypt Data frame presc
2023-11-21 00:39:04,197 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:39:04,197 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:39:04,244 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:39:04,259 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:39:04,275 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:39:04,306 - Data_processing - WARNING - concat first and lname
2023-11-21 00:39:04,337 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:39:04,337 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:39:04,337 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:39:04,378 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:39:31,561 - root - INFO - Aplication done
2023-11-21 00:44:52,543 - root - INFO - I am in the main method...
2023-11-21 00:44:52,544 - root - INFO - Calling  spark object
2023-11-21 00:44:52,544 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:44:52,544 - Create_pyspark - INFO - master is local
2023-11-21 00:45:02,666 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:45:02,666 - root - INFO - Validating spark object 
2023-11-21 00:45:02,666 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:45:08,657 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:45:08,657 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:45:08,657 - root - INFO - reading file which is of > parquet
2023-11-21 00:45:08,657 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:45:09,689 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:45:09,689 - root - INFO - displaying file
2023-11-21 00:45:09,689 - root - INFO - validating the dataframe city...
2023-11-21 00:45:09,689 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:45:10,654 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:45:10,654 - root - INFO - checking for the files in the FACT....
2023-11-21 00:45:10,669 - root - INFO - reading file which is of > csv
2023-11-21 00:45:10,670 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:45:16,295 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:45:16,295 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:45:16,295 - root - INFO - validating the dataframe fact...
2023-11-21 00:45:16,358 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:45:17,789 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:45:17,789 - root - INFO - implementing data_processing methods...
2023-11-21 00:45:17,795 - root - INFO - Decrypt Data frame city
2023-11-21 00:45:17,963 - root - INFO - Decrypt Data frame presc
2023-11-21 00:45:18,284 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:45:18,284 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:45:18,331 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:45:18,347 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:45:18,362 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:45:18,393 - Data_processing - WARNING - concat first and lname
2023-11-21 00:45:18,425 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:45:18,440 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:45:18,440 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:45:18,472 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:45:45,935 - root - INFO - Aplication done
2023-11-21 00:46:34,256 - root - INFO - I am in the main method...
2023-11-21 00:46:34,257 - root - INFO - Calling  spark object
2023-11-21 00:46:34,257 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 00:46:34,258 - Create_pyspark - INFO - master is local
2023-11-21 00:46:44,570 - Create_pyspark - INFO - Spark object created...
2023-11-21 00:46:44,570 - root - INFO - Validating spark object 
2023-11-21 00:46:44,571 - Validate - WARNING - started the get_current_date method...
2023-11-21 00:46:50,887 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 00:46:50,887 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 00:46:50,887 - root - INFO - reading file which is of > parquet
2023-11-21 00:46:50,888 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:46:52,120 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 00:46:52,120 - root - INFO - displaying file
2023-11-21 00:46:52,120 - root - INFO - validating the dataframe city...
2023-11-21 00:46:52,126 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 00:46:53,202 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 00:46:53,202 - root - INFO - checking for the files in the FACT....
2023-11-21 00:46:53,205 - root - INFO - reading file which is of > csv
2023-11-21 00:46:53,205 - Ingest - WARNING - load_files method  started...   
2023-11-21 00:46:57,385 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 00:46:57,385 - root - INFO - displaying the df_fact dataframe
2023-11-21 00:46:57,385 - root - INFO - validating the dataframe fact...
2023-11-21 00:46:57,388 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 00:46:58,625 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 1329329 
2023-11-21 00:46:58,626 - root - INFO - implementing data_processing methods...
2023-11-21 00:46:58,630 - root - INFO - Decrypt Data frame city
2023-11-21 00:46:58,747 - root - INFO - Decrypt Data frame presc
2023-11-21 00:46:58,997 - Data_processing - WARNING - data_clean method() start...
2023-11-21 00:46:58,997 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 00:46:59,028 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 00:46:59,044 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 00:46:59,044 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 00:46:59,082 - Data_processing - WARNING - concat first and lname
2023-11-21 00:46:59,098 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 00:46:59,098 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 00:46:59,098 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 00:46:59,129 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 00:47:25,933 - root - INFO - Aplication done
2023-11-21 09:49:33,697 - root - INFO - I am in the main method...
2023-11-21 09:49:33,697 - root - INFO - Calling  spark object
2023-11-21 09:49:33,697 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 09:49:33,697 - Create_pyspark - INFO - master is local
2023-11-21 09:49:41,260 - Create_pyspark - INFO - Spark object created...
2023-11-21 09:49:41,260 - root - INFO - Validating spark object 
2023-11-21 09:49:41,260 - Validate - WARNING - started the get_current_date method...
2023-11-21 09:49:48,034 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 09:49:48,034 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 09:49:48,034 - root - INFO - reading file which is of > parquet
2023-11-21 09:49:48,034 - Ingest - WARNING - load_files method  started...   
2023-11-21 09:49:49,227 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 09:49:49,227 - root - INFO - displaying file
2023-11-21 09:49:49,227 - root - INFO - validating the dataframe city...
2023-11-21 09:49:49,227 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 09:49:50,429 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 09:49:50,429 - root - INFO - checking for the files in the FACT....
2023-11-21 09:49:50,443 - root - INFO - reading file which is of > csv
2023-11-21 09:49:50,443 - Ingest - WARNING - load_files method  started...   
2023-11-21 09:49:52,544 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 09:49:52,544 - root - INFO - displaying the df_fact dataframe
2023-11-21 09:49:52,544 - root - INFO - validating the dataframe fact...
2023-11-21 09:49:52,544 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 09:49:53,174 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 83562 
2023-11-21 09:49:53,174 - root - INFO - implementing data_processing methods...
2023-11-21 09:49:53,188 - root - INFO - Decrypt Data frame city
2023-11-21 09:49:53,417 - root - INFO - Decrypt Data frame presc
2023-11-21 09:49:53,765 - Data_processing - WARNING - data_clean method() start...
2023-11-21 09:49:53,765 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 09:49:53,812 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 09:49:53,828 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 09:49:53,828 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 09:49:53,859 - Data_processing - WARNING - concat first and lname
2023-11-21 09:49:53,874 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 09:49:53,890 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 09:49:53,890 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 09:49:53,921 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 09:50:04,028 - root - INFO - Aplication done
2023-11-21 09:56:34,325 - root - INFO - I am in the main method...
2023-11-21 09:56:34,325 - root - INFO - Calling  spark object
2023-11-21 09:56:34,325 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 09:56:34,325 - Create_pyspark - INFO - master is local
2023-11-21 09:56:42,232 - Create_pyspark - INFO - Spark object created...
2023-11-21 09:56:42,232 - root - INFO - Validating spark object 
2023-11-21 09:56:42,232 - Validate - WARNING - started the get_current_date method...
2023-11-21 09:56:49,908 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 09:56:49,908 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 09:56:49,908 - root - INFO - reading file which is of > parquet
2023-11-21 09:56:49,908 - Ingest - WARNING - load_files method  started...   
2023-11-21 09:56:51,280 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 09:56:51,280 - root - INFO - displaying file
2023-11-21 09:56:51,288 - root - INFO - validating the dataframe city...
2023-11-21 09:56:51,288 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 09:56:53,126 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 09:56:53,126 - root - INFO - checking for the files in the FACT....
2023-11-21 09:56:53,134 - root - INFO - reading file which is of > csv
2023-11-21 09:56:53,134 - Ingest - WARNING - load_files method  started...   
2023-11-21 09:56:55,876 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 09:56:55,876 - root - INFO - displaying the df_fact dataframe
2023-11-21 09:56:55,876 - root - INFO - validating the dataframe fact...
2023-11-21 09:56:55,876 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 09:56:56,396 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 83562 
2023-11-21 09:56:56,396 - root - INFO - implementing data_processing methods...
2023-11-21 09:56:56,406 - root - INFO - Decrypt Data frame city
2023-11-21 09:56:56,598 - root - INFO - Decrypt Data frame presc
2023-11-21 09:56:57,017 - Data_processing - WARNING - data_clean method() start...
2023-11-21 09:56:57,017 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 09:56:57,065 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 09:56:57,112 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 09:56:57,112 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 09:56:57,159 - Data_processing - WARNING - concat first and lname
2023-11-21 09:56:57,190 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 09:56:57,206 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 09:56:57,206 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 09:56:57,227 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 09:57:08,734 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 09:57:08,734 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 09:57:08,734 - root - INFO - validating  schema for the dataframe...
2023-11-21 09:57:08,742 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - print_schema done, go frwd...
2023-11-21 09:57:08,742 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 09:57:08,742 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 09:57:08,742 - Validate - INFO - print_schema done, go frwd...
2023-11-21 09:57:08,742 - root - INFO - checking for null values in dataframe ...after processing
2023-11-21 09:57:08,750 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-21 09:57:08,993 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-21 09:57:08,993 - root - INFO - data_transformation executing...
2023-11-21 09:57:08,993 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 09:57:08,993 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 09:57:09,026 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 09:57:09,082 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 09:57:09,228 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 09:57:34,867 - root - INFO - Aplication done
2023-11-21 09:58:28,552 - root - INFO - I am in the main method...
2023-11-21 09:58:28,552 - root - INFO - Calling  spark object
2023-11-21 09:58:28,552 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 09:58:28,552 - Create_pyspark - INFO - master is local
2023-11-21 09:58:35,496 - Create_pyspark - INFO - Spark object created...
2023-11-21 09:58:35,496 - root - INFO - Validating spark object 
2023-11-21 09:58:35,496 - Validate - WARNING - started the get_current_date method...
2023-11-21 09:58:41,556 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 09:58:41,556 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 09:58:41,556 - root - INFO - reading file which is of > parquet
2023-11-21 09:58:41,556 - Ingest - WARNING - load_files method  started...   
2023-11-21 09:58:42,927 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 09:58:42,927 - root - INFO - displaying file
2023-11-21 09:58:42,927 - root - INFO - validating the dataframe city...
2023-11-21 09:58:42,927 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 09:58:44,019 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 09:58:44,019 - root - INFO - checking for the files in the FACT....
2023-11-21 09:58:44,034 - root - INFO - reading file which is of > csv
2023-11-21 09:58:44,034 - Ingest - WARNING - load_files method  started...   
2023-11-21 09:58:46,438 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 09:58:46,438 - root - INFO - displaying the df_fact dataframe
2023-11-21 09:58:46,438 - root - INFO - validating the dataframe fact...
2023-11-21 09:58:46,438 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 09:58:46,893 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 83562 
2023-11-21 09:58:46,893 - root - INFO - implementing data_processing methods...
2023-11-21 09:58:46,910 - root - INFO - Decrypt Data frame city
2023-11-21 09:58:47,118 - root - INFO - Decrypt Data frame presc
2023-11-21 09:58:47,535 - Data_processing - WARNING - data_clean method() start...
2023-11-21 09:58:47,535 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 09:58:47,559 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 09:58:47,574 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 09:58:47,590 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 09:58:47,637 - Data_processing - WARNING - concat first and lname
2023-11-21 09:58:47,668 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 09:58:47,668 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 09:58:47,668 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 09:58:47,702 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 09:58:57,325 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 09:58:57,325 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 09:58:57,325 - root - INFO - validating  schema for the dataframe...
2023-11-21 09:58:57,325 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 09:58:57,325 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 09:58:57,325 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 09:58:57,325 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 09:58:57,325 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 09:58:57,325 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 09:58:57,325 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 09:58:57,325 - Validate - INFO - print_schema done, go frwd...
2023-11-21 09:58:57,325 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 09:58:57,333 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 09:58:57,333 - Validate - INFO - print_schema done, go frwd...
2023-11-21 09:58:57,333 - root - INFO - checking for null values in dataframe ...after processing
2023-11-21 09:58:57,333 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-21 09:58:57,509 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-21 09:58:57,509 - root - INFO - data_transformation executing...
2023-11-21 09:58:57,509 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 09:58:57,509 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 09:58:57,541 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 09:58:57,613 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 09:58:57,749 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 09:59:26,120 - root - INFO - Aplication done
2023-11-21 10:02:02,295 - root - INFO - I am in the main method...
2023-11-21 10:02:02,310 - root - INFO - Calling  spark object
2023-11-21 10:02:02,310 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:02:02,310 - Create_pyspark - INFO - master is local
2023-11-21 10:02:08,864 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:02:08,864 - root - INFO - Validating spark object 
2023-11-21 10:02:08,864 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:02:14,850 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:02:14,850 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:02:14,850 - root - INFO - reading file which is of > parquet
2023-11-21 10:02:14,850 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:02:16,104 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:02:16,104 - root - INFO - displaying file
2023-11-21 10:02:16,104 - root - INFO - validating the dataframe city...
2023-11-21 10:02:16,116 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:02:17,406 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:02:17,406 - root - INFO - checking for the files in the FACT....
2023-11-21 10:02:17,406 - root - INFO - reading file which is of > csv
2023-11-21 10:02:17,406 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:02:19,304 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:02:19,304 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:02:19,304 - root - INFO - validating the dataframe fact...
2023-11-21 10:02:19,304 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 10:02:19,682 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 13593 
2023-11-21 10:02:19,682 - root - INFO - implementing data_processing methods...
2023-11-21 10:02:19,698 - root - INFO - Decrypt Data frame city
2023-11-21 10:02:19,883 - root - INFO - Decrypt Data frame presc
2023-11-21 10:02:20,231 - Data_processing - WARNING - data_clean method() start...
2023-11-21 10:02:20,231 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 10:02:20,278 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 10:02:20,294 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 10:02:20,294 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 10:02:20,341 - Data_processing - WARNING - concat first and lname
2023-11-21 10:02:20,372 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 10:02:20,372 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 10:02:20,372 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 10:02:20,403 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 10:02:24,130 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 10:02:24,130 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 10:02:24,130 - root - INFO - validating  schema for the dataframe...
2023-11-21 10:02:24,130 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:02:24,130 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 10:02:24,130 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 10:02:24,138 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 10:02:24,138 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 10:02:24,138 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 10:02:24,138 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 10:02:24,138 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:02:24,138 - root - INFO - checking for null values in dataframe ...after processing
2023-11-21 10:02:24,138 - Validate - INFO - check for nulls method executing ..... for df_fact
2023-11-21 10:02:24,346 - Validate - WARNING - check_for_nulls executed successfully....
2023-11-21 10:02:24,354 - root - INFO - data_transformation executing...
2023-11-21 10:02:24,354 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 10:02:24,354 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 10:02:24,386 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 10:02:24,450 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 10:02:24,674 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 10:02:31,732 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 10:02:31,732 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 10:02:31,998 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 10:02:31,998 - root - INFO - extracting files to Output...
2023-11-21 10:02:43,821 - root - INFO - extracting files to output completed.....
2023-11-21 10:02:43,837 - root - INFO - writing into hive table
2023-11-21 10:02:43,837 - root - INFO - successfully written into Hive
2023-11-21 10:02:43,845 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-21 10:02:51,182 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-21 10:02:55,396 - root - INFO - successfully data inserted into table Sql server...
2023-11-21 10:02:55,405 - root - INFO - Aplication done
2023-11-21 10:07:23,134 - root - INFO - I am in the main method...
2023-11-21 10:07:23,150 - root - INFO - Calling  spark object
2023-11-21 10:07:23,150 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:07:23,150 - Create_pyspark - INFO - master is local
2023-11-21 10:07:29,505 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:07:29,505 - root - INFO - Validating spark object 
2023-11-21 10:07:29,505 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:07:36,350 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:07:36,350 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:07:36,350 - root - INFO - reading file which is of > parquet
2023-11-21 10:07:36,350 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:07:37,503 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:07:37,503 - root - INFO - displaying file
2023-11-21 10:07:37,503 - root - INFO - validating the dataframe city...
2023-11-21 10:07:37,503 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:07:38,632 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:07:38,632 - root - INFO - checking for the files in the FACT....
2023-11-21 10:07:38,647 - root - INFO - reading file which is of > csv
2023-11-21 10:07:38,647 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:07:40,627 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:07:40,627 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:07:40,627 - root - INFO - validating the dataframe fact...
2023-11-21 10:07:40,627 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 10:07:40,973 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 13593 
2023-11-21 10:07:40,973 - root - INFO - implementing data_processing methods...
2023-11-21 10:07:40,973 - root - INFO - Decrypt Data frame city
2023-11-21 10:07:41,175 - root - INFO - Decrypt Data frame presc
2023-11-21 10:07:41,477 - Data_processing - WARNING - data_clean method() start...
2023-11-21 10:07:41,477 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 10:07:41,509 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 10:07:41,524 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 10:07:41,540 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 10:07:41,602 - Data_processing - WARNING - concat first and lname
2023-11-21 10:07:41,634 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 10:07:41,649 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 10:07:41,649 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 10:07:41,681 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 10:07:45,247 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 10:07:45,247 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 10:07:45,247 - root - INFO - validating  schema for the dataframe...
2023-11-21 10:07:45,247 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:07:45,247 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 10:07:45,247 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 10:07:45,247 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:07:45,247 - root - INFO - data_transformation executing...
2023-11-21 10:07:45,255 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 10:07:45,255 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 10:07:45,287 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 10:07:45,359 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 10:07:45,523 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 10:07:51,487 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 10:07:51,487 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 10:07:51,760 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 10:07:55,973 - root - INFO - extracting files to Output...
2023-11-21 10:08:06,440 - root - INFO - extracting files to output completed.....
2023-11-21 10:08:06,448 - root - INFO - writing into hive table
2023-11-21 10:08:06,448 - root - INFO - successfully written into Hive
2023-11-21 10:08:06,448 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-21 10:08:12,510 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-21 10:08:16,846 - root - INFO - successfully data inserted into table Sql server...
2023-11-21 10:08:16,846 - root - INFO - Aplication done
2023-11-21 10:10:03,779 - root - INFO - I am in the main method...
2023-11-21 10:10:03,779 - root - INFO - Calling  spark object
2023-11-21 10:10:03,779 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:10:03,779 - Create_pyspark - INFO - master is local
2023-11-21 10:10:10,880 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:10:10,880 - root - INFO - Validating spark object 
2023-11-21 10:10:10,880 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:10:16,914 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:10:16,914 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:10:16,922 - root - INFO - reading file which is of > parquet
2023-11-21 10:10:16,922 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:10:18,202 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:10:18,202 - root - INFO - displaying file
2023-11-21 10:10:18,202 - root - INFO - validating the dataframe city...
2023-11-21 10:10:18,202 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:10:19,528 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:10:19,528 - root - INFO - checking for the files in the FACT....
2023-11-21 10:10:19,538 - root - INFO - reading file which is of > csv
2023-11-21 10:10:19,538 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:10:21,278 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:10:21,278 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:10:21,278 - root - INFO - validating the dataframe fact...
2023-11-21 10:10:21,278 - Ingest - WARNING - here to count the records in the df_fact
2023-11-21 10:10:21,642 - Ingest - WARNING - Number  of records present in the DataFrame[npi: string, nppes_provider_last_org_name: string, nppes_provider_first_name: string, nppes_provider_city: string, nppes_provider_state: string, specialty_description: string, description_flag: string, drug_name: string, generic_name: string, bene_count: string, total_claim_count: string, total_30_day_fill_count: string, total_day_supply: string, total_drug_cost: string, bene_count_ge65: string, bene_count_ge65_suppress_flag: string, total_claim_count_ge65: string, ge65_suppress_flag: string, total_30_day_fill_count_ge65: string, total_day_supply_ge65: string, total_drug_cost_ge65: string, years_of_exp: string] are :: 13593 
2023-11-21 10:10:21,642 - root - INFO - implementing data_processing methods...
2023-11-21 10:10:21,642 - root - INFO - Decrypt Data frame city
2023-11-21 10:10:24,779 - root - INFO - Decrypt Data frame presc
2023-11-21 10:10:27,972 - Data_processing - WARNING - data_clean method() start...
2023-11-21 10:10:27,972 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 10:10:28,028 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 10:10:28,052 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 10:10:28,060 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 10:10:28,116 - Data_processing - WARNING - concat first and lname
2023-11-21 10:10:28,148 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 10:10:28,160 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 10:10:28,160 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 10:10:28,192 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 10:10:31,964 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 10:10:31,964 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 10:10:31,964 - root - INFO - validating  schema for the dataframe...
2023-11-21 10:10:31,964 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 10:10:31,964 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 10:10:31,964 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 10:10:31,971 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 10:10:31,971 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 10:10:31,971 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 10:10:31,971 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 10:10:31,971 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:10:33,387 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 10:10:33,387 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 10:10:33,387 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:10:37,021 - root - INFO - data_transformation executing...
2023-11-21 10:10:37,021 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 10:10:37,021 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 10:10:37,062 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 10:10:37,110 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 10:10:37,235 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 10:10:42,920 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 10:10:42,920 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 10:10:43,156 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 10:10:47,397 - root - INFO - extracting files to Output...
2023-11-21 10:10:57,264 - root - INFO - extracting files to output completed.....
2023-11-21 10:10:57,272 - root - INFO - writing into hive table
2023-11-21 10:10:57,272 - root - INFO - successfully written into Hive
2023-11-21 10:10:57,272 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-21 10:11:03,373 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-21 10:11:06,803 - root - INFO - successfully data inserted into table Sql server...
2023-11-21 10:11:06,803 - root - INFO - Aplication done
2023-11-21 10:16:21,729 - root - INFO - I am in the main method...
2023-11-21 10:16:21,729 - root - INFO - Calling  spark object
2023-11-21 10:16:21,729 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:16:21,729 - Create_pyspark - INFO - master is local
2023-11-21 10:16:28,888 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:16:28,888 - root - INFO - Validating spark object 
2023-11-21 10:16:28,888 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:16:34,829 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:16:34,829 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:16:34,829 - root - INFO - reading file which is of > parquet
2023-11-21 10:16:34,829 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:16:36,398 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:16:36,398 - root - INFO - displaying file
2023-11-21 10:16:36,438 - root - INFO - validating the dataframe city...
2023-11-21 10:16:36,486 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:16:40,030 - root - INFO - I am in the main method...
2023-11-21 10:16:40,030 - root - INFO - Calling  spark object
2023-11-21 10:16:40,030 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:16:40,030 - Create_pyspark - INFO - master is local
2023-11-21 10:16:46,445 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:16:46,445 - root - INFO - Validating spark object 
2023-11-21 10:16:46,445 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:16:52,705 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:16:52,705 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:16:52,705 - root - INFO - reading file which is of > parquet
2023-11-21 10:16:52,705 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:16:53,844 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:16:53,844 - root - INFO - displaying file
2023-11-21 10:16:53,844 - root - INFO - validating the dataframe city...
2023-11-21 10:16:53,844 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:16:55,091 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:16:55,091 - root - INFO - checking for the files in the FACT....
2023-11-21 10:16:55,109 - root - INFO - reading file which is of > csv
2023-11-21 10:16:55,109 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:16:56,922 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:16:56,922 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:16:56,922 - root - INFO - implementing data_processing methods...
2023-11-21 10:16:56,922 - root - INFO - Decrypt Data frame city
2023-11-21 10:17:00,100 - root - INFO - Decrypt Data frame presc
2023-11-21 10:17:03,427 - Data_processing - WARNING - data_clean method() start...
2023-11-21 10:17:03,443 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 10:17:03,499 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 10:17:03,531 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 10:17:03,547 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 10:17:03,598 - Data_processing - WARNING - concat first and lname
2023-11-21 10:17:03,645 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 10:17:03,660 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 10:17:03,660 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 10:17:03,692 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 10:17:09,033 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 10:17:09,033 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 10:17:09,033 - root - INFO - validating  schema for the dataframe...
2023-11-21 10:17:09,033 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 10:17:09,033 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 10:17:09,033 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 10:17:09,033 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 10:17:09,033 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 10:17:09,033 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 10:17:09,033 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 10:17:09,041 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:17:10,849 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 10:17:10,849 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 10:17:10,849 - Validate - INFO - print_schema done, go frwd...
2023-11-21 10:17:15,910 - root - INFO - data_transformation executing...
2023-11-21 10:17:15,918 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 10:17:15,918 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 10:17:15,958 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 10:17:16,014 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 10:17:16,191 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 10:17:24,797 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 10:17:24,797 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 10:17:25,106 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 10:17:30,256 - root - INFO - extracting files to Output...
2023-11-21 10:17:46,359 - root - INFO - extracting files to output completed.....
2023-11-21 10:17:46,374 - root - INFO - writing into hive table
2023-11-21 10:17:46,374 - root - INFO - successfully written into Hive
2023-11-21 10:17:46,374 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-21 10:17:56,775 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-21 10:18:02,944 - root - INFO - successfully data inserted into table Sql server...
2023-11-21 10:18:02,952 - root - INFO - Aplication done
2023-11-21 10:19:21,120 - root - INFO - I am in the main method...
2023-11-21 10:19:21,128 - root - INFO - Calling  spark object
2023-11-21 10:19:21,128 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:19:21,128 - Create_pyspark - INFO - master is local
2023-11-21 10:19:27,640 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:19:27,640 - root - INFO - Validating spark object 
2023-11-21 10:19:27,640 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:19:35,396 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:19:35,396 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:19:35,396 - root - INFO - reading file which is of > parquet
2023-11-21 10:19:35,396 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:19:37,079 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:19:37,079 - root - INFO - displaying file
2023-11-21 10:19:40,301 - root - INFO - validating the dataframe city...
2023-11-21 10:19:40,301 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:19:41,144 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:19:41,144 - root - INFO - checking for the files in the FACT....
2023-11-21 10:19:41,144 - root - INFO - reading file which is of > csv
2023-11-21 10:19:41,144 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:19:42,650 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:19:42,650 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:19:44,608 - root - INFO - Aplication done
2023-11-21 10:20:13,167 - root - INFO - I am in the main method...
2023-11-21 10:20:13,175 - root - INFO - Calling  spark object
2023-11-21 10:20:13,175 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:20:13,175 - Create_pyspark - INFO - master is local
2023-11-21 10:20:21,052 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:20:21,052 - root - INFO - Validating spark object 
2023-11-21 10:20:21,060 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:20:32,678 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:20:32,678 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:20:32,678 - root - INFO - reading file which is of > parquet
2023-11-21 10:20:32,678 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:20:34,178 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:20:34,179 - root - INFO - displaying file
2023-11-21 10:20:37,409 - root - INFO - validating the dataframe city...
2023-11-21 10:20:37,409 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:20:38,555 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:20:38,555 - root - INFO - checking for the files in the FACT....
2023-11-21 10:20:38,571 - root - INFO - reading file which is of > csv
2023-11-21 10:20:38,571 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:20:40,840 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:20:40,840 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:20:43,111 - root - INFO - Aplication done
2023-11-21 10:25:01,988 - root - INFO - I am in the main method...
2023-11-21 10:25:01,988 - root - INFO - Calling  spark object
2023-11-21 10:25:02,004 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:25:02,004 - Create_pyspark - INFO - master is local
2023-11-21 10:25:10,756 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:25:10,756 - root - INFO - Validating spark object 
2023-11-21 10:25:10,756 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:25:19,097 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:25:19,097 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:25:19,097 - root - INFO - reading file which is of > parquet
2023-11-21 10:25:19,097 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:25:21,065 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:25:21,065 - root - INFO - displaying file
2023-11-21 10:25:25,189 - root - INFO - I am in the main method...
2023-11-21 10:25:25,189 - root - INFO - Calling  spark object
2023-11-21 10:25:25,189 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:25:25,189 - Create_pyspark - INFO - master is local
2023-11-21 10:25:33,349 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:25:33,349 - root - INFO - Validating spark object 
2023-11-21 10:25:33,349 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:25:42,281 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:25:42,281 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:25:42,281 - root - INFO - reading file which is of > parquet
2023-11-21 10:25:42,281 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:25:43,933 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:25:43,933 - root - INFO - displaying file
2023-11-21 10:25:47,379 - root - INFO - validating the dataframe city...
2023-11-21 10:25:47,379 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:25:48,290 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:25:48,290 - root - INFO - checking for the files in the FACT....
2023-11-21 10:25:48,301 - root - INFO - reading file which is of > csv
2023-11-21 10:25:48,301 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:25:49,984 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:25:49,984 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:25:52,276 - root - INFO - Aplication done
2023-11-21 10:37:03,678 - root - INFO - I am in the main method...
2023-11-21 10:37:03,678 - root - INFO - Calling  spark object
2023-11-21 10:37:03,678 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:37:03,678 - Create_pyspark - INFO - master is local
2023-11-21 10:37:10,550 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:37:10,550 - root - INFO - Validating spark object 
2023-11-21 10:37:10,550 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:37:16,545 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:37:16,545 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:37:16,545 - root - INFO - reading file which is of > parquet
2023-11-21 10:37:16,545 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:37:17,837 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:37:17,837 - root - INFO - displaying file
2023-11-21 10:37:20,639 - root - INFO - validating the dataframe city...
2023-11-21 10:37:20,671 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:37:21,466 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:37:21,466 - root - INFO - checking for the files in the FACT....
2023-11-21 10:37:21,482 - root - INFO - reading file which is of > csv
2023-11-21 10:37:21,482 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:37:23,119 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:37:23,119 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:37:24,976 - root - INFO - Aplication done
2023-11-21 10:39:34,350 - root - INFO - I am in the main method...
2023-11-21 10:39:34,350 - root - INFO - Calling  spark object
2023-11-21 10:39:34,350 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:39:34,350 - Create_pyspark - INFO - master is local
2023-11-21 10:39:40,336 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:39:40,336 - root - INFO - Validating spark object 
2023-11-21 10:39:40,336 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:39:46,505 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:39:46,505 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:39:46,505 - root - INFO - reading file which is of > parquet
2023-11-21 10:39:46,505 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:39:47,659 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:39:47,659 - root - INFO - displaying file
2023-11-21 10:39:50,316 - root - INFO - validating the dataframe city...
2023-11-21 10:39:50,316 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:39:51,165 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: string, county_name: string, lat: string, lng: string, population: string, density: string, timezone: string, zips: string] are :: 28338 
2023-11-21 10:39:51,165 - root - INFO - checking for the files in the FACT....
2023-11-21 10:39:51,173 - root - INFO - reading file which is of > csv
2023-11-21 10:39:51,181 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:39:52,980 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:39:52,980 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:39:54,932 - root - INFO - implementing data_processing methods...
2023-11-21 10:39:54,932 - root - INFO - Decrypt Data frame city
2023-11-21 10:39:57,127 - root - INFO - Decrypt Data frame presc
2023-11-21 10:39:59,790 - root - INFO - Aplication done
2023-11-21 10:47:22,921 - root - INFO - I am in the main method...
2023-11-21 10:47:22,929 - root - INFO - Calling  spark object
2023-11-21 10:47:22,929 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:47:22,930 - Create_pyspark - INFO - master is local
2023-11-21 10:47:34,238 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:47:34,238 - root - INFO - Validating spark object 
2023-11-21 10:47:34,238 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:47:40,524 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:47:40,524 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:47:40,542 - root - INFO - reading file which is of > parquet
2023-11-21 10:47:40,542 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:47:41,581 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:47:41,918 - root - INFO - displaying file
2023-11-21 10:47:44,652 - root - INFO - validating the dataframe city...
2023-11-21 10:47:44,652 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:47:45,432 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-21 10:47:45,432 - root - INFO - checking for the files in the FACT....
2023-11-21 10:47:45,448 - root - INFO - reading file which is of > csv
2023-11-21 10:47:45,451 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:47:46,696 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:47:47,547 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:47:49,444 - root - INFO - implementing data_processing methods...
2023-11-21 10:47:49,452 - root - INFO - Decrypt Data frame city
2023-11-21 10:47:51,551 - root - INFO - Decrypt Data frame presc
2023-11-21 10:47:53,338 - root - INFO - Aplication done
2023-11-21 10:49:11,067 - root - INFO - I am in the main method...
2023-11-21 10:49:11,067 - root - INFO - Calling  spark object
2023-11-21 10:49:11,067 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:49:11,067 - Create_pyspark - INFO - master is local
2023-11-21 10:49:22,042 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:49:22,042 - root - INFO - Validating spark object 
2023-11-21 10:49:22,042 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:49:28,050 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:49:28,050 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:49:28,050 - root - INFO - reading file which is of > parquet
2023-11-21 10:49:28,058 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:49:28,924 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:49:29,297 - root - INFO - displaying file
2023-11-21 10:49:32,045 - root - INFO - validating the dataframe city...
2023-11-21 10:49:32,045 - Ingest - WARNING - here to count the records in the df_city
2023-11-21 10:49:32,973 - Ingest - WARNING - Number  of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338 
2023-11-21 10:49:32,973 - root - INFO - checking for the files in the FACT....
2023-11-21 10:49:32,997 - root - INFO - reading file which is of > csv
2023-11-21 10:49:32,997 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:49:34,339 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:49:35,355 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:49:38,274 - root - INFO - implementing data_processing methods...
2023-11-21 10:49:38,282 - root - INFO - Decrypt Data frame city
2023-11-21 10:49:40,140 - root - INFO - Decrypt Data frame presc
2023-11-21 10:49:42,127 - root - INFO - Aplication done
2023-11-21 10:55:27,943 - root - INFO - I am in the main method...
2023-11-21 10:55:27,943 - root - INFO - Calling  spark object
2023-11-21 10:55:27,943 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:55:27,943 - Create_pyspark - INFO - master is local
2023-11-21 10:55:39,046 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:55:39,046 - root - INFO - Validating spark object 
2023-11-21 10:55:39,061 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:55:46,428 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:55:46,428 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:55:46,428 - root - INFO - reading file which is of > parquet
2023-11-21 10:55:46,428 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:55:47,244 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:55:48,595 - root - INFO - Aplication done
2023-11-21 10:57:44,182 - root - INFO - I am in the main method...
2023-11-21 10:57:44,182 - root - INFO - Calling  spark object
2023-11-21 10:57:44,182 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:57:44,182 - Create_pyspark - INFO - master is local
2023-11-21 10:58:00,692 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:58:00,692 - root - INFO - Validating spark object 
2023-11-21 10:58:00,692 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:58:15,854 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:58:15,854 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:58:15,854 - root - INFO - reading file which is of > parquet
2023-11-21 10:58:15,854 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:58:17,122 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:58:19,925 - root - INFO - displaying file
2023-11-21 10:58:23,701 - root - INFO - checking for the files in the FACT....
2023-11-21 10:58:23,701 - root - INFO - reading file which is of > csv
2023-11-21 10:58:23,701 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:58:26,317 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:58:27,645 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:58:31,238 - root - INFO - implementing data_processing methods...
2023-11-21 10:58:31,238 - root - INFO - Decrypt Data frame city
2023-11-21 10:58:35,136 - root - INFO - Decrypt Data frame presc
2023-11-21 10:58:38,781 - root - INFO - Aplication done
2023-11-21 10:59:14,868 - root - INFO - I am in the main method...
2023-11-21 10:59:14,868 - root - INFO - Calling  spark object
2023-11-21 10:59:14,868 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 10:59:14,868 - Create_pyspark - INFO - master is local
2023-11-21 10:59:30,418 - Create_pyspark - INFO - Spark object created...
2023-11-21 10:59:30,418 - root - INFO - Validating spark object 
2023-11-21 10:59:30,418 - Validate - WARNING - started the get_current_date method...
2023-11-21 10:59:44,018 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 10:59:44,018 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 10:59:44,018 - root - INFO - reading file which is of > parquet
2023-11-21 10:59:44,018 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:59:45,091 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 10:59:48,499 - root - INFO - displaying file
2023-11-21 10:59:51,858 - root - INFO - checking for the files in the FACT....
2023-11-21 10:59:51,858 - root - INFO - reading file which is of > csv
2023-11-21 10:59:51,858 - Ingest - WARNING - load_files method  started...   
2023-11-21 10:59:54,136 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 10:59:55,425 - root - INFO - displaying the df_fact dataframe
2023-11-21 10:59:58,903 - root - INFO - implementing data_processing methods...
2023-11-21 10:59:58,903 - root - INFO - Decrypt Data frame city
2023-11-21 11:00:04,955 - root - INFO - Decrypt Data frame presc
2023-11-21 11:00:11,436 - root - INFO - Aplication done
2023-11-21 11:04:08,550 - root - INFO - I am in the main method...
2023-11-21 11:04:08,550 - root - INFO - Calling  spark object
2023-11-21 11:04:08,550 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 11:04:08,550 - Create_pyspark - INFO - master is local
2023-11-21 11:04:19,317 - Create_pyspark - INFO - Spark object created...
2023-11-21 11:04:19,317 - root - INFO - Validating spark object 
2023-11-21 11:04:19,317 - Validate - WARNING - started the get_current_date method...
2023-11-21 11:04:25,812 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 11:04:25,812 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 11:04:25,812 - root - INFO - reading file which is of > parquet
2023-11-21 11:04:25,812 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:04:26,730 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 11:04:27,160 - root - INFO - displaying file
2023-11-21 11:04:27,167 - root - INFO - checking for the files in the FACT....
2023-11-21 11:04:27,167 - root - INFO - reading file which is of > csv
2023-11-21 11:04:27,167 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:04:28,647 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 11:04:29,135 - root - INFO - displaying the df_fact dataframe
2023-11-21 11:04:29,145 - root - INFO - implementing data_processing methods...
2023-11-21 11:04:29,145 - root - INFO - Decrypt Data frame city
2023-11-21 11:04:29,330 - root - INFO - Decrypt Data frame presc
2023-11-21 11:04:29,634 - Data_processing - WARNING - data_clean method() start...
2023-11-21 11:04:29,634 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 11:04:29,665 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 11:04:29,681 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 11:04:29,697 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 11:04:29,743 - Data_processing - WARNING - concat first and lname
2023-11-21 11:04:29,768 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 11:04:29,781 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 11:04:29,781 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 11:04:29,796 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 11:04:39,758 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 11:04:39,758 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 11:04:39,758 - root - INFO - validating  schema for the dataframe...
2023-11-21 11:04:39,758 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 11:04:39,758 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 11:04:39,758 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 11:04:39,758 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 11:04:39,758 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 11:04:39,758 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 11:04:39,758 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 11:04:39,758 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:04:41,986 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 11:04:41,986 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 11:04:41,986 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:04:47,303 - root - INFO - Aplication done
2023-11-21 11:06:59,960 - root - INFO - I am in the main method...
2023-11-21 11:06:59,968 - root - INFO - Calling  spark object
2023-11-21 11:06:59,968 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 11:06:59,968 - Create_pyspark - INFO - master is local
2023-11-21 11:07:11,366 - root - INFO - I am in the main method...
2023-11-21 11:07:11,366 - root - INFO - Calling  spark object
2023-11-21 11:07:11,366 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 11:07:11,366 - Create_pyspark - INFO - master is local
2023-11-21 11:07:23,313 - Create_pyspark - INFO - Spark object created...
2023-11-21 11:07:23,313 - root - INFO - Validating spark object 
2023-11-21 11:07:23,313 - Validate - WARNING - started the get_current_date method...
2023-11-21 11:07:29,346 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 11:07:29,346 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 11:07:29,346 - root - INFO - reading file which is of > parquet
2023-11-21 11:07:29,346 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:07:30,307 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 11:07:30,680 - root - INFO - displaying file
2023-11-21 11:07:30,684 - root - INFO - checking for the files in the FACT....
2023-11-21 11:07:30,684 - root - INFO - reading file which is of > csv
2023-11-21 11:07:30,684 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:07:32,382 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 11:07:32,887 - root - INFO - displaying the df_fact dataframe
2023-11-21 11:07:32,898 - root - INFO - implementing data_processing methods...
2023-11-21 11:07:32,898 - root - INFO - Decrypt Data frame city
2023-11-21 11:07:33,055 - root - INFO - Decrypt Data frame presc
2023-11-21 11:07:33,363 - Data_processing - WARNING - data_clean method() start...
2023-11-21 11:07:33,363 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 11:07:33,394 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 11:07:33,425 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 11:07:33,441 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 11:07:33,507 - Data_processing - WARNING - concat first and lname
2023-11-21 11:07:33,531 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 11:07:33,546 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 11:07:33,546 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 11:07:33,578 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 11:07:45,565 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 11:07:45,565 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 11:07:45,565 - root - INFO - validating  schema for the dataframe...
2023-11-21 11:07:45,573 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:07:45,573 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 11:07:45,573 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 11:07:45,573 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:07:45,573 - root - INFO - data_transformation executing...
2023-11-21 11:07:45,573 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 11:07:45,581 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 11:07:45,629 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 11:07:45,813 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 11:07:45,919 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 11:08:45,325 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 11:08:45,325 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 11:08:45,535 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 11:09:08,904 - root - INFO - Aplication done
2023-11-21 11:13:05,813 - root - INFO - I am in the main method...
2023-11-21 11:13:05,813 - root - INFO - Calling  spark object
2023-11-21 11:13:05,813 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 11:13:05,813 - Create_pyspark - INFO - master is local
2023-11-21 11:13:18,869 - Create_pyspark - INFO - Spark object created...
2023-11-21 11:13:18,869 - root - INFO - Validating spark object 
2023-11-21 11:13:18,869 - Validate - WARNING - started the get_current_date method...
2023-11-21 11:13:24,947 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 11:13:24,947 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 11:13:24,947 - root - INFO - reading file which is of > parquet
2023-11-21 11:13:24,947 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:13:25,790 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 11:13:26,251 - root - INFO - displaying file
2023-11-21 11:13:26,251 - root - INFO - checking for the files in the FACT....
2023-11-21 11:13:26,251 - root - INFO - reading file which is of > csv
2023-11-21 11:13:26,262 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:13:27,812 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 11:13:28,327 - root - INFO - displaying the df_fact dataframe
2023-11-21 11:13:28,327 - root - INFO - implementing data_processing methods...
2023-11-21 11:13:28,327 - root - INFO - Decrypt Data frame city
2023-11-21 11:13:28,511 - root - INFO - Decrypt Data frame presc
2023-11-21 11:13:28,858 - Data_processing - WARNING - data_clean method() start...
2023-11-21 11:13:28,858 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 11:13:28,889 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 11:13:28,905 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 11:13:28,920 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 11:13:28,993 - Data_processing - WARNING - concat first and lname
2023-11-21 11:13:29,025 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 11:13:29,041 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 11:13:29,041 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 11:13:29,072 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 11:13:38,570 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 11:13:38,570 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 11:13:38,570 - root - INFO - validating  schema for the dataframe...
2023-11-21 11:13:38,572 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 11:13:38,574 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 11:13:38,574 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 11:13:38,574 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 11:13:38,574 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 11:13:38,574 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 11:13:38,574 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 11:13:38,574 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:13:38,574 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 11:13:38,582 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 11:13:38,582 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 11:13:38,582 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 11:13:38,582 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 11:13:38,582 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 11:13:38,584 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 11:13:38,584 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 11:13:38,584 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 11:13:38,584 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 11:13:38,584 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 11:13:38,584 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 11:13:38,584 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:13:38,584 - root - INFO - data_transformation executing...
2023-11-21 11:13:38,584 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 11:13:38,590 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 11:13:38,645 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 11:13:38,774 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 11:13:38,920 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 11:14:30,856 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 11:14:30,856 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 11:14:31,064 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 11:14:51,974 - root - INFO - Aplication done
2023-11-21 11:18:02,380 - root - INFO - I am in the main method...
2023-11-21 11:18:02,381 - root - INFO - Calling  spark object
2023-11-21 11:18:02,382 - Create_pyspark - INFO - get_spark_object method started
2023-11-21 11:18:02,382 - Create_pyspark - INFO - master is local
2023-11-21 11:18:14,452 - Create_pyspark - INFO - Spark object created...
2023-11-21 11:18:14,452 - root - INFO - Validating spark object 
2023-11-21 11:18:14,452 - Validate - WARNING - started the get_current_date method...
2023-11-21 11:18:20,938 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 21))]
2023-11-21 11:18:20,938 - Validate - WARNING - Validation  done , go frwd...
2023-11-21 11:18:20,939 - root - INFO - reading file which is of > parquet
2023-11-21 11:18:20,939 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:18:21,704 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-21 11:18:22,227 - root - INFO - displaying file
2023-11-21 11:18:22,243 - root - INFO - checking for the files in the FACT....
2023-11-21 11:18:22,243 - root - INFO - reading file which is of > csv
2023-11-21 11:18:22,243 - Ingest - WARNING - load_files method  started...   
2023-11-21 11:18:23,693 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-21 11:18:24,213 - root - INFO - displaying the df_fact dataframe
2023-11-21 11:18:24,215 - root - INFO - implementing data_processing methods...
2023-11-21 11:18:24,215 - root - INFO - Decrypt Data frame city
2023-11-21 11:18:24,404 - root - INFO - Decrypt Data frame presc
2023-11-21 11:18:24,689 - Data_processing - WARNING - data_clean method() start...
2023-11-21 11:18:24,689 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-21 11:18:24,705 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-21 11:18:24,723 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-21 11:18:24,739 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-21 11:18:24,773 - Data_processing - WARNING - concat first and lname
2023-11-21 11:18:24,789 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-21 11:18:24,805 - Data_processing - WARNING - now check for null values in all columns
2023-11-21 11:18:24,805 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-21 11:18:24,820 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-21 11:18:36,231 - Data_processing - WARNING - successfully droped the null values...
2023-11-21 11:18:36,232 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-21 11:18:36,232 - root - INFO - validating  schema for the dataframe...
2023-11-21 11:18:36,232 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-21 11:18:36,234 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-21 11:18:36,234 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-21 11:18:36,234 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-21 11:18:36,234 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-21 11:18:36,234 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-21 11:18:36,234 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-21 11:18:36,234 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:18:36,234 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-21 11:18:36,236 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-21 11:18:36,237 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-21 11:18:36,237 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-21 11:18:36,237 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-21 11:18:36,237 - Validate - INFO - print_schema done, go frwd...
2023-11-21 11:18:36,237 - root - INFO - data_transformation executing...
2023-11-21 11:18:36,242 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-21 11:18:36,245 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-21 11:18:36,285 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-21 11:18:36,355 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-21 11:18:36,476 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-21 11:18:36,585 - Data_transformation - WARNING - executing data_report2 method...
2023-11-21 11:18:36,585 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-21 11:18:36,726 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-21 11:18:36,872 - root - INFO - extracting files to Output...
2023-11-21 11:20:26,396 - root - INFO - extracting files to output completed.....
2023-11-21 11:20:26,405 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-21 11:21:34,216 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-21 11:22:18,864 - root - INFO - successfully data inserted into table Sql server...
2023-11-21 11:22:18,865 - root - INFO - Aplication done
2023-11-22 19:00:57,559 - root - INFO - I am in the main method...
2023-11-22 19:00:57,560 - root - INFO - Calling  spark object
2023-11-22 19:00:57,560 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 19:00:57,560 - Create_pyspark - INFO - master is local
2023-11-22 19:01:10,383 - Create_pyspark - INFO - Spark object created...
2023-11-22 19:01:10,383 - root - INFO - Validating spark object 
2023-11-22 19:01:10,383 - Validate - WARNING - started the get_current_date method...
2023-11-22 19:01:20,743 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 22))]
2023-11-22 19:01:20,743 - Validate - WARNING - Validation  done , go frwd...
2023-11-22 19:01:20,744 - root - INFO - reading file which is of > parquet
2023-11-22 19:01:20,744 - Ingest - WARNING - load_files method  started...   
2023-11-22 19:01:22,601 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-22 19:01:23,191 - root - INFO - displaying file
2023-11-22 19:01:23,192 - root - INFO - checking for the files in the FACT....
2023-11-22 19:01:23,192 - root - INFO - reading file which is of > csv
2023-11-22 19:01:23,193 - Ingest - WARNING - load_files method  started...   
2023-11-22 19:01:26,281 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-22 19:01:27,045 - root - INFO - displaying the df_fact dataframe
2023-11-22 19:01:27,079 - root - INFO - implementing data_processing methods...
2023-11-22 19:01:27,080 - root - INFO - Decrypt Data frame city
2023-11-22 19:01:27,322 - root - INFO - Decrypt Data frame presc
2023-11-22 19:01:27,725 - Data_processing - WARNING - data_clean method() start...
2023-11-22 19:01:27,725 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-22 19:01:27,775 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-22 19:01:27,803 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-22 19:01:27,814 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-22 19:01:27,883 - Data_processing - WARNING - concat first and lname
2023-11-22 19:01:27,922 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-22 19:01:27,939 - Data_processing - WARNING - now check for null values in all columns
2023-11-22 19:01:27,940 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-22 19:01:27,988 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-22 19:01:41,036 - Data_processing - WARNING - successfully droped the null values...
2023-11-22 19:01:41,036 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-22 19:01:41,036 - root - INFO - validating  schema for the dataframe...
2023-11-22 19:01:41,037 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-22 19:01:41,039 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-22 19:01:41,039 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-22 19:01:41,039 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-22 19:01:41,040 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-22 19:01:41,040 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-22 19:01:41,040 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-22 19:01:41,040 - Validate - INFO - print_schema done, go frwd...
2023-11-22 19:01:41,040 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-22 19:01:41,042 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-22 19:01:41,043 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-22 19:01:41,043 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-22 19:01:41,043 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-22 19:01:41,043 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-22 19:01:41,043 - Validate - INFO - print_schema done, go frwd...
2023-11-22 19:01:41,043 - root - INFO - data_transformation executing...
2023-11-22 19:01:41,043 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-22 19:01:41,047 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-22 19:01:41,096 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-22 19:01:41,175 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-22 19:01:41,246 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-22 19:01:41,391 - Data_transformation - WARNING - executing data_report2 method...
2023-11-22 19:01:41,392 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-22 19:01:41,516 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-22 19:01:41,659 - root - INFO - extracting files to Output...
2023-11-22 19:03:20,136 - root - INFO - extracting files to output completed.....
2023-11-22 19:03:20,150 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-22 19:04:32,517 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-22 19:04:56,825 - root - INFO - successfully data inserted into table Sql server...
2023-11-22 19:04:56,826 - root - INFO - Aplication done
2023-11-22 19:51:36,284 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 19:51:36,284 - Create_pyspark - INFO - master is local
2023-11-22 19:51:46,966 - Create_pyspark - INFO - Spark object created...
2023-11-22 19:53:26,925 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 19:53:26,925 - Create_pyspark - INFO - master is local
2023-11-22 19:53:37,517 - Create_pyspark - INFO - Spark object created...
2023-11-22 19:59:03,049 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 19:59:03,049 - Create_pyspark - INFO - master is local
2023-11-22 19:59:14,270 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:28:27,417 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:28:27,418 - Create_pyspark - INFO - master is local
2023-11-22 22:28:39,110 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:39:20,540 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:39:20,540 - Create_pyspark - INFO - master is local
2023-11-22 22:39:31,549 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:43:54,252 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:43:54,253 - Create_pyspark - INFO - master is local
2023-11-22 22:44:05,887 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:48:40,492 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:48:40,492 - Create_pyspark - INFO - master is local
2023-11-22 22:48:52,003 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:49:24,351 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:49:24,351 - Create_pyspark - INFO - master is local
2023-11-22 22:49:36,110 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:52:29,331 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:52:29,331 - Create_pyspark - INFO - master is local
2023-11-22 22:52:41,384 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:53:24,123 - root - INFO - I am in the main method...
2023-11-22 22:53:24,124 - root - INFO - Calling  spark object
2023-11-22 22:53:24,124 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 22:53:24,124 - Create_pyspark - INFO - master is local
2023-11-22 22:53:34,672 - Create_pyspark - INFO - Spark object created...
2023-11-22 22:53:34,672 - root - INFO - Validating spark object 
2023-11-22 22:53:34,672 - Validate - WARNING - started the get_current_date method...
2023-11-22 22:53:42,028 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 22))]
2023-11-22 22:53:42,028 - Validate - WARNING - Validation  done , go frwd...
2023-11-22 22:53:42,028 - root - INFO - reading file which is of > parquet
2023-11-22 22:53:42,044 - Ingest - WARNING - load_files method  started...   
2023-11-22 22:53:42,881 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-22 22:53:43,256 - root - INFO - displaying file
2023-11-22 22:53:43,272 - root - INFO - checking for the files in the FACT....
2023-11-22 22:53:43,272 - root - INFO - reading file which is of > csv
2023-11-22 22:53:43,273 - Ingest - WARNING - load_files method  started...   
2023-11-22 22:53:44,738 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-22 22:53:45,207 - root - INFO - displaying the df_fact dataframe
2023-11-22 22:53:45,207 - root - INFO - implementing data_processing methods...
2023-11-22 22:53:45,207 - root - INFO - Decrypt Data frame city
2023-11-22 22:53:45,389 - root - INFO - Decrypt Data frame presc
2023-11-22 22:53:45,709 - Data_processing - WARNING - data_clean method() start...
2023-11-22 22:53:45,709 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-22 22:53:45,740 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-22 22:53:45,756 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-22 22:53:45,771 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-22 22:53:45,818 - Data_processing - WARNING - concat first and lname
2023-11-22 22:53:45,850 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-22 22:53:45,865 - Data_processing - WARNING - now check for null values in all columns
2023-11-22 22:53:45,865 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-22 22:53:45,896 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-22 22:53:56,677 - Data_processing - WARNING - successfully droped the null values...
2023-11-22 22:53:56,677 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-22 22:53:56,677 - root - INFO - validating  schema for the dataframe...
2023-11-22 22:53:56,677 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - print_schema done, go frwd...
2023-11-22 22:53:56,677 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-22 22:53:56,677 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-22 22:53:56,677 - Validate - INFO - print_schema done, go frwd...
2023-11-22 22:53:56,677 - root - INFO - data_transformation executing...
2023-11-22 22:53:56,677 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-22 22:53:56,693 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-22 22:53:56,723 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-22 22:53:56,774 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-22 22:53:56,824 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-22 22:53:56,918 - Data_transformation - WARNING - executing data_report2 method...
2023-11-22 22:53:56,918 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-22 22:53:57,049 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
2023-11-22 22:53:57,169 - root - INFO - extracting files to Output...
2023-11-22 22:55:25,116 - root - INFO - extracting files to output completed.....
2023-11-22 22:55:25,119 - root - INFO - Now write DataFrame[city: string, state_name: string, county_name: string, population: string, zipcounts: string, presc_counts: string] into SQL Server
2023-11-22 22:56:21,576 - root - INFO - Now write DataFrame[presc_id: string, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: string, tx_cnt: string, total_day_supply: string, total_drug_cost: string, dense_rank: string] into SQL Server
2023-11-22 22:56:43,085 - root - INFO - successfully data inserted into table Sql server...
2023-11-22 22:56:43,085 - root - INFO - Aplication done
2023-11-22 23:04:11,292 - Create_pyspark - INFO - get_spark_object method started
2023-11-22 23:04:11,292 - Create_pyspark - INFO - master is local
2023-11-22 23:04:21,560 - Create_pyspark - INFO - Spark object created...
2023-11-22 23:04:21,560 - Validate - WARNING - started the get_current_date method...
2023-11-22 23:04:27,388 - Validate - WARNING - validating spark object with current date-[Row(current_date()=datetime.date(2023, 11, 22))]
2023-11-22 23:04:27,388 - Validate - WARNING - Validation  done , go frwd...
2023-11-22 23:04:27,527 - Ingest - WARNING - load_files method  started...   
2023-11-22 23:04:28,347 - Ingest - WARNING - dataframe created successfully which is of parquet
2023-11-22 23:04:28,942 - Ingest - WARNING - load_files method  started...   
2023-11-22 23:04:30,427 - Ingest - WARNING - dataframe created successfully which is of csv
2023-11-22 23:04:31,442 - Data_processing - WARNING - data_clean method() start...
2023-11-22 23:04:31,442 - Data_processing - WARNING - selecting required columns and converting some of columns into upper case...
2023-11-22 23:04:31,464 - Data_processing - WARNING - working on OLTP dataset and selecting couple of columns and rename,...
2023-11-22 23:04:31,479 - Data_processing - WARNING - Adding a new column to df_presc_sel
2023-11-22 23:04:31,490 - Data_processing - WARNING - converting years_of_exp string to int and replacing =
2023-11-22 23:04:31,532 - Data_processing - WARNING - concat first and lname
2023-11-22 23:04:31,558 - Data_processing - WARNING - Now droping presc_lname,presc_fname
2023-11-22 23:04:31,567 - Data_processing - WARNING - now check for null values in all columns
2023-11-22 23:04:31,567 - Data_processing - WARNING - drop the null values in the respective columns...
2023-11-22 23:04:31,595 - Data_processing - WARNING - fill the null values in tx_cnt with the avg values...
2023-11-22 23:04:41,186 - Data_processing - WARNING - successfully droped the null values...
2023-11-22 23:04:41,186 - Data_processing - WARNING - data cleaing method executed done, go frwd...
2023-11-22 23:04:41,255 - Validate - WARNING - print schema method executing....df_city_sel
2023-11-22 23:04:41,255 - Validate - INFO - 	StructField('city', StringType(), True)
2023-11-22 23:04:41,255 - Validate - INFO - 	StructField('state_id', StringType(), True)
2023-11-22 23:04:41,255 - Validate - INFO - 	StructField('state_name', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('county_name', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('population', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('zips', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - print_schema done, go frwd...
2023-11-22 23:04:41,270 - Validate - WARNING - print schema method executing....df_presc_sel
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('presc_id', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('presc_city', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('presc_state', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('presc_spclt', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('drug_name', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('tx_cnt', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('total_day_supply', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('total_drug_cost', StringType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('years_of_exp', IntegerType(), True)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('Country_name', StringType(), False)
2023-11-22 23:04:41,270 - Validate - INFO - 	StructField('presc_fullname', StringType(), False)
2023-11-22 23:04:41,270 - Validate - INFO - print_schema done, go frwd...
2023-11-22 23:04:41,376 - Data_transformation - WARNING - processing the data_report1 method..
2023-11-22 23:04:41,381 - Data_transformation - WARNING - calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: string, zips: string]
2023-11-22 23:04:41,415 - Data_transformation - WARNING - calculating distinct prescribers and total tx_cnt
2023-11-22 23:04:41,492 - Data_transformation - WARNING - Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-11-22 23:04:41,573 - Data_transformation - WARNING - Data_report1 succesfully executed..., go frwd
2023-11-22 23:04:41,903 - Data_transformation - WARNING - executing data_report2 method...
2023-11-22 23:04:41,903 - Data_transformation - WARNING - executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-11-22 23:04:42,088 - Data_transformation - WARNING - data_report2 method executed...., go frwd...
